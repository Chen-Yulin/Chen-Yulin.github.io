<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="theme-color" content="#123456"><title>Chen Yulin&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#6495ed"><meta name="application-name" content="Icarus - Hexo Theme"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="msapplication-TileColor" content="#6495ed"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Icarus - Hexo Theme"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Chen Yulin&#039;s Blog"><meta property="og:url" content="http://chen-yulin.github.io/"><meta property="og:site_name" content="Chen Yulin&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://chen-yulin.github.io/img/og_image.png"><meta property="article:author" content="Chen Yulin"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://chen-yulin.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://chen-yulin.github.io"},"headline":"Chen Yulin's Blog","image":["http://chen-yulin.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Chen Yulin"},"publisher":{"@type":"Organization","name":"Chen Yulin's Blog","logo":{"@type":"ImageObject","url":{"light":"/img/cyllogo.png","dark":"/img/cyllogonight.png"}}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><script type="text/javascript" src="/js/imaegoo/night.js"></script><canvas id="universe"></canvas><canvas id="flower"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img class="logo-img" src="/img/cyllogo.png" alt="Chen Yulin&#039;s Blog" height="28"><img class="logo-img-dark" src="/img/cyllogonight.png" alt="Chen Yulin&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/03/03/%5BOBS%5DReconstruct%20Anything-Semantic-ZegCLIP/"><img class="fill" src="/gallery/Research-paper.png" alt="ZegCLIP" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-03-03T08:57:04.000Z" title="3/3/2025, 4:57:04 PM">2025-03-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-24T01:54:52.760Z" title="4/24/2025, 9:54:52 AM">2025-04-24</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/03/03/%5BOBS%5DReconstruct%20Anything-Semantic-ZegCLIP/">ZegCLIP</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/03/03/%5BOBS%5DReconstruct%20Anything-Semantic-BLIP/"><img class="fill" src="/gallery/Research-paper.png" alt="BLIP" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-03-03T07:02:00.000Z" title="3/3/2025, 3:02:00 PM">2025-03-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-24T01:54:52.767Z" title="4/24/2025, 9:54:52 AM">2025-04-24</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">a few seconds read (About 108 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/03/03/%5BOBS%5DReconstruct%20Anything-Semantic-BLIP/">BLIP</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/03/03/[OBS]Reconstruct Anything-Semantic-BLIP/Pasted_image_20250303150710.png" title="" title=" class="gallery-item"><img src="/2025/03/03/[OBS]Reconstruct Anything-Semantic-BLIP/Pasted_image_20250303150710.png" alt="" title=""></a></div>

<p>A vision-language model that unifies vision-language understanding and generation tasks.</p>
<p>主要分为两块工作：</p>
<ul>
<li>去除图文检索所使用的数据集中的噪声</li>
<li>vision language understanding and generation</li>
</ul>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><h2 id="Noise-Filtering"><a href="#Noise-Filtering" class="headerlink" title="Noise Filtering"></a>Noise Filtering</h2><div class="post-content"><a href="/2025/03/03/[OBS]Reconstruct Anything-Semantic-BLIP/Pasted_image_20250304113427.png" title="" title=" class="gallery-item"><img src="/2025/03/03/[OBS]Reconstruct Anything-Semantic-BLIP/Pasted_image_20250304113427.png" alt="" title=""></a></div>
Caption 模型生成图像文本对，然后Filt将caption和真实互联网数据（可能存在噪声）进行对比，如果差异过大则使用Caption模型生成的结果

<h2 id="Understanding-amp-Generation"><a href="#Understanding-amp-Generation" class="headerlink" title="Understanding &amp; Generation"></a>Understanding &amp; Generation</h2></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/02/19/%5BOBS%5DReconstruct%20Anything-Semantic-GLIP/"><img class="fill" src="/gallery/Research-paper.png" alt="GLIP" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-19T11:07:33.000Z" title="2/19/2025, 7:07:33 PM">2025-02-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-24T01:54:52.758Z" title="4/24/2025, 9:54:52 AM">2025-04-24</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">2 minutes read (About 273 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/19/%5BOBS%5DReconstruct%20Anything-Semantic-GLIP/">GLIP</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p>GLIP是一个学习了object-level, language-aware, and semantic-rich visual representations 的模型。<br>统一对象检测和短语接地进行预训练。</p>
<h2 id="重要的问题"><a href="#重要的问题" class="headerlink" title="重要的问题"></a>重要的问题</h2><p>什么是 phrase grounding:<br><strong>Phrase Grounding</strong> refers to the task of associating or “grounding” a natural language phrase (like a sentence or a word) to a specific region or object in an image. In other words, it’s about finding which part of the image corresponds to the object or concept described by a given text phrase.</p>
<blockquote>
<p>For instance, if you have the phrase <em>“the red ball on the table”</em> and an image of a room with a red ball placed on a table, the goal of phrase grounding is to identify the exact region in the image that corresponds to the <em>“red ball on the table”</em>, distinguishing it from other objects in the image.</p>
</blockquote>
<div class="post-content"><a href="/2025/02/19/[OBS]Reconstruct Anything-Semantic-GLIP/Pasted_image_20250219200042.png" title="" title=" class="gallery-item"><img src="/2025/02/19/[OBS]Reconstruct Anything-Semantic-GLIP/Pasted_image_20250219200042.png" alt="" title=""></a></div>
## Grounded Language Image Pre-training
将经典对象检测任务投入到grounding问题中，并提出**Unified Formulation**

<h3 id="Unified-Formulation"><a href="#Unified-Formulation" class="headerlink" title="Unified Formulation"></a>Unified Formulation</h3><p>传统的物体检测方法会把每个region分类进c个classes，而本文使用的<strong>Object detection as phrase grounding</strong>.<br>我们通过将每个区域与文本提示中的c(class)短语进行接地&#x2F;对齐，将检测重新制定为基础任务<br>the classification prompt “person. bicycle. car. … . toothbrush”</p>
<div class="post-content"><a href="/2025/02/19/[OBS]Reconstruct Anything-Semantic-GLIP/Pasted_image_20250219200847.png" title="" title=" class="gallery-item"><img src="/2025/02/19/[OBS]Reconstruct Anything-Semantic-GLIP/Pasted_image_20250219200847.png" alt="" title=""></a></div>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-18T14:40:07.000Z" title="2/18/2025, 10:40:07 PM">2025-02-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-24T01:54:52.358Z" title="4/24/2025, 9:54:52 AM">2025-04-24</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">25 minutes read (About 3683 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/18/%5BOBS%5DNSFC%20-%20SceneLLM+KnowledgeGraph/">NSFC</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/b0e12986bd2f9cb38846cd84de198c2b.jpg" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/b0e12986bd2f9cb38846cd84de198c2b.jpg" alt="" title=""></a></div>
## Related Works
### Scene-LLM
一系列（数量没有限制）深度图片整合为一整个可以输入大语言模型的token,
可以实现动态更新场景
可以基于场景进行推理，输出物体之间的关系
### ConceptFusion
用于从图像生成像素级clip embeding，由Scene-LLM使用
### CLIP
通过对齐text encoder 和image encoder, 用于图像分类。单独使用image encoder可以生成图像整体的feature(clip embeding)

<h3 id="一、研究背景与意义"><a href="#一、研究背景与意义" class="headerlink" title="一、研究背景与意义"></a>一、研究背景与意义</h3><p>在人机协作的工作环境中，准确地理解与推理工作场景至关重要。传统方法往往依赖静态感知技术，难以处理动态变化的场景信息。随着深度学习和大语言模型的进步，结合<strong>场景大模型</strong>与<strong>知识图谱</strong>的多模态推理技术，将为环境理解提供更强的动态感知和智能推理能力。</p>
<ul>
<li><strong>场景大模型（Scene-LLM）</strong>：通过输入深度图像或点云数据，将场景信息转化为可用于推理的tokens，从而动态更新并理解场景中物体的关系。</li>
<li><strong>ConceptFusion</strong>：从图像中生成像素级特征，通过与Scene-LLM结合，帮助生成精确的物体描述和物体关系。</li>
<li><strong>CLIP</strong>：通过文本和图像的对齐，生成图像的语义特征，可用来进行图像分类、物体比对及外形描述验证。</li>
<li><strong>知识图谱</strong>：用图形表示的知识结构，其中的节点表示实体（如物体、事件、任务等），边表示实体之间的关系。它通过对现实世界的知识进行结构化、语义化的表示，能够支持推理、查询、推荐等应用。在本研究中，知识图谱用于表示人机协作环境中的工件、工具、任务和环境之间的关系</li>
</ul>
<h3 id="二、研究目标"><a href="#二、研究目标" class="headerlink" title="二、研究目标"></a>二、研究目标</h3><p>本研究的目标是提出一种结合场景大模型（Scene-LLM）与知识图谱的动态工作环境理解方法，利用深度学习的图像处理、物体检测和推理能力，优化人机协作的效率和安全性。具体目标包括：</p>
<ol>
<li>动态环境感知与更新：通过Scene-LLM和ConceptFusion，对多视角的工人装配场景进行实时处理，准确识别物体和工具的位置信息。</li>
<li>任务与物体关系理解：构建基于知识图谱的任务理解模型，结合图文比对技术，优化任务分配与物体关系推理。</li>
<li>智能协作与优化：通过知识图谱和场景推理，实现任务分配与协作策略的自动调整，提升人机协作的灵活性与效率。</li>
</ol>
<h3 id="三、研究Pipeline"><a href="#三、研究Pipeline" class="headerlink" title="三、研究Pipeline"></a>三、研究Pipeline</h3><h4 id="0-知识图谱的构建"><a href="#0-知识图谱的构建" class="headerlink" title="0. 知识图谱的构建"></a>0. 知识图谱的构建</h4><p>知识图谱是机器人了解工人与工件之间关系的重要凭依，所以第一步需要构建工人任务的知识图谱。（<strong>融合持续学习和推理的思想</strong>）</p>
<p><strong>知识图谱的结构<strong><strong>（</strong></strong>表格的形式表示关系和实体的类型****）</strong>通常是由实体（Nodes）和关系（Edges）组成的图。在人机协作工作环境，本方案构建的知识图谱的结构包括以下几个主要组件：</p>
<ul>
<li><p><strong>Nodes</strong></p>
</li>
<li><p>工件：每个工件都作为一个节点，节点包含工件的属性（如形状、尺寸、材质等，也可以包括多角度的图片），注：工件不一定是单独的零件，可以是装配体，也因此，整个装配任务可以被组织为一个树状的装配流程</p>
</li>
<li><p>工具：每种工具作为一个节点，节点包含工件的属性（如形状、尺寸、材质等，也可以包括多角度的图片）。</p>
</li>
<li><p>人员：描述工人或操作人员的节点，包含技能、工作任务等信息。</p>
</li>
<li><p><strong>Edges</strong></p>
</li>
<li><p>包含（Part-of）：表示某个工件是另一个工件的组成部分。</p>
</li>
<li><p>依赖（Depends-on）：描述任务或工具之间的依赖关系。例如，某个装配任务依赖于特定工具或工件。</p>
</li>
<li><p>执行（Performs）：表示人员与任务之间的执行关系，指示某个人员执行特定的任务。</p>
</li>
</ul>
<h4 id="1-动态语义空间重构（通用场景大模型适配专业化的工作领域，不需要微调fine-tuning-free）"><a href="#1-动态语义空间重构（通用场景大模型适配专业化的工作领域，不需要微调fine-tuning-free）" class="headerlink" title="1. 动态语义空间重构（通用场景大模型适配专业化的工作领域，不需要微调fine-tuning free）"></a>1. 动态语义空间重构（通用场景大模型适配专业化的工作领域，不需要微调fine-tuning free）</h4><p><strong>有选择地更新（亮点）</strong></p>
<p>场景语义化的核心目标是从原始场景数据中提取出有意义的实体（如工件、工具等）和它们之间的关系，并为这些实体和关系赋予语义标签，并输出给下游的推理模块生成任务。</p>
<p>主要分为以下几个步骤：</p>
<ol>
<li><p>场景数据采集</p>
</li>
<li><ol>
<li>深度图像与点云数据：使用多视角深度相机采集工作环境中的深度图像和点云数据</li>
</ol>
</li>
<li><ol start="2">
<li>使用<strong>ConceptFusion</strong>生成每个视角的像素级特征点云，以获取精确的场景语义点云信息。</li>
</ol>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=YjAxMmY1NWQyOWEzMDlkZTM1ZGYxNTdlZjUyYzg5ZDZfbHA5ZUVFZXhzaDZ1NFA5N3hnd1ZIQUlmTFpabklpbEJfVG9rZW46TWhKbWJNWERSbzZrdTV4YkI1ZGNVVk0zbk1kXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=YjAxMmY1NWQyOWEzMDlkZTM1ZGYxNTdlZjUyYzg5ZDZfbHA5ZUVFZXhzaDZ1NFA5N3hnd1ZIQUlmTFpabklpbEJfVG9rZW46TWhKbWJNWERSbzZrdTV4YkI1ZGNVVk0zbk1kXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   全局的像素级特帧点云 <code>M</code> 由一系列点构成，每个点都由顶点位置，法向向量，置信度数量，颜色和概念向量（concept vector）组成</p>
<p>   想要生成这样的像素级特征点云<code>M</code>，首先需要进行帧（单张输入图片）预处理：通过一系列输入的深度图片获取顶点法相maps和相机方位，再通过计算获得每张图片中每个像素的语义上下文嵌入。其中，语义上下文的嵌入是通过结合局部和全局的CLIP features获得的。</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NGEzNWQ2NDUyZmE3NTgyZmJhZjBjYTUyNDdhMTc3MDVfTzZyMFpFM3oxbFN0M3FyR2xuNHhGR2Qxc1lwdTcwN3RfVG9rZW46QXF0UmJVR2pkb3RvQkV4b0FoT2NZRTZublZ6XzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NGEzNWQ2NDUyZmE3NTgyZmJhZjBjYTUyNDdhMTc3MDVfTzZyMFpFM3oxbFN0M3FyR2xuNHhGR2Qxc1lwdTcwN3RfVG9rZW46QXF0UmJVR2pkb3RvQkV4b0FoT2NZRTZublZ6XzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   然后再进行特征融合：通过相机的方位将每个帧的顶点和法相图映射到全局坐标系。对于帧$X_{t}$中的每个像素$(u，v)_t$，都在全局的点云图中具有相应的点$P_k$</p>
<p>   以下是将不同帧$X_t$中的特征集合在<code>M</code>中特征点的公式：</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NjE1NWU4ZTRiMzlkMTE5ZDI4OTliYzE4MjEzMjhiODlfZHZjTzQzQjJiZzdGTVEwWXUybW5HdHdYQ3Q5TXRZbHJfVG9rZW46QUtVd2JnYlBhb21waHN4Mm1YUWNTN3J4bmZnXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NjE1NWU4ZTRiMzlkMTE5ZDI4OTliYzE4MjEzMjhiODlfZHZjTzQzQjJiZzdGTVEwWXUybW5HdHdYQ3Q5TXRZbHJfVG9rZW46QUtVd2JnYlBhb21waHN4Mm1YUWNTN3J4bmZnXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   通过ConceptFusion的预处理和语义上下文嵌入，就获得了精确的场景语义点云信息。</p>
</li>
<li><p>场景Token化：由于场景语义点云的信息过于密集，导致信息长度不可控，不利于输入大模型，所以使用Scene-LLM中的体素<strong>均匀下采样方法</strong>，将图像数据转化为统一的tokens格式，确保数据可以与prompt一起输入Scene-LLM模型进行推理，同时也便于将场景进行动态更新。</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NWQ0ZDVmZTJkMzhlZGVlMzY0M2YwYWFiNGUyNjg4N2JfY0JvREx5dVpjWU9Fc2VjQXhoRXh5cnZ2Mks3S1V0QmdfVG9rZW46SW9yZmJ2dndqb0hLWnR4bnJZOWNFa0c4bnFnXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NWQ0ZDVmZTJkMzhlZGVlMzY0M2YwYWFiNGUyNjg4N2JfY0JvREx5dVpjWU9Fc2VjQXhoRXh5cnZ2Mks3S1V0QmdfVG9rZW46SW9yZmJ2dndqb0hLWnR4bnJZOWNFa0c4bnFnXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   具体来说，这里首先将空间分为具有尺寸x×y×z的固定分辨率体素网格，其中x，y，z代表沿着各个轴的素数。由于这种固定的分辨率，在不同场景中的体素数量有所不同。其次，对于每个体素，使用K近邻（KNN）方法将所有包含的点聚类。每个点的特征包括语义属性和空间坐标。由此可以获得特征的体素网格：</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=OTYxNjUzNDExMzE1NWVmNzJlZDczM2I1ZWU0OGJkMTBfWEExclJlTTEweTFLSW9ya2J5cDBMa1pValpqR29PbTBfVG9rZW46UUpTRWJCYzZ0b3lYVmp4R0lwRmNMZFpQbjJiXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=OTYxNjUzNDExMzE1NWVmNzJlZDczM2I1ZWU0OGJkMTBfWEExclJlTTEweTFLSW9ya2J5cDBMa1pValpqR29PbTBfVG9rZW46UUpTRWJCYzZ0b3lYVmp4R0lwRmNMZFpQbjJiXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   其中D是语义特征的维度，而3是空间坐标的维度。</p>
<p>   最后，计算可见性映射V∈{0，1} x×y×z，表明每个体素中的点存在（1）或不存在（0）。仅使用可见体素的特征用作视觉tokens。这种 hybrid-representation 通过均匀地采样点云信息设置来保留密集的空间信息，同时促进了语义特征空间的动态更新。</p>
<p>   语义体素网络的动态更新可以通过如下方式实现：为了更新场景以状态t的 $f^{vox}_t$ 到状态t + 1，我们首先从当前的摄像头视图渲染3D 帧。该帧的语义特征F被投影到3D点的特征映射Fˆ，并将其体素化为F^^{Vox}并且生成 visibility map Vˆ。然后使用以下方式更新语义体素网络</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=Zjg1ZGYyM2U3ZTgzZjM4MGI3OWFiNGU1YjZjZDM5MGJfaUJWYlJaOFZVY3BiQjZhVHFpNGZrS2pkTnN1ckdQUXhfVG9rZW46THFqNmJJdnJIb2QzTjB4OG56OWMzTlBvbnRlXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=Zjg1ZGYyM2U3ZTgzZjM4MGI3OWFiNGU1YjZjZDM5MGJfaUJWYlJaOFZVY3BiQjZhVHFpNGZrS2pkTnN1ckdQUXhfVG9rZW46THFqNmJJdnJIb2QzTjB4OG56OWMzTlBvbnRlXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   如此便可以确保3D场景的语义表示与任何场景状态变化保持同步。</p>
</li>
<li><p>Scene-LLM生成语义空间信息</p>
</li>
<li><ol>
<li>通过将场景Tokens和prompt结合输入Scene-LLM，得到工件，工具或其他工人所需物品的信息(<strong>粗标签</strong>+坐标)</li>
</ol>
</li>
<li><ol start="2">
<li>依据物品在场景中的坐标，获得相机视角下该物体的（多视角）裁剪图片</li>
</ol>
</li>
<li><ol start="3">
<li>如果是工件&#x2F;工具，则通过CLIP，将裁剪图与知识图谱中该物品的文字描述进行<strong>比对</strong>，得到工件或工具的具体ID和<strong>专业名称</strong>。</li>
</ol>
</li>
</ol>
<div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=MTUzYzYwYWYyMDYyYWE0ZThhNWI0ZmMyZTU5ODhjNmRfaXRGajVuN0dZRGgySXBVRTZDRDUwT3dXR2dXQk5LR0NfVG9rZW46Q05haWJOZzg1bzhxNzR4cWtCa2NieENablNjXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=MTUzYzYwYWYyMDYyYWE0ZThhNWI0ZmMyZTU5ODhjNmRfaXRGajVuN0dZRGgySXBVRTZDRDUwT3dXR2dXQk5LR0NfVG9rZW46Q05haWJOZzg1bzhxNzR4cWtCa2NieENablNjXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>

<p>CLIP（Contrastive Language-Image Pre-training）是一种基于对比学习的模型，旨在同时处理图像和文本数据，并将它们映射到一个共享的特征嵌入空间中。其训练过程包括对图像和文本对的学习，其中每一对图像和文本（如图像的描述）都会被处理成特征向量，图像由视觉编码器（通常是卷积神经网络或视觉Transformer）处理，文本则通过一个Transformer模型编码。模型的核心思想是通过对比学习的方式优化图像和文本之间的关系，使得正确配对的图像和文本在共享的嵌入空间中距离较近，而不相关的图像和文本则距离较远。这一过程通过对比损失函数（如InfoNCE）进行优化，模型逐渐学习到图像和文本之间的语义对应关系。CLIP在大规模图像-文本数据集上进行训练，通常涉及数百万对图像-文本配对，从而使其能够进行跨模态推理。训练完成后的CLIP能够在零-shot的情况下执行任务，即在没有专门训练的情况下处理新的计算机视觉和自然语言处理任务，如通过文本描述检索相关图像，或者根据图像检索相关文本。</p>
<p>想要比对裁剪图和物品的文字描述，可以通过使用预先使用CLIP预训练好的ViT图编码器和Transformer 文字编码器，分别用于编码物体的裁剪图和知识图谱中对于每一个工件的描述（并不需要每次识别都进行编码，可以预编码之后保存用于后续每次对比）。再使用裁剪图和文字的特征向量进行似然性评估，找到最贴合裁剪图的文字特征向量并由此获得裁剪图对应的具体工件或者工具序号。</p>
<p><strong>语义空间最终输出</strong>：场景中所有关键的工具、零件的标签（ID和<strong>专业名称</strong>）+精确位置坐标（场景中有啥，在哪）</p>
<h4 id="2-基于知识图谱的推理与任务生成"><a href="#2-基于知识图谱的推理与任务生成" class="headerlink" title="2. 基于知识图谱的推理与任务生成"></a>2. 基于知识图谱的推理与任务生成</h4><p>基于知识图谱的推理和任务生成方法在智能系统中扮演着关键角色，特别是在需要理解复杂场景和动态调整任务的应用中。</p>
<p>在获取了语义空间的信息后，知识图谱的应用主要分为以下几个步骤：</p>
<ol>
<li><p>通过工人的手部位置+语义空间的信息-&gt;判断当前正在装配的工件（检索&#x2F;搜索过程）+工人在用的工具</p>
</li>
<li><p>正在装配的工件+工人在用的工具+<strong>知识图谱</strong><strong>-&gt;<strong>判断下一步需要装配的零件以及需要的工具，并据此生成机器人需要执行的</strong>具体任务</strong>（比如抓取某区域的关键物体并放置到特定位置，更具体一些？）</p>
</li>
</ol>
<p>具体任务可能包括以下几种：</p>
<ul>
<li><p>GRASP <Pos>：</p>
<ul>
<li><p>任务描述：机器人需要抓取某一特定区域(<Pos>)的关键物体。</p>
</li>
<li><p>生成任务：结合语义空间的信息，系统会确定物体的精确位置（例如，某个工件的位置），并且会根据工件的形状、尺寸、重量等属性选择适当的抓取策略和工具。系统会向机器人发送抓取任务，指示其准确抓取目标物体。</p>
</li>
</ul>
</li>
<li><p>PLACE <Pos>：</p>
<ul>
<li><p>任务描述：机器人将物体放置到指定位置(<Pos>)。</p>
</li>
<li><p>生成任务：根据知识图谱和工人正在装配物体的位置，推理出工件的目标位置，例如，物体需要放置在某个工作台上的特定位置。</p>
</li>
<li><p>示例：将抓取的零件放置到工人需要的位置上，确保其放置的位置正确。</p>
</li>
</ul>
</li>
<li><p>GOTO <Pos>：</p>
<ul>
<li><p>任务描述：机器人末端移动到指定位置(<Pos>)。</p>
</li>
<li><p>生成任务：一般用于机器人执行完PLACE <Pos>后，归位以免阻碍工人操作工件</p>
</li>
</ul>
</li>
</ul>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/02/18/%5BOBS%5DReconstruct%20Anything-Extract%20Free%20Dense%20Labels%20from%20CLIP/"><img class="fill" src="/gallery/Research-paper.png" alt="Extract Free Dense Labels from CLIP" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-18T05:09:17.000Z" title="2/18/2025, 1:09:17 PM">2025-02-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-24T01:54:52.749Z" title="4/24/2025, 9:54:52 AM">2025-04-24</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/18/%5BOBS%5DReconstruct%20Anything-Extract%20Free%20Dense%20Labels%20from%20CLIP/">Extract Free Dense Labels from CLIP</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-17T13:56:40.000Z" title="2/17/2025, 9:56:40 PM">2025-02-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-24T01:54:52.374Z" title="4/24/2025, 9:54:52 AM">2025-04-24</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 14 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/17/%5BOBS%5Dlinux-Docker/">Docker</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>proxy网络: <a target="_blank" rel="noopener" href="https://docs.docker.com/engine/daemon/proxy/#httphttps-proxy">https://docs.docker.com/engine/daemon/proxy/#httphttps-proxy</a></p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/02/17/%5BOBS%5DReconstruct%20Anything-ConceptFusion/"><img class="fill" src="/gallery/Research-paper.png" alt="ConceptFusion" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-17T06:59:54.000Z" title="2/17/2025, 2:59:54 PM">2025-02-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-24T01:54:52.822Z" title="4/24/2025, 9:54:52 AM">2025-04-24</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">2 minutes read (About 297 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/17/%5BOBS%5DReconstruct%20Anything-ConceptFusion/">ConceptFusion</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/02/17/[OBS]Reconstruct Anything-ConceptFusion/Pasted_image_20250223135004.png" title="" title=" class="gallery-item"><img src="/2025/02/17/[OBS]Reconstruct Anything-ConceptFusion/Pasted_image_20250223135004.png" alt="" title=""></a></div>
## Approach
目标是构建一个open-set multimodal  3D map `M`. 
可以使用特定于模态的编码器（基础模型）$F_{Mode}$将图像，文本，音频和点击等多维信号编码为矢量空间
其中，`M` 由一系列点构成，每个点都包含：顶点位置，法向向量，置信度数量，颜色和概念向量（concept vector）组成
首先是帧（单张输入图片）预处理：通过一系列输入的深度图片获取顶点法相maps和相机方位，再通过计算获得每张图片中每个像素的语义上下文嵌入。其中，语义上下文的嵌入是通过结合局部和全局的CLIP features获得的。
<div class="post-content"><a href="/2025/02/17/[OBS]Reconstruct Anything-ConceptFusion/Pasted_image_20250223143614.png" title="" title=" class="gallery-item"><img src="/2025/02/17/[OBS]Reconstruct Anything-ConceptFusion/Pasted_image_20250223143614.png" alt="" title=""></a></div>
然后再进行特征融合：通过相机的方位将每个帧的顶点和法相图映射到全局坐标系。对于帧$X_{t}$中的每个像素$(u，v)_t$，都在`M`中具有相应的点$P_k$

<p>将不同帧$X_t$中的特征集合在<code>M</code>中特征点的公式：</p>
<div class="post-content"><a href="/2025/02/17/[OBS]Reconstruct Anything-ConceptFusion/Pasted_image_20250223143103.png" title="" title=" class="gallery-item"><img src="/2025/02/17/[OBS]Reconstruct Anything-ConceptFusion/Pasted_image_20250223143103.png" alt="" title=""></a></div>



</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/02/16/%5BOBS%5DReconstruct%20Anything-Semantic-Grounding-DINO/"><img class="fill" src="/gallery/Research-paper.png" alt="Grounding-DINO" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-16T09:07:36.000Z" title="2/16/2025, 5:07:36 PM">2025-02-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-24T01:54:52.783Z" title="4/24/2025, 9:54:52 AM">2025-04-24</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">a minute read (About 216 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/16/%5BOBS%5DReconstruct%20Anything-Semantic-Grounding-DINO/">Grounding-DINO</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p>,<div class="post-content"><a href="/2025/02/16/[OBS]Reconstruct Anything-Semantic-Grounding-DINO/Pasted_image_20250219103227.png" title="" title=" class="gallery-item"><img src="/2025/02/16/[OBS]Reconstruct Anything-Semantic-Grounding-DINO/Pasted_image_20250219103227.png" alt="" title=""></a></div></p>
<p>通过结合[[DINO]]和grounded-pretraining，可以使用人类输入（例如类别名称或转介表达式）检测任意对象<br>Open-Vocab. Det</p>
<blockquote>
<p>an open-set object detector that can detect any objects with respect to an arbitrary free-form text prompt. The model was trained on over 10 million images, including detection data, visual grounding data, and image-text pairs. It has a strong zero-shot detection performance. However, the model needs text as inputs and can only detect boxes with corresponding phrases.</p>
</blockquote>
<h2 id="Grounding-DINO"><a href="#Grounding-DINO" class="headerlink" title="Grounding-DINO"></a>Grounding-DINO</h2><h3 id="Principle"><a href="#Principle" class="headerlink" title="Principle"></a>Principle</h3><h4 id="Tight-modality-fusion-based-on-DINO"><a href="#Tight-modality-fusion-based-on-DINO" class="headerlink" title="Tight modality fusion based on [[DINO]]"></a>Tight modality fusion based on [[DINO]]</h4><p>什么是feature fusion?</p>
<div class="post-content"><a href="/2025/02/16/[OBS]Reconstruct Anything-Semantic-Grounding-DINO/Pasted_image_20250219100532.png" title="" title=" class="gallery-item"><img src="/2025/02/16/[OBS]Reconstruct Anything-Semantic-Grounding-DINO/Pasted_image_20250219100532.png" alt="" title=""></a></div>
- 在多模态领域，feature fusion 特指将不同模态的特征（如视觉、文本、音频等）进行融合的技术。CLIP 应该被看作是 Middle Fusion 的一种形式, 在特征提取后就进行融合对齐
#### large-scale grounded pre-train for concept generalization
Reformulating **object detection** as a **phrase grounding task** and introducing **contrastive training** between object regions and language phrases on large-scale data</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/02/16/%5BOBS%5DReconstruct%20Anything-Semantic-Gounded-SAM/"><img class="fill" src="/gallery/Research-paper.png" alt="Gounded-SAM" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-16T09:07:30.000Z" title="2/16/2025, 5:07:30 PM">2025-02-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-24T01:54:52.766Z" title="4/24/2025, 9:54:52 AM">2025-04-24</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">a few seconds read (About 17 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/16/%5BOBS%5DReconstruct%20Anything-Semantic-Gounded-SAM/">Gounded-SAM</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p><a target="_blank" rel="noopener" href="https://github.com/IDEA-Research/Grounded-Segment-Anything">https://github.com/IDEA-Research/Grounded-Segment-Anything</a></p>
<p>By [[Grounding-DINO]] + SAM<br>Achieving Open-Vocab. Det &amp; Seg</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/02/15/%5BOBS%5DReconstruct%20Anything-Scene-LLM/"><img class="fill" src="/gallery/LLM.png" alt="Scene-LLM" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-15T08:17:31.000Z" title="2/15/2025, 4:17:31 PM">2025-02-15</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-24T01:54:52.795Z" title="4/24/2025, 9:54:52 AM">2025-04-24</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">6 minutes read (About 919 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/15/%5BOBS%5DReconstruct%20Anything-Scene-LLM/">Scene-LLM</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/02/15/[OBS]Reconstruct Anything-Scene-LLM/Pasted_image_20250215153945.png" title="" title=" class="gallery-item"><img src="/2025/02/15/[OBS]Reconstruct Anything-Scene-LLM/Pasted_image_20250215153945.png" alt="" title=""></a></div>
## Intro
尽管现有的视觉语言模型（VLM）在2D视觉语言的理解中取得了长足的进步，但与使用3D表示室内场景任务的人相比，它们对持续3D空间信息的掌握有限通常会使它们的有效性较小。
最近的一些文章[[3D-LLM]]以文本和其他方式桥接3D视觉信息显示出3D视觉理解和推理的潜力。但是，它们主要处理静态3D场景，这对于涉及场景变化的互动计划的适应性较低。

<p>本文提出的模型主要想解决3D密集标注和交互式规划。<br>结合</p>
<ul>
<li>egocentric（crucial for immediate updates during object interactions and for localizing the agent within the scene）</li>
<li>comprehensive（provides temporal persistent and multi-view consistent details of the entire 3D scene）<br>scene-level的信息。</li>
</ul>
<p>需要align the dense 3D visual information with the textual embedding space of a pre-trained LLM。3D点集由于其连续坐标系以及需要适应场景状态变化的表示形式而构成了一个独特的问题</p>
<h2 id="Related-Works"><a href="#Related-Works" class="headerlink" title="Related Works"></a>Related Works</h2><p>3D-VQA<br>VLN(Visual-Language Navigation)</p>
<h2 id="3D-Visual-Language-Data-Generation"><a href="#3D-Visual-Language-Data-Generation" class="headerlink" title="3D-Visual-Language Data Generation"></a>3D-Visual-Language Data Generation</h2><p>和[[3D-LLM]]一样，都是多视角采集D-RGB信息然后整合为3D frame<br>标注信息来自于Mini-GPT-V2（capable of generating captions and object descriptions from images by using caption and grounded caption identifiers）。</p>
<h3 id="3D-frame"><a href="#3D-frame" class="headerlink" title="3D-frame"></a>3D-frame</h3><p>Uses image frames and a 2D-VLM(Mini-GPT-V2) to generate frame descriptions</p>
<h3 id="Scene-Data"><a href="#Scene-Data" class="headerlink" title="Scene Data"></a>Scene Data</h3><p>3D场景数据是通过基于其相机姿势汇总的3D帧来重建<br>使用Llama-2-Chat-70B [65]生成场景的语言注释</p>
<blockquote>
<p>prompted with a mix of context data including generated frame captions, frame object descriptions, annotated object lists, and annotated bounding boxes. These prompts lead to diverse instruction-following data types like dense caption, object caption, task decomposition, functionality enhancement, question-answering, and human-robot dialogues</p>
</blockquote>
<div class="post-content"><a href="/2025/02/15/[OBS]Reconstruct Anything-Scene-LLM/Pasted_image_20250217143744.png" title="" title=" class="gallery-item"><img src="/2025/02/15/[OBS]Reconstruct Anything-Scene-LLM/Pasted_image_20250217143744.png" alt="" title=""></a></div>
From Vision Studio
对于VLM生成内容使用的self-checking: [83]

<h2 id="Scene-LLM"><a href="#Scene-LLM" class="headerlink" title="Scene-LLM"></a>Scene-LLM</h2><p>场景-LLM是一种3D视觉语言模型（VLM），具有简单而有效的体系结构，旨在理解以基于本体和场景级别的3D视觉信息，使其能够成功执行交互式计划任务。本节概述了3D视觉特征提取过程，我们的模型的体系结构，3D视觉信息与数据集的对齐以及使用Scene-LLM进行推理。</p>
<p>Employ visual language semantic features [51] to represent 3D visual semantics</p>
<ul>
<li>first extracting pixel-wise CLIP features from each image and then aggregating these into a 3D point set [[ConceptFusion]]</li>
</ul>
<p>Tokenize 3D visual features for LLM input:</p>
<ul>
<li>hybrid point-voxel representation (need for dense 3D visual information, support for interactive updates, and manageable token lengths for the LLM)</li>
</ul>
<h3 id="网络大体上分为两层："><a href="#网络大体上分为两层：" class="headerlink" title="网络大体上分为两层："></a>网络大体上分为两层：</h3><h4 id="Projection-layer"><a href="#Projection-layer" class="headerlink" title="Projection layer"></a>Projection layer</h4><p>To bridge 3D visual tokens(F) with the LLM’s tokenized space<br>FC(1030, 768)-&gt;GELU-&gt;FC(768,768)</p>
<h4 id="LLM"><a href="#LLM" class="headerlink" title="LLM"></a>LLM</h4><p>Llama-2-7b as the foundational LLM backbone</p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><h4 id="Stage-1-Pretraining-for-Feature-Alignment"><a href="#Stage-1-Pretraining-for-Feature-Alignment" class="headerlink" title="Stage 1: Pretraining for Feature Alignment"></a>Stage 1: Pretraining for Feature Alignment</h4><p>在两个坐标系统（camera和世界坐标）下使用3D帧数据，以确保场景-LLM理解以自我为中心和以场景为中心的观点。<br>在此阶段，仅训练了projection layer，可以有效地对齐具有文本特征的3D视觉特征，同时保持LLM参数（φ）不变。</p>
<h4 id="Stage-2-Finetuning"><a href="#Stage-2-Finetuning" class="headerlink" title="Stage 2: Finetuning"></a>Stage 2: Finetuning</h4><p>优化Scene-llm，以准确响应用户说明。我们使用标识符令牌“我看到”将3D帧语言和3D场景语言数据合并到前言。文本描述分为指令（$T_{INST}$）及其相应的响应（$T_{ANS}$）。利用转换后的3D视觉令牌（$T_{3D}$）和指令令牌（$T_{INST}$），我们的目标是微调LLM（φ）以自动生成$T_{ANS}$.<br>在这里，我们共同微调了投影层和LLM，由θ&#x3D; {ψ，φ}表示</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/6/">Previous</a></div><div class="pagination-next"><a href="/page/8/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/5/">5</a></li><li><a class="pagination-link" href="/page/6/">6</a></li><li><a class="pagination-link is-current" href="/page/7/">7</a></li><li><a class="pagination-link" href="/page/8/">8</a></li><li><a class="pagination-link" href="/page/9/">9</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/26/">26</a></li></ul></nav></div><style>.column.column-left,.column.column-right{display:none}</style><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Chen Yulin"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Chen Yulin</p><p class="is-size-6 is-block">SJTU student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Manchester by the Sea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">252</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">186</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Chen-Yulin" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/04/"><span class="level-start"><span class="level-item">April 2025</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">March 2025</span></span><span class="level-end"><span class="level-item tag">45</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">February 2025</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item">January 2025</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">December 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/11/"><span class="level-start"><span class="level-item">November 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/07/"><span class="level-start"><span class="level-item">July 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">June 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/05/"><span class="level-start"><span class="level-item">May 2024</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/04/"><span class="level-start"><span class="level-item">April 2024</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">46</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/2025/04/23/%5BOBS%5D%E7%A7%91%E7%A0%94-FCSGG%20Repo%20Explanation/"><img src="/thumb/Python.png" alt="FCSGG Repo Explanation"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-23T14:34:47.000Z">2025-04-23</time></p><p class="title"><a href="/2025/04/23/%5BOBS%5D%E7%A7%91%E7%A0%94-FCSGG%20Repo%20Explanation/">FCSGG Repo Explanation</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/22/%5BOBS%5D%E7%A7%91%E7%A0%94-Detectron/"><img src="/thumb/Python.png" alt="Detectron"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-22T14:13:52.000Z">2025-04-22</time></p><p class="title"><a href="/2025/04/22/%5BOBS%5D%E7%A7%91%E7%A0%94-Detectron/">Detectron</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/22/%5BOBS%5D%E7%A7%91%E7%A0%94-FCSGG%20Repository%20Application/"><img src="/thumb/Python.png" alt="FCSGG Repository Application"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-22T10:08:07.000Z">2025-04-22</time></p><p class="title"><a href="/2025/04/22/%5BOBS%5D%E7%A7%91%E7%A0%94-FCSGG%20Repository%20Application/">FCSGG Repository Application</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/16/%5BOBS%5DTask%20Planning-Language%20Models%20as%20Zero-Shot%20Planners=%20Extracting%20Actionable%20Knowledge%20for%20Embodied%20Agents/"><img src="/thumb/LLM.png" alt="Language Models as Zero-Shot Planners= Extracting Actionable Knowledge for Embodied Agents"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-16T09:14:50.000Z">2025-04-16</time></p><p class="title"><a href="/2025/04/16/%5BOBS%5DTask%20Planning-Language%20Models%20as%20Zero-Shot%20Planners=%20Extracting%20Actionable%20Knowledge%20for%20Embodied%20Agents/">Language Models as Zero-Shot Planners= Extracting Actionable Knowledge for Embodied Agents</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/16/%5BOBS%5DReconstruct%20Anything-%E7%9B%B8%E8%BF%91%E5%B7%A5%E4%BD%9C-Vision-Language%20Interpreter%20for%20Robot%20Task%20Planning/"><img src="/thumb/Research-paper.png" alt="Vision-Language Interpreter for Robot Task Planning"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-16T06:38:13.000Z">2025-04-16</time></p><p class="title"><a href="/2025/04/16/%5BOBS%5DReconstruct%20Anything-%E7%9B%B8%E8%BF%91%E5%B7%A5%E4%BD%9C-Vision-Language%20Interpreter%20for%20Robot%20Task%20Planning/">Vision-Language Interpreter for Robot Task Planning</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/3D-Scene/"><span class="tag">3D-Scene</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/6-D/"><span class="tag">6-D</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AIGC/"><span class="tag">AIGC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AR/"><span class="tag">AR</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Academic/"><span class="tag">Academic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Aliyun/"><span class="tag">Aliyun</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/App/"><span class="tag">App</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BS4/"><span class="tag">BS4</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Beautify/"><span class="tag">Beautify</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Behaviorism/"><span class="tag">Behaviorism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Business/"><span class="tag">Business</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CADC/"><span class="tag">CADC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CD/"><span class="tag">CD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLIP/"><span class="tag">CLIP</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CV/"><span class="tag">CV</span><span class="tag">21</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Capstone/"><span class="tag">Capstone</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Communication/"><span class="tag">Communication</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Contrastive-Learning/"><span class="tag">Contrastive-Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Control/"><span class="tag">Control</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Csharp/"><span class="tag">Csharp</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Css/"><span class="tag">Css</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cuda/"><span class="tag">Cuda</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DD/"><span class="tag">DD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DINO/"><span class="tag">DINO</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DT/"><span class="tag">DT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dataframe/"><span class="tag">Dataframe</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debate/"><span class="tag">Debate</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debugger/"><span class="tag">Debugger</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Diffusion/"><span class="tag">Diffusion</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Discrete-Mathematics/"><span class="tag">Discrete-Mathematics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docs/"><span class="tag">Docs</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dynamic-programming/"><span class="tag">Dynamic-programming</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ESP32/"><span class="tag">ESP32</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Education/"><span class="tag">Education</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embeded-System/"><span class="tag">Embeded-System</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embodied-AI/"><span class="tag">Embodied-AI</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emoation/"><span class="tag">Emoation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emotion/"><span class="tag">Emotion</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ethic/"><span class="tag">Ethic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FL/"><span class="tag">FL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Family/"><span class="tag">Family</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Federated-Learning/"><span class="tag">Federated-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Foundation/"><span class="tag">Foundation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Functional-programming/"><span class="tag">Functional programming</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Game/"><span class="tag">Game</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gated-NN/"><span class="tag">Gated-NN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Github/"><span class="tag">Github</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Godot/"><span class="tag">Godot</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HPC/"><span class="tag">HPC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HRI/"><span class="tag">HRI</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Haskell/"><span class="tag">Haskell</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Health/"><span class="tag">Health</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hierarchical/"><span class="tag">Hierarchical</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Html/"><span class="tag">Html</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Humanism/"><span class="tag">Humanism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hyprland/"><span class="tag">Hyprland</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IK/"><span class="tag">IK</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Grounding/"><span class="tag">Image-Grounding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Text/"><span class="tag">Image-Text</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-generation/"><span class="tag">Image-generation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ImitationLearning/"><span class="tag">ImitationLearning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Jolt/"><span class="tag">Jolt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Json/"><span class="tag">Json</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LSP/"><span class="tag">LSP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latex/"><span class="tag">Latex</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life/"><span class="tag">Life</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinearAlgebra/"><span class="tag">LinearAlgebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Live2d/"><span class="tag">Live2d</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Love/"><span class="tag">Love</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lua/"><span class="tag">Lua</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MBTI/"><span class="tag">MBTI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MR-AR/"><span class="tag">MR/AR</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mason/"><span class="tag">Mason</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Math/"><span class="tag">Math</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Meme/"><span class="tag">Meme</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Message-Passing/"><span class="tag">Message-Passing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mod/"><span class="tag">Mod</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Motivation/"><span class="tag">Motivation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Movie/"><span class="tag">Movie</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-modal/"><span class="tag">Multi-modal</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-view/"><span class="tag">Multi-view</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Music/"><span class="tag">Music</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NN/"><span class="tag">NN</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Network/"><span class="tag">Network</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nodejs/"><span class="tag">Nodejs</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Numpy/"><span class="tag">Numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nvim/"><span class="tag">Nvim</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Object-Detection/"><span class="tag">Object-Detection</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Open-Vocabulary/"><span class="tag">Open-Vocabulary</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenCV/"><span class="tag">OpenCV</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Oral/"><span class="tag">Oral</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PHD/"><span class="tag">PHD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PSY/"><span class="tag">PSY</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pandas/"><span class="tag">Pandas</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Panoptic/"><span class="tag">Panoptic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Path/"><span class="tag">Path</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Philosophy/"><span class="tag">Philosophy</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PhysX/"><span class="tag">PhysX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Physical-Scene/"><span class="tag">Physical-Scene</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Physics-engine/"><span class="tag">Physics-engine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pio/"><span class="tag">Pio</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Planning/"><span class="tag">Planning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Plugin/"><span class="tag">Plugin</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PoseEstimation/"><span class="tag">PoseEstimation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Postgraduate/"><span class="tag">Postgraduate</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Prefab/"><span class="tag">Prefab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Probability/"><span class="tag">Probability</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">26</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/QML/"><span class="tag">QML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Quantum/"><span class="tag">Quantum</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROS/"><span class="tag">ROS</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reading/"><span class="tag">Reading</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Real2Sim/"><span class="tag">Real2Sim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reconstruct/"><span class="tag">Reconstruct</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regex/"><span class="tag">Regex</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reinforcement-learning/"><span class="tag">Reinforcement-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Repository/"><span class="tag">Repository</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation-Learning/"><span class="tag">Representation-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Research-paper/"><span class="tag">Research-paper</span><span class="tag">82</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robot/"><span class="tag">Robot</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robotics/"><span class="tag">Robotics</span><span class="tag">16</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SJTU-Lecture/"><span class="tag">SJTU-Lecture</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SSH/"><span class="tag">SSH</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scene-graph/"><span class="tag">Scene-graph</span><span class="tag">29</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scene-synthesis/"><span class="tag">Scene-synthesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Science-fiction/"><span class="tag">Science-fiction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scrap/"><span class="tag">Scrap</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Script/"><span class="tag">Script</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Segmentation/"><span class="tag">Segmentation</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Semantic/"><span class="tag">Semantic</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shader/"><span class="tag">Shader</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shell/"><span class="tag">Shell</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Signals-and-Systems/"><span class="tag">Signals and Systems</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sim2Real/"><span class="tag">Sim2Real</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sklearn/"><span class="tag">Sklearn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Snippets/"><span class="tag">Snippets</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Society/"><span class="tag">Society</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Star-rail/"><span class="tag">Star-rail</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Subgraph/"><span class="tag">Subgraph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Submodule/"><span class="tag">Submodule</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Supervised-learning/"><span class="tag">Supervised-learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Survey/"><span class="tag">Survey</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TC/"><span class="tag">TC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TOEFL/"><span class="tag">TOEFL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Task-Planning/"><span class="tag">Task-Planning</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tasks/"><span class="tag">Tasks</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tech-Communication/"><span class="tag">Tech Communication</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Torch/"><span class="tag">Torch</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Translation-Embedding/"><span class="tag">Translation-Embedding</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Travel/"><span class="tag">Travel</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unity/"><span class="tag">Unity</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unsupervised-learning/"><span class="tag">Unsupervised-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLM/"><span class="tag">VLM</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLP/"><span class="tag">VLP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Version-management/"><span class="tag">Version-management</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ViT/"><span class="tag">ViT</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VideoEditing/"><span class="tag">VideoEditing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vim/"><span class="tag">Vim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Visual-Relation/"><span class="tag">Visual-Relation</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WSL/"><span class="tag">WSL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Waybar/"><span class="tag">Waybar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wayland/"><span class="tag">Wayland</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Web/"><span class="tag">Web</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Website/"><span class="tag">Website</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Well-being/"><span class="tag">Well-being</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Window-manager/"><span class="tag">Window-manager</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/YKLL/"><span class="tag">YKLL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Zen/"><span class="tag">Zen</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%F0%9F%90%B1/"><span class="tag">🐱</span><span class="tag">1</span></a></div></div></div></div></div></div><style>.column.column-left,.column.column-right{display:block}</style></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img class="logo-img" src="/img/cyllogo.png" alt="Chen Yulin&#039;s Blog" height="28"><img class="logo-img-dark" src="/img/cyllogonight.png" alt="Chen Yulin&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 Chen Yulin</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/imaegoo/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><div class="searchbox-pinyin"><label class="checkbox"><input id="search-by-pinyin" type="checkbox" checked="checked"><span> 拼音检索</span></label></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/imaegoo/pinyin.js" defer></script><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script type="text/javascript" src="/js/imaegoo/imaegoo.js"></script><script type="text/javascript" src="/js/imaegoo/universe.js"></script><script type="text/javascript" src="/js/imaegoo/falling-petals.js"></script><!-- hexo injector body_end start -->
<link rel="stylesheet" crossorigin href="https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.css" />
<script type="module" crossorigin src="https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.js"></script>
<script>
  window.CHATBOT_CONFIG = {
    endpoint: "https://webchat-bot-iqu-knzhgrvznd.cn-hangzhou.fcapp.run/chat", // 可以替换为 https://{your-fc-http-trigger-domain}/chat
    displayByDefault: false, // 默认不展示 AI 助手聊天框
    aiChatOptions: { // aiChatOptions 中 options 会传递 aiChat 组件，自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat
      conversationOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#conversation-options
        conversationStarters: [
          {prompt: '你是谁？'},
          {prompt: '博主又是谁？'},
          {prompt: '怎么使用这个网站？'},
          {prompt: '想要博主联系方式！'},
        ]
      },
      displayOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#display-options
        height: 600,
        width: 350,
      },
      personaOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#chat-personas
        assistant: {          name: '博主的AI助手，十四行诗参上！',
          // AI 助手的图标
          avatar: 'https://chen-yulin.github.io/thumb/14.png',
          tagline: '要不要试试问下面的问题呢？',
        }
      }
    }
  };
</script>
<style>
  :root {
    /* webchat 工具栏的颜色 */
    --webchat-toolbar-background-color: #1464E4;
    /* webchat 工具栏文字和按钮的颜色 */
    --webchat-toolbar-text-color: #FFF;
  }
  /* webchat 对话框如果被遮挡，可以尝试通过 z-index、bottom、left 等设置来调整位置 */
  .webchat-container {
    z-index: 100;
    bottom: 10px;
    right: 10px;
  }
  /* webchat 的唤起按钮如果被遮挡，可以尝试通过 z-index、bottom、left 等设置来调整位置 */
  .webchat-bubble-tip {
    z-index: 99;
    bottom: 60px;
    right: 20px;
  }
  .webchat-bubble-tip {
    overflow: visible !important;
  }
  @keyframes float {
    0% {
      transform: translateY(0px) translateX(-50%);
    }
    50% {
      transform: translateY(-10px) translateX(-50%);
    }
    100% {
      transform: translateY(0px) translateX(-50%);
    }
  }

  .webchat-bubble-tip::before {
    content: '';
    position: absolute;
    top: -25px;
    left: 70%;
    width: 40px;
    height: 40px;
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='white'%3E%3Cpath d='M20 2H4c-1.1 0-2 .9-2 2v18l4-4h14c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm0 14H6l-2 2V4h16v12z'/%3E%3C/svg%3E");
    background-repeat: no-repeat;
    background-position: center;
    background-size: contain;
    filter: drop-shadow(0 4px 6px rgba(0, 0, 0, 0.5));
    animation: float 3s ease-in-out infinite;
  }
</style><script data-pjax src="https://registry.npmmirror.com/oh-my-live2d/latest/files"></script><script>const oml2d = OML2D.loadOml2d({libraryUrls:{"complete":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/complete.js","cubism2":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism2.js","cubism5":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism5.js"},dockedPosition:"left",mobileDisplay:true,models:[{"path":"https://model.hacxy.cn/mai/model.json","mobilePosition":[25,0],"mobileScale":0.1,"mobileStageStyle":{"width":125,"height":175},"motionPreloadStrategy":"ALL","position":[50,0],"scale":0.2,"stageStyle":{"width":250,"height":350}}],parentElement:document.body,primaryColor:"var(--btn-bg)",sayHello:false,tips:{style: {"width":230,"height":120,"left":"calc(50% - 20px)","top":"-100px"},mobileStyle: {"width":180,"height":80,"left":"calc(50% - 30px)","top":"-100px"},idleTips:{interval:15000,message:function(){
  return axios.get('https://v1.hitokoto.cn?c=i')
    .then(function (response) {
      return response.data.hitokoto ;
    })
    .catch(function (error) {
      console.error(error);
    });
}
}}});</script><!-- hexo injector body_end end --></body></html>