<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="theme-color" content="#123456"><title>Chen Yulin&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#6495ed"><meta name="application-name" content="Icarus - Hexo Theme"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="msapplication-TileColor" content="#6495ed"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Icarus - Hexo Theme"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Chen Yulin&#039;s Blog"><meta property="og:url" content="http://chen-yulin.github.io/"><meta property="og:site_name" content="Chen Yulin&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://chen-yulin.github.io/img/og_image.png"><meta property="article:author" content="Chen Yulin"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://chen-yulin.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://chen-yulin.github.io"},"headline":"Chen Yulin's Blog","image":["http://chen-yulin.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Chen Yulin"},"publisher":{"@type":"Organization","name":"Chen Yulin's Blog","logo":{"@type":"ImageObject","url":{"light":"/img/cyllogo.png","dark":"/img/cyllogonight.png"}}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><script type="text/javascript" src="/js/imaegoo/night.js"></script><canvas id="universe"></canvas><canvas id="flower"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img class="logo-img" src="/img/cyllogo.png" alt="Chen Yulin&#039;s Blog" height="28"><img class="logo-img-dark" src="/img/cyllogonight.png" alt="Chen Yulin&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/02/13/%5BOBS%5DTask%20Planning-ProgPrompt/"><img class="fill" src="/gallery/Research-paper.png" alt="ProgPrompt" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-13T06:04:41.000Z" title="2/13/2025, 2:04:41 PM">2025-02-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-08-27T03:37:30.021Z" title="8/27/2025, 11:37:30 AM">2025-08-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/13/%5BOBS%5DTask%20Planning-ProgPrompt/">ProgPrompt</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/01/15/%E8%AE%A9%E4%B8%80%E5%88%87%E9%9A%90%E4%BA%8E%E6%99%A6%E6%9C%94%EF%BC%8C%E5%B0%B1%E5%9C%A8%E9%82%A3%E6%9C%88%E4%B9%8B%E6%9A%97%E9%9D%A2/"><img class="fill" src="/gallery/life.png" alt="让一切隐于晦朔，就在那月之暗面" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-15T08:58:46.000Z" title="1/15/2025, 4:58:46 PM">2025-01-15</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-07-02T08:23:52.262Z" title="7/2/2025, 4:23:52 PM">2025-07-02</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%9D%82%E8%AE%B0/">杂记</a></span><span class="level-item">2 hours read (About 13544 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/15/%E8%AE%A9%E4%B8%80%E5%88%87%E9%9A%90%E4%BA%8E%E6%99%A6%E6%9C%94%EF%BC%8C%E5%B0%B1%E5%9C%A8%E9%82%A3%E6%9C%88%E4%B9%8B%E6%9A%97%E9%9D%A2/">让一切隐于晦朔，就在那月之暗面</a></p><div class="content">Here's something encrypted, password is required to continue reading.</div><a class="article-more button is-small is-size-7" href="/2025/01/15/%E8%AE%A9%E4%B8%80%E5%88%87%E9%9A%90%E4%BA%8E%E6%99%A6%E6%9C%94%EF%BC%8C%E5%B0%B1%E5%9C%A8%E9%82%A3%E6%9C%88%E4%B9%8B%E6%9A%97%E9%9D%A2/#more">Read more</a></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Moco-%20Momentum%20Contrast%20for%20Unsupervised%20Visual%20Representation%20Learning/"><img class="fill" src="/gallery/Research-paper.png" alt="Momentum Contrast for Unsupervised Visual Representation Learning" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-09T11:48:43.000Z" title="1/9/2025, 7:48:43 PM">2025-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-08-27T03:37:30.054Z" title="8/27/2025, 11:37:30 AM">2025-08-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">5 minutes read (About 722 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Moco-%20Momentum%20Contrast%20for%20Unsupervised%20Visual%20Representation%20Learning/">Momentum Contrast for Unsupervised Visual Representation Learning</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304154105.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304154105.png" alt="" title=""></a></div>
左侧是query encoder，右侧为key encoder
## 是什么
通过无监督对比学习的方法(loss:InfoNCE)来学习图像的特征。
<div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304154327.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304154327.png" alt="" title=""></a></div>
使用的pretext task是个体判别任务

<p>伪代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># f_q, f_k: encoder networks for query and key </span></span><br><span class="line"><span class="comment"># queue: dictionary as a queue of K keys (CxK) </span></span><br><span class="line"><span class="comment"># m: momentum </span></span><br><span class="line"><span class="comment"># t: temperature  </span></span><br><span class="line"></span><br><span class="line">f_k.params = f_q.params <span class="comment"># initialize </span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> loader: <span class="comment"># load a minibatch x with N samples </span></span><br><span class="line">	x_q = aug(x) <span class="comment"># a randomly augmented version </span></span><br><span class="line">	x_k = aug(x) <span class="comment"># another randomly augmented version  </span></span><br><span class="line">	q = f_q.forward(x_q) <span class="comment"># queries: NxC </span></span><br><span class="line">	k = f_k.forward(x_k) <span class="comment"># keys: NxC </span></span><br><span class="line">	k = k.detach() <span class="comment"># no gradient to keys  </span></span><br><span class="line">	</span><br><span class="line">	<span class="comment"># positive logits: Nx1 </span></span><br><span class="line">	l_pos = bmm(q.view(N,<span class="number">1</span>,C), k.view(N,C,<span class="number">1</span>))  <span class="comment"># 相当于把batch中每个正样本对之间求了cosine临近</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment"># negative logits: NxK </span></span><br><span class="line">	l_neg = mm(q.view(N,C), queue.view(C,K))  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># logits: Nx(1+K) </span></span><br><span class="line">	logits = cat([l_pos, l_neg], dim=<span class="number">1</span>)  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># contrastive loss, Eqn.(1) </span></span><br><span class="line">		labels = zeros(N) <span class="comment"># positives are the 0-th，将识别的类别视为0,可以直接使用CrossEntropyLoss</span></span><br><span class="line">	loss = CrossEntropyLoss(logits/t, labels)  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># SGD update: query network </span></span><br><span class="line">	loss.backward() </span><br><span class="line">	update(f_q.params)  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># momentum update: key network </span></span><br><span class="line">	f_k.params = m*f_k.params+(<span class="number">1</span>-m)*f_q.params  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># update dictionary </span></span><br><span class="line">	enqueue(queue, k) <span class="comment"># enqueue the current minibatch </span></span><br><span class="line">	dequeue(queue) <span class="comment"># dequeue the earliest minibatch</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="亮点"><a href="#亮点" class="headerlink" title="亮点"></a>亮点</h2><h3 id="Dictionary-as-a-queue"><a href="#Dictionary-as-a-queue" class="headerlink" title="Dictionary as a queue"></a>Dictionary as a queue</h3><p>在使用key encoder(momentum encoder)创建负样本，并把encode过的负样本存在一个queue（FIFO）中方便后续对比时直接使用，每次训练都会使用一个新的mini batch，此时会将此mini batch中的样本encode之后加入queue并删除存在最久的那个mini batch的样本（因为考虑到最老的mini batch使用的encoder是最过时的，所以FIFO是非常合理的），这样可以有效控制负样本的数量，也就是公式中的K。</p>
<ul>
<li>节省字典的计算开销</li>
<li>而且mini batch大小可以直接和负样本脱钩</li>
</ul>
<h3 id="Momentum-update"><a href="#Momentum-update" class="headerlink" title="Momentum update"></a>Momentum update</h3><p>因为负样本数量（字典&#x2F;队列）很大，所以没办法给key encoder回传梯度，所以可以考虑把query encoder的参数直接复制给key encoder，<strong>但过快改变的key encoder会导致样本字典的特征不一致</strong>，所以使用动量更新的方式。</p>
<div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304160138.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304160138.png" alt="" title=""></a></div>
> queue这个字典越大，那么理论上这个m就需要越大，保证字典中key的一致性

<h2 id="过往工作对比"><a href="#过往工作对比" class="headerlink" title="过往工作对比"></a>过往工作对比</h2><div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304160703.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304160703.png" alt="" title=""></a></div>
a)
所有的样本都在一个 mini batch 里，两个encoder完全一致，也因此都可以回传梯度，keys也高度一致，但限制了字典的大小

<p>b)<br>只有一个编码器进行学习。Memory bank存下了所有样本的key。每当梯度回传后，会把memory bank被本次训练中被采样过的key使用新的encoder进行更新。</p>
<ul>
<li>缺乏特帧一致性</li>
<li>需要训练一阵个epoch才能更新一遍memory bank</li>
</ul>
<p>MoCo和memory bank 更接近，但是使用了queue dictionary和momentum update</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-Vision%20Transformers%20Need%20Registers/"><img class="fill" src="/gallery/Research-paper.png" alt="Vision Transformers Need Registers" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-09T08:29:47.000Z" title="1/9/2025, 4:29:47 PM">2025-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-08-27T03:37:30.085Z" title="8/27/2025, 11:37:30 AM">2025-08-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-Vision%20Transformers%20Need%20Registers/">Vision Transformers Need Registers</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-DINOv2-%20Learning%20Robust%20Visual%20Features%20without%20Supervision/"><img class="fill" src="/gallery/Research-paper.png" alt="DINOv2- Learning Robust Visual Features without Supervision" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-09T08:28:49.000Z" title="1/9/2025, 4:28:49 PM">2025-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-08-27T03:37:30.063Z" title="8/27/2025, 11:37:30 AM">2025-08-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-DINOv2-%20Learning%20Robust%20Visual%20Features%20without%20Supervision/">DINOv2- Learning Robust Visual Features without Supervision</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-AN%20IMAGE%20IS%20WORTH%2016X16%20WORDS-%20TRANSFORMERS%20FOR%20IMAGE%20RECOGNITION%20AT%20SCALE/"><img class="fill" src="/gallery/Research-paper.png" alt="AN IMAGE IS WORTH 16X16 WORDS- TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-09T08:18:40.000Z" title="1/9/2025, 4:18:40 PM">2025-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-08-27T03:37:30.065Z" title="8/27/2025, 11:37:30 AM">2025-08-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 71 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-AN%20IMAGE%20IS%20WORTH%2016X16%20WORDS-%20TRANSFORMERS%20FOR%20IMAGE%20RECOGNITION%20AT%20SCALE/">AN IMAGE IS WORTH 16X16 WORDS- TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Semantic-AN IMAGE IS WORTH 16X16 WORDS- TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE/Pasted_image_20250109194820.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Semantic-AN IMAGE IS WORTH 16X16 WORDS- TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE/Pasted_image_20250109194820.png" alt="" title=""></a></div>

<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=j3VNqtJUoz0&t=16s">https://www.youtube.com/watch?v=j3VNqtJUoz0&amp;t=16s</a></p>
<p>核心思想：</p>
<ul>
<li>将图像分为patches, 线性映射, 再加上图片的position embeding来输入transformer encoder</li>
<li>额外使用一个cls token用于占位（ViT的输出就是这个cls input token对应的output token）</li>
</ul>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/01/08/%5BOBS%5DReconstruct%20Anything-Semantic-DINO/"><img class="fill" src="/gallery/Research-paper.png" alt="DINO" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-08T12:26:27.000Z" title="1/8/2025, 8:26:27 PM">2025-01-08</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-08-27T03:37:30.081Z" title="8/27/2025, 11:37:30 AM">2025-08-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">4 minutes read (About 561 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/08/%5BOBS%5DReconstruct%20Anything-Semantic-DINO/">DINO</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/dino/tree/main">https://github.com/facebookresearch/dino/tree/main</a></p>
<div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250306112727.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250306112727.png" alt="" title=""></a></div>
# Emerging Properties in Self-Supervised Vision Transformers

<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/7224738994825789496">https://juejin.cn/post/7224738994825789496</a><br><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=h3ij3F3cPIk&t=1005s">https://www.youtube.com/watch?v=h3ij3F3cPIk&amp;t=1005s</a><br>DI+NO（蒸馏+No Label）<br>具体来说，DINO 是使用一种称为“无监督自蒸馏”的方法，该方法通过自监督学习来学习模型的知识表示。在这个方法中，模型使用自身的输出来生成“伪标签”，然后使用这些伪标签来重新训练模型，从而进一步提高模型的性能和泛化能力。</p>
<h2 id="知识蒸馏"><a href="#知识蒸馏" class="headerlink" title="知识蒸馏"></a>知识蒸馏</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/xbinworld/article/details/83063726">https://blog.csdn.net/xbinworld/article/details/83063726</a></p>
<blockquote>
<p>重点idea就是提出用soft target来辅助hard target一起训练，而soft target来自于大模型的预测输出。这里有人会问，明明true label（hard target）是完全正确的，为什么还要soft target呢？<br>hard target 包含的信息量（信息熵）很低，soft target包含的信息量大，拥有不同类之间关系的信息（比如同时分类驴和马的时候，尽管某张图片是马，但是soft target就不会像hard target 那样只有马的index处的值为1，其余为0，而是在驴的部分也会有概率。）[5]<br>这样的好处是，这个图像可能更像驴，而不会去像汽车或者狗之类的，而这样的soft信息存在于概率中，以及label之间的高低相似性都存在于soft target中。但是如果soft targe是像这样的信息[0.98 0.01 0.01]，就意义不大了，所以需要在softmax中增加温度参数T（这个设置在最终训练完之后的推理中是不需要的）</p>
</blockquote>
<div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250108203323.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250108203323.png" alt="" title=""></a></div>

<h2 id="ViT"><a href="#ViT" class="headerlink" title="ViT"></a>ViT</h2><div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250109141410.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250109141410.png" alt="" title=""></a></div>


<h2 id="DINO"><a href="#DINO" class="headerlink" title="DINO"></a>DINO</h2><div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250109152153.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250109152153.png" alt="" title=""></a></div>
<div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250304154624.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250304154624.png" alt="" title=""></a></div>
总的来说DINO最适合的任务就是将不同状态的同一物体进行归类。


<p>关于DINO中发生的涌现<br><a target="_blank" rel="noopener" href="https://juejin.cn/post/7280436457142501388">https://juejin.cn/post/7280436457142501388</a></p>
<p>DINO之前的工作</p>
<div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250110172355.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250110172355.png" alt="" title=""></a></div>

<p>We have also seen emerged two properties that can be leveraged in future applications: the quality of the features in k-NN classification has a potential for image retrieval. The presence of information about the scene layout in the features can also benefit weakly supervised image segmentation.</p>
<div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250219093931.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250219093931.png" alt="" title=""></a></div></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/01/06/%5BOBS%5DReconstruct%20Anything-Semantic-CLIP%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"><img class="fill" src="/gallery/Research-paper.png" alt="CLIP" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-06T12:12:44.000Z" title="1/6/2025, 8:12:44 PM">2025-01-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-08-27T03:37:30.084Z" title="8/27/2025, 11:37:30 AM">2025-08-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a minute read (About 197 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/06/%5BOBS%5DReconstruct%20Anything-Semantic-CLIP%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">CLIP</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/01/06/[OBS]Reconstruct Anything-Semantic-CLIP多模态预训练模型/Pasted_image_20250106201326.png" title="" title=" class="gallery-item"><img src="/2025/01/06/[OBS]Reconstruct Anything-Semantic-CLIP多模态预训练模型/Pasted_image_20250106201326.png" alt="" title=""></a></div>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/h661975/article/details/135116957">https://blog.csdn.net/h661975/article/details/135116957</a></p>
<p>loss: ITC (Image Text Contrastive)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># image_encoder - ResNet or Vision Transformer </span></span><br><span class="line"><span class="comment"># text_encoder - CBOW or Text Transformer </span></span><br><span class="line"><span class="comment"># I[n, h, w, c] - minibatch of aligned images </span></span><br><span class="line"><span class="comment"># T[n, l] - minibatch of aligned texts </span></span><br><span class="line"><span class="comment"># W_i[d_i, d_e] - learned proj of image to embed </span></span><br><span class="line"><span class="comment"># W_t[d_t, d_e] - learned proj of text to embed </span></span><br><span class="line"><span class="comment"># t - learned temperature parameter  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># extract feature representations of each modality </span></span><br><span class="line">I_f = image_encoder(I) <span class="comment">#[n, d_i] </span></span><br><span class="line">T_f = text_encoder(T) <span class="comment">#[n, d_t]  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># joint multimodal embedding [n, d_e] </span></span><br><span class="line">I_e = l2_normalize(np.dot(I_f, W_i), axis=<span class="number">1</span>) T</span><br><span class="line">_e = l2_normalize(np.dot(T_f, W_t), axis=<span class="number">1</span>)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># scaled pairwise cosine similarities [n, n] </span></span><br><span class="line">logits = np.dot(I_e, T_e.T) * np.exp(t)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># symmetric loss function </span></span><br><span class="line">labels = np.arange(n) </span><br><span class="line">loss_i = cross_entropy_loss(logits, labels, axis=<span class="number">0</span>) </span><br><span class="line">loss_t = cross_entropy_loss(logits, labels, axis=<span class="number">1</span>) </span><br><span class="line">loss = (loss_i + loss_t)/<span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>Cross_entropy_loss:</p>
<div class="post-content"><a href="/2025/01/06/[OBS]Reconstruct Anything-Semantic-CLIP多模态预训练模型/Pasted_image_20250304121717.png" title="" title=" class="gallery-item"><img src="/2025/01/06/[OBS]Reconstruct Anything-Semantic-CLIP多模态预训练模型/Pasted_image_20250304121717.png" alt="" title=""></a></div>

<p>CLIP 本质上是全局图像嵌入，不利于像素对齐特征提取。</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/01/06/%5BOBS%5DReconstruct%20Anything-LERF-%20Language%20Embedded%20Radiance%20Fields/"><img class="fill" src="/gallery/LLM.png" alt="LERF- Language Embedded Radiance Fields" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-06T08:42:43.000Z" title="1/6/2025, 4:42:43 PM">2025-01-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-08-27T03:37:30.053Z" title="8/27/2025, 11:37:30 AM">2025-08-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">5 minutes read (About 790 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/06/%5BOBS%5DReconstruct%20Anything-LERF-%20Language%20Embedded%20Radiance%20Fields/">LERF- Language Embedded Radiance Fields</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/01/06/[OBS]Reconstruct Anything-LERF- Language Embedded Radiance Fields/Pasted_image_20250106164559.png" title="" title=" class="gallery-item"><img src="/2025/01/06/[OBS]Reconstruct Anything-LERF- Language Embedded Radiance Fields/Pasted_image_20250106164559.png" alt="" title=""></a></div>

<p><strong>NeRF+CLIP</strong></p>
<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul>
<li>神经辐射场 (NeRF) 已成为一种强大的技术，用于捕获复杂的现实世界 3D 场景的逼真数字表示。然而，NeRF 的直接输出只不过是一个彩色的密度场，缺乏意义或上下文，这阻碍了构建与生成的 3D 场景交互的界面。</li>
<li>自然语言是与 3D 场景交互的直观界面。考虑厨房的捕获。想象一下，能够通过询问“用具”在哪里来导航这个厨房，或者更具体地说，询问可用于“搅拌”的工具，甚至可以询问您最喜欢的带有特定功能的杯子。其上的徽标——贯穿日常对话的舒适和熟悉。这不仅需要处理自然语言输入查询的能力，还需要能够在多个尺度上合并语义并与长尾和抽象概念相关。</li>
</ul>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>一个Language Field<br>通过优化从现成的视觉语言模型（如 CLIP）到 3D 场景的嵌入，为 NeRF 中的语言奠定基础。<br>LERF 提供了一个额外的好处：由于我们从多个尺度的多个视图中提取 CLIP 嵌入，因此通过 3D CLIP 嵌入获得的文本查询的相关性图与通过 2D CLIP 嵌入获得的文本查询的相关性图相比更加本地化。根据定义，它们也是 3D 一致的，可以直接在 3D 字段中进行查询，而无需渲染到多个视图。</p>
<p>相较于Clip-Field[[CLIP-Fields- Weakly Supervised Semantic Fields for Robotic Memory]], LERF 更密集。</p>
<blockquote>
<p>CLIP-Fields [32] and NLMaps-SayCan [8] fuse CLIP embeddings of crops into pointclouds, using a contrastively supervised field and classical pointcloud fusion respectively. In CLIP-Fields, the crop locations are guided by Detic [40]. On the other hand, NLMaps-SayCan relies on region proposal networks. These maps are sparser than LERF as they primarily query CLIP on detected objects rather than densely throughout views of the scene. Concurrent work ConceptFusion [19] fuses CLIP features more densely in RGBD pointclouds, using Mask2Former [9] to predict regions of interest, meaning it can lose objects which are out of distribution to Mask2Former’s training set. In contrast, LERF does not use region or mask proposals.</p>
</blockquote>
<h2 id="LERF"><a href="#LERF" class="headerlink" title="LERF"></a>LERF</h2><h2 id="给定一组校准的输入图像，我们将-CLIP-嵌入到-NeRF-内的-3D-场中。然而，查询单个-3D-点的-CLIP-嵌入是不明确的，因为-CLIP-本质上是全局图像嵌入，不利于像素对齐特征提取。为了解释这一特性，我们提出了一种新颖的方法，该方法涉及学习以样本点为中心的卷上的语言嵌入领域。具体来说，该字段的输出是包含指定体积的图像作物的所有训练视图中的平均-CLIP-嵌入。通过将查询从点重新构造为体积，我们可以有效地从输入图像的粗裁剪中监督密集的字段，这些图像可以通过在给定的体积尺度上进行调节来以像素对齐的方式渲染。"><a href="#给定一组校准的输入图像，我们将-CLIP-嵌入到-NeRF-内的-3D-场中。然而，查询单个-3D-点的-CLIP-嵌入是不明确的，因为-CLIP-本质上是全局图像嵌入，不利于像素对齐特征提取。为了解释这一特性，我们提出了一种新颖的方法，该方法涉及学习以样本点为中心的卷上的语言嵌入领域。具体来说，该字段的输出是包含指定体积的图像作物的所有训练视图中的平均-CLIP-嵌入。通过将查询从点重新构造为体积，我们可以有效地从输入图像的粗裁剪中监督密集的字段，这些图像可以通过在给定的体积尺度上进行调节来以像素对齐的方式渲染。" class="headerlink" title="给定一组校准的输入图像，我们将 CLIP 嵌入到 NeRF 内的 3D 场中。然而，查询单个 3D 点的 CLIP 嵌入是不明确的，因为 CLIP 本质上是全局图像嵌入，不利于像素对齐特征提取。为了解释这一特性，我们提出了一种新颖的方法，该方法涉及学习以样本点为中心的卷上的语言嵌入领域。具体来说，该字段的输出是包含指定体积的图像作物的所有训练视图中的平均 CLIP 嵌入。通过将查询从点重新构造为体积，我们可以有效地从输入图像的粗裁剪中监督密集的字段，这些图像可以通过在给定的体积尺度上进行调节来以像素对齐的方式渲染。"></a>给定一组校准的输入图像，我们将 CLIP 嵌入到 NeRF 内的 3D 场中。然而，查询单个 3D 点的 CLIP 嵌入是不明确的，因为 CLIP 本质上是全局图像嵌入，不利于像素对齐特征提取。为了解释这一特性，我们提出了一种新颖的方法，该方法涉及学习以样本点为中心的卷上的语言嵌入领域。具体来说，该字段的输出是包含指定体积的图像作物的所有训练视图中的平均 CLIP 嵌入。通过将查询从点重新构造为体积，我们可以有效地从输入图像的粗裁剪中监督密集的字段，这些图像可以通过在给定的体积尺度上进行调节来以像素对齐的方式渲染。<br><div class="post-content"><a href="/2025/01/06/[OBS]Reconstruct Anything-LERF- Language Embedded Radiance Fields/Pasted_image_20250108172911.png" title="" title=" class="gallery-item"><img src="/2025/01/06/[OBS]Reconstruct Anything-LERF- Language Embedded Radiance Fields/Pasted_image_20250108172911.png" alt="" title=""></a></div></h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/amusi1994/article/details/129701012">https://blog.csdn.net/amusi1994/article/details/129701012</a></p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/01/06/%5BOBS%5DReconstruct%20Anything-Some%20Thoughts%20Regarding%20-Reconstruct%20Anything-/"><img class="fill" src="/gallery/Research-paper.png" alt="Some Thoughts Regarding -Reconstruct Anything-" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-06T07:08:28.000Z" title="1/6/2025, 3:08:28 PM">2025-01-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-08-27T03:37:30.121Z" title="8/27/2025, 11:37:30 AM">2025-08-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">3 minutes read (About 480 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/06/%5BOBS%5DReconstruct%20Anything-Some%20Thoughts%20Regarding%20-Reconstruct%20Anything-/">Some Thoughts Regarding -Reconstruct Anything-</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p>主要记录一些读场景语义化重建的论文的过程中的想法</p>
<h2 id="重要的问题"><a href="#重要的问题" class="headerlink" title="重要的问题"></a>重要的问题</h2><h3 id="多模态包含哪些任务"><a href="#多模态包含哪些任务" class="headerlink" title="多模态包含哪些任务"></a>多模态包含哪些任务</h3><ul>
<li>图文检索 Image-text Retrival</li>
<li>视觉问答 VQA</li>
<li>视觉推理 Visual Reasoning</li>
<li>视觉蕴含 Visual Entailment</li>
</ul>
<h3 id="多模态有哪些loss"><a href="#多模态有哪些loss" class="headerlink" title="多模态有哪些loss"></a>多模态有哪些loss</h3><ul>
<li>Image Text Contrastive(ITC) [[CLIP多模态预训练模型]]</li>
<li>Word Patch Aligment (WPA) used in object detection ViT</li>
<li>Image Text Matching (ITM) </li>
<li>Mask Languae Modeling (MLM) BERT 完形填空</li>
</ul>
<h3 id="给定一个具体的任务，机器人需要哪些场景信息才能顺利执行这个任务（通用机器人）"><a href="#给定一个具体的任务，机器人需要哪些场景信息才能顺利执行这个任务（通用机器人）" class="headerlink" title="给定一个具体的任务，机器人需要哪些场景信息才能顺利执行这个任务（通用机器人）"></a>给定一个具体的任务，机器人需要哪些场景信息才能顺利执行这个任务（通用机器人）</h3><p>限定：暂不考虑机器人的移动性，也就是不需要跨视野的导航(OK-Robot)，暂定为桌面机器人</p>
<p>具体来说，通用机器人的特点包括：</p>
<ol>
<li><strong>多任务能力</strong>：能够执行多种不同类型的任务，如装配、搬运、清洁、检测等。</li>
<li><strong>适应性强</strong>：具备适应多种环境和工作条件的能力，例如在不同地形或生产线中工作的能力。</li>
<li><strong>智能控制</strong>：通过先进的传感器、人工智能算法、机器学习技术等手段，能够实现自主决策和任务规划。</li>
</ol>
<ul>
<li>物体的具体形状（用于抓取, grab-anything）</li>
<li>物体语义信息（grounded caption, clip）</li>
</ul>
<h2 id="Recognize-The-Relationships-Between-Child-amp-Parent"><a href="#Recognize-The-Relationships-Between-Child-amp-Parent" class="headerlink" title="Recognize The Relationships Between Child &amp; Parent"></a>Recognize The Relationships Between Child &amp; Parent</h2><p>受DINO自蒸馏自监督的启发，可以通过物体活动的图像序列来推测物体各个部分的物理关系(attention map)[[DINO]]</p>
<p>训练集可以使用Unity生成不同的光影&#x2F;物体，连接语义</p>
<h2 id="Build-the-physics-world-in-robot-mind"><a href="#Build-the-physics-world-in-robot-mind" class="headerlink" title="Build the physics world in robot mind"></a>Build the physics world in robot mind</h2><p>voxel collider for detected objects, joints, physics agent interact with physics engine.<br>点云数据，grounded caption&#x3D;&gt;object property, hierarchy relation, joints(maybe new model should be proposed)</p>
<h2 id="语义还原物体模型"><a href="#语义还原物体模型" class="headerlink" title="语义还原物体模型"></a>语义还原物体模型</h2><p>受[[BLIP]]启发，understanding for language &amp; existing point cloud, generation for the rest of the point cloud (Wonder3D已实现)</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/6/">Previous</a></div><div class="pagination-next"><a href="/page/8/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/5/">5</a></li><li><a class="pagination-link" href="/page/6/">6</a></li><li><a class="pagination-link is-current" href="/page/7/">7</a></li><li><a class="pagination-link" href="/page/8/">8</a></li><li><a class="pagination-link" href="/page/9/">9</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/12/">12</a></li></ul></nav></div><style>.column.column-left,.column.column-right{display:none}</style><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Chen Yulin"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Chen Yulin</p><p class="is-size-6 is-block">SJTU student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Manchester by the Sea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">119</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">87</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Chen-Yulin" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/07/"><span class="level-start"><span class="level-item">July 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/05/"><span class="level-start"><span class="level-item">May 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/04/"><span class="level-start"><span class="level-item">April 2025</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">March 2025</span></span><span class="level-end"><span class="level-item tag">40</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">February 2025</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item">January 2025</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">December 2024</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/11/"><span class="level-start"><span class="level-item">November 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/07/"><span class="level-start"><span class="level-item">July 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">June 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/05/"><span class="level-start"><span class="level-item">May 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/04/"><span class="level-start"><span class="level-item">April 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/2025/07/02/%E2%99%A5%E5%A4%8F%E5%A4%A9%E5%92%8C%E6%B3%A2%E5%AD%90%E6%B1%BD%E6%B0%B4%E6%98%AF%E7%BB%9D%E9%85%8D%E2%99%A5/"><img src="/thumb/Sufei.png" alt="♥夏天和波子汽水是绝配♥"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-07-02T08:20:44.000Z">2025-07-02</time></p><p class="title"><a href="/2025/07/02/%E2%99%A5%E5%A4%8F%E5%A4%A9%E5%92%8C%E6%B3%A2%E5%AD%90%E6%B1%BD%E6%B0%B4%E6%98%AF%E7%BB%9D%E9%85%8D%E2%99%A5/">♥夏天和波子汽水是绝配♥</a></p><p class="categories"><a href="/categories/%E7%94%9C%E7%94%9C%E7%9A%84%E6%81%8B%E7%88%B1%E6%97%A5%E5%B8%B8%E5%91%80/">甜甜的恋爱日常呀</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/08/%5BOBS%5DDeep%20Learning-CV-Feature%20Pyramid%20Networks%20for%20Object%20Detection/"><img src="/thumb/Research-paper.png" alt="Feature Pyramid Networks for Object Detection"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-05-08T11:39:38.000Z">2025-05-08</time></p><p class="title"><a href="/2025/05/08/%5BOBS%5DDeep%20Learning-CV-Feature%20Pyramid%20Networks%20for%20Object%20Detection/">Feature Pyramid Networks for Object Detection</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/06/%5BOBS%5DDeep%20Learning-CV-Deformable%20Convolutional%20Networks/"><img src="/thumb/Research-paper.png" alt="Deformable Convolutional Networks"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-05-06T03:55:36.000Z">2025-05-06</time></p><p class="title"><a href="/2025/05/06/%5BOBS%5DDeep%20Learning-CV-Deformable%20Convolutional%20Networks/">Deformable Convolutional Networks</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/24/%5BOBS%5DDeep%20Learning-CV-Associative%20Embedding=%20End-to-End%20Learning%20for%20Joint%20Detection%20and%20Grouping/"><img src="/thumb/Research-paper.png" alt="Associative Embedding= End-to-End Learning for Joint Detection and Grouping"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-24T03:00:20.000Z">2025-04-24</time></p><p class="title"><a href="/2025/04/24/%5BOBS%5DDeep%20Learning-CV-Associative%20Embedding=%20End-to-End%20Learning%20for%20Joint%20Detection%20and%20Grouping/">Associative Embedding= End-to-End Learning for Joint Detection and Grouping</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/24/%5BOBS%5DDeep%20Learning-CV-CenterNet/"><img src="/thumb/Research-paper.png" alt="CenterNet"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-24T02:29:51.000Z">2025-04-24</time></p><p class="title"><a href="/2025/04/24/%5BOBS%5DDeep%20Learning-CV-CenterNet/">CenterNet</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/3D-Scene/"><span class="tag">3D-Scene</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CADC/"><span class="tag">CADC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLIP/"><span class="tag">CLIP</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CV/"><span class="tag">CV</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Contrastive-Learning/"><span class="tag">Contrastive-Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Csharp/"><span class="tag">Csharp</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DINO/"><span class="tag">DINO</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DT/"><span class="tag">DT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debate/"><span class="tag">Debate</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Diffusion/"><span class="tag">Diffusion</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Discrete-Mathematics/"><span class="tag">Discrete-Mathematics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embodied-AI/"><span class="tag">Embodied-AI</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emoation/"><span class="tag">Emoation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emotion/"><span class="tag">Emotion</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FL/"><span class="tag">FL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FPN/"><span class="tag">FPN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Foundation/"><span class="tag">Foundation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Functional-programming/"><span class="tag">Functional programming</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Game/"><span class="tag">Game</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gated-NN/"><span class="tag">Gated-NN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Github/"><span class="tag">Github</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HRI/"><span class="tag">HRI</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Haskell/"><span class="tag">Haskell</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hierarchical/"><span class="tag">Hierarchical</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Html/"><span class="tag">Html</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Grounding/"><span class="tag">Image-Grounding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Text/"><span class="tag">Image-Text</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-generation/"><span class="tag">Image-generation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ImitationLearning/"><span class="tag">ImitationLearning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latex/"><span class="tag">Latex</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Love/"><span class="tag">Love</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MR-AR/"><span class="tag">MR/AR</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Message-Passing/"><span class="tag">Message-Passing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mod/"><span class="tag">Mod</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-modal/"><span class="tag">Multi-modal</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-view/"><span class="tag">Multi-view</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NN/"><span class="tag">NN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nodejs/"><span class="tag">Nodejs</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Object-Detection/"><span class="tag">Object-Detection</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Open-Vocabulary/"><span class="tag">Open-Vocabulary</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenCV/"><span class="tag">OpenCV</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Panoptic/"><span class="tag">Panoptic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Physical-Scene/"><span class="tag">Physical-Scene</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Plugin/"><span class="tag">Plugin</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PoseEstimation/"><span class="tag">PoseEstimation</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Probability/"><span class="tag">Probability</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/QML/"><span class="tag">QML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Quantum/"><span class="tag">Quantum</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROS/"><span class="tag">ROS</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reading/"><span class="tag">Reading</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Real2Sim/"><span class="tag">Real2Sim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reconstruct/"><span class="tag">Reconstruct</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation-Learning/"><span class="tag">Representation-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Research-paper/"><span class="tag">Research-paper</span><span class="tag">86</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robotics/"><span class="tag">Robotics</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SJTU-Lecture/"><span class="tag">SJTU-Lecture</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scene-graph/"><span class="tag">Scene-graph</span><span class="tag">28</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scene-synthesis/"><span class="tag">Scene-synthesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Segmentation/"><span class="tag">Segmentation</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Semantic/"><span class="tag">Semantic</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Signals-and-Systems/"><span class="tag">Signals and Systems</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sim2Real/"><span class="tag">Sim2Real</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Snippets/"><span class="tag">Snippets</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Subgraph/"><span class="tag">Subgraph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Survey/"><span class="tag">Survey</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Task-Planning/"><span class="tag">Task-Planning</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tech-Communication/"><span class="tag">Tech Communication</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Translation-Embedding/"><span class="tag">Translation-Embedding</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Travel/"><span class="tag">Travel</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unity/"><span class="tag">Unity</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLM/"><span class="tag">VLM</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLP/"><span class="tag">VLP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ViT/"><span class="tag">ViT</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vim/"><span class="tag">Vim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Visual-Relation/"><span class="tag">Visual-Relation</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WSL/"><span class="tag">WSL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Web/"><span class="tag">Web</span><span class="tag">1</span></a></div></div></div></div></div></div><style>.column.column-left,.column.column-right{display:block}</style></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img class="logo-img" src="/img/cyllogo.png" alt="Chen Yulin&#039;s Blog" height="28"><img class="logo-img-dark" src="/img/cyllogonight.png" alt="Chen Yulin&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 Chen Yulin</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/imaegoo/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><div class="searchbox-pinyin"><label class="checkbox"><input id="search-by-pinyin" type="checkbox" checked="checked"><span> 拼音检索</span></label></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/imaegoo/pinyin.js" defer></script><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script type="text/javascript" src="/js/imaegoo/imaegoo.js"></script><script type="text/javascript" src="/js/imaegoo/universe.js"></script><script type="text/javascript" src="/js/imaegoo/falling-petals.js"></script><!-- hexo injector body_end start -->
<link rel="stylesheet" crossorigin href="https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.css" />
<script type="module" crossorigin src="https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.js"></script>
<script>
  window.CHATBOT_CONFIG = {
    endpoint: "https://webchat-bot-iqu-knzhgrvznd.cn-hangzhou.fcapp.run/chat", // 可以替换为 https://{your-fc-http-trigger-domain}/chat
    displayByDefault: false, // 默认不展示 AI 助手聊天框
    aiChatOptions: { // aiChatOptions 中 options 会传递 aiChat 组件，自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat
      conversationOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#conversation-options
        conversationStarters: [
          {prompt: '你是谁？'},
          {prompt: '博主又是谁？'},
          {prompt: '怎么使用这个网站？'},
          {prompt: '想要博主联系方式！'},
        ]
      },
      displayOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#display-options
        height: 600,
        width: 350,
      },
      personaOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#chat-personas
        assistant: {          name: '博主的AI助手，十四行诗参上！',
          // AI 助手的图标
          avatar: 'https://chen-yulin.github.io/thumb/14.png',
          tagline: '要不要试试问下面的问题呢？',
        }
      }
    }
  };
</script>
<style>
  :root {
    /* webchat 工具栏的颜色 */
    --webchat-toolbar-background-color: #1464E4;
    /* webchat 工具栏文字和按钮的颜色 */
    --webchat-toolbar-text-color: #FFF;
  }
  /* webchat 对话框如果被遮挡，可以尝试通过 z-index、bottom、left 等设置来调整位置 */
  .webchat-container {
    z-index: 100;
    bottom: 10px;
    right: 10px;
  }
  /* webchat 的唤起按钮如果被遮挡，可以尝试通过 z-index、bottom、left 等设置来调整位置 */
  .webchat-bubble-tip {
    z-index: 99;
    bottom: 60px;
    right: 20px;
  }
  .webchat-bubble-tip {
    overflow: visible !important;
  }
  @keyframes float {
    0% {
      transform: translateY(0px) translateX(-50%);
    }
    50% {
      transform: translateY(-10px) translateX(-50%);
    }
    100% {
      transform: translateY(0px) translateX(-50%);
    }
  }

  .webchat-bubble-tip::before {
    content: '';
    position: absolute;
    top: -25px;
    left: 70%;
    width: 40px;
    height: 40px;
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='white'%3E%3Cpath d='M20 2H4c-1.1 0-2 .9-2 2v18l4-4h14c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm0 14H6l-2 2V4h16v12z'/%3E%3C/svg%3E");
    background-repeat: no-repeat;
    background-position: center;
    background-size: contain;
    filter: drop-shadow(0 4px 6px rgba(0, 0, 0, 0.5));
    animation: float 3s ease-in-out infinite;
  }
</style><script data-pjax src="https://registry.npmmirror.com/oh-my-live2d/latest/files"></script><script>const oml2d = OML2D.loadOml2d({libraryUrls:{"complete":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/complete.js","cubism2":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism2.js","cubism5":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism5.js"},dockedPosition:"left",mobileDisplay:true,models:[{"path":"https://model.hacxy.cn/mai/model.json","mobilePosition":[25,0],"mobileScale":0.1,"mobileStageStyle":{"width":125,"height":175},"motionPreloadStrategy":"ALL","position":[50,0],"scale":0.2,"stageStyle":{"width":250,"height":350}}],parentElement:document.body,primaryColor:"var(--btn-bg)",sayHello:false,tips:{style: {"width":230,"height":120,"left":"calc(50% - 20px)","top":"-100px"},mobileStyle: {"width":180,"height":80,"left":"calc(50% - 30px)","top":"-100px"},idleTips:{interval:15000,message:function(){
  return axios.get('https://v1.hitokoto.cn?c=i')
    .then(function (response) {
      return response.data.hitokoto ;
    })
    .catch(function (error) {
      console.error(error);
    });
}
}}});</script><!-- hexo injector body_end end --></body></html>