<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="theme-color" content="#123456"><title>Chen Yulin&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#6495ed"><meta name="application-name" content="Icarus - Hexo Theme"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="msapplication-TileColor" content="#6495ed"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Icarus - Hexo Theme"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Chen Yulin&#039;s Blog"><meta property="og:url" content="http://chen-yulin.github.io/"><meta property="og:site_name" content="Chen Yulin&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://chen-yulin.github.io/img/og_image.png"><meta property="article:author" content="Chen Yulin"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://chen-yulin.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://chen-yulin.github.io"},"headline":"Chen Yulin's Blog","image":["http://chen-yulin.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Chen Yulin"},"publisher":{"@type":"Organization","name":"Chen Yulin's Blog","logo":{"@type":"ImageObject","url":{"light":"/img/cyllogo.png","dark":"/img/cyllogonight.png"}}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><svg style="position:absolute;width:0;height:0;" aria-hidden="true"><defs><filter id="liquid-glass-sm" x="-10%" y="-10%" width="120%" height="120%"><feTurbulence type="fractalNoise" baseFrequency="0.015" numOctaves="2" result="noise" seed="5"></feTurbulence><feDisplacementMap in="SourceGraphic" in2="noise" scale="2" xchannelselector="R" ychannelselector="G"></feDisplacementMap></filter></defs></svg><script type="text/javascript" src="/js/imaegoo/night.js"></script><canvas id="universe"></canvas><canvas id="flower"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img class="logo-img" src="/img/cyllogo.png" alt="Chen Yulin&#039;s Blog" height="28"><img class="logo-img-dark" src="/img/cyllogonight.png" alt="Chen Yulin&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><a class="image is-7by3" href="/2026/02/03/%5BOBS%5DDeep%20Learning-CV-Diffusion-Transformers-DiT/"><img class="fill" src="/gallery/Research-paper.png" alt="Scalable Diffusion Models with Transformers" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2026-02-03T11:30:00.000Z" title="2/3/2026, 7:30:00 PM">2026-02-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2026-02-14T13:40:28.509Z" title="2/14/2026, 9:40:28 PM">2026-02-14</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">18 minutes read (About 2709 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/03/%5BOBS%5DDeep%20Learning-CV-Diffusion-Transformers-DiT/">Scalable Diffusion Models with Transformers</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2026/02/03/[OBS]Deep Learning-CV-Diffusion-Transformers-DiT/Pasted_image_20260203120620.png" title="" title=" class="gallery-item"><img src="/2026/02/03/[OBS]Deep Learning-CV-Diffusion-Transformers-DiT/Pasted_image_20260203120620.png" alt="" title=""></a></div>
# Diffusion Transformers (DiT)

<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2212.09748">Scalable Diffusion Models with Transformers</a> | ICCV 2023</p>
<hr>
<h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>扩散模型(Diffusion Models)在图像生成领域取得了显著成功，但其架构设计一直沿用卷积U-Net作为主干网络。与此同时，Transformer架构已经在自然语言处理、视觉识别等多个领域取得了统治地位，并展现出优秀的可扩展性。本文探索将Transformer架构引入扩散模型，研究其在图像生成任务中的可扩展性和性能表现。</p>
<hr>
<h2 id="研究目标"><a href="#研究目标" class="headerlink" title="研究目标"></a>研究目标</h2><ul>
<li><strong>突破架构局限</strong>：探索用Transformer替代传统U-Net作为扩散模型主干的可行性</li>
<li><strong>验证可扩展性</strong>：研究Transformer在扩散模型中的可扩展性规律</li>
<li><strong>建立性能基准</strong>：在ImageNet等基准数据集上达到SOTA性能</li>
<li><strong>揭示计算-质量关系</strong>：分析模型计算量(Gflops)与生成质量之间的关系</li>
</ul>
<hr>
<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="Latent-Diffusion-Models-LDMs"><a href="#Latent-Diffusion-Models-LDMs" class="headerlink" title="Latent Diffusion Models (LDMs)"></a>Latent Diffusion Models (LDMs)</h3><p>在潜在空间而非像素空间训练扩散模型，提高计算效率：</p>
<ol>
<li><strong>VAE编码器</strong>：将图像压缩到潜在空间 $z &#x3D; E(x)$</li>
<li><strong>扩散模型</strong>：在潜在空间 $z$ 中训练</li>
<li><strong>VAE解码器</strong>：将生成的潜在表示解码为图像 $x &#x3D; D(z)$</li>
</ol>
<p>对于256×256×3的图像，VAE将其压缩为32×32×4的潜在表示（下采样因子为8）。</p>
<p><strong>注意</strong>：这里使用的是标准VAE，输出是<strong>连续的潜在表示</strong>，而非VQ-VAE的离散codebook索引。</p>
<h3 id="Patchify机制"><a href="#Patchify机制" class="headerlink" title="Patchify机制"></a>Patchify机制</h3><p>将潜在表示分解为patch序列：</p>
<ul>
<li>输入：32×32×4的潜在表示</li>
<li>Patch大小：$p \times p$（$p \in {2, 4, 8}$）</li>
<li>输出序列长度：$T &#x3D; (I&#x2F;p)^2$</li>
</ul>
<p>例如，$p&#x3D;2$ 时，序列长度 $T &#x3D; (32&#x2F;2)^2 &#x3D; 256$。</p>
<h3 id="Classifier-Free-Guidance"><a href="#Classifier-Free-Guidance" class="headerlink" title="Classifier-Free Guidance"></a>Classifier-Free Guidance</h3><p>条件生成的采样技巧，提高生成质量：</p>
<p>$$<br>\hat{\epsilon}_\theta(x_t, c) &#x3D; \epsilon_\theta(x_t, \emptyset) + s \cdot (\epsilon_\theta(x_t, c) - \epsilon_\theta(x_t, \emptyset))<br>$$</p>
<p>其中：</p>
<ul>
<li>$c$：条件信息（如类别标签）</li>
<li>$\emptyset$：空条件（训练时随机dropout）</li>
<li>$s$：guidance scale（$s &gt; 1$增强条件控制）</li>
</ul>
<hr>
<h2 id="研究方法"><a href="#研究方法" class="headerlink" title="研究方法"></a>研究方法</h2><h3 id="DiT架构设计"><a href="#DiT架构设计" class="headerlink" title="DiT架构设计"></a>DiT架构设计</h3><p>DiT基于Vision Transformer (ViT)架构，包含以下组件：</p>
<ol>
<li><strong>Patchify层</strong>：将潜在表示转换为token序列</li>
<li><strong>位置编码</strong>：使用正弦-余弦位置编码</li>
<li><strong>DiT Blocks</strong>：N个Transformer block</li>
<li><strong>解码器</strong>：将token序列解码为噪声预测和协方差预测</li>
</ol>
<h3 id="条件注入机制"><a href="#条件注入机制" class="headerlink" title="条件注入机制"></a>条件注入机制</h3><p>探索了四种将时间步 $t$ 和类别标签 $c$ 注入Transformer的方式：</p>
<h4 id="1-In-Context-Conditioning"><a href="#1-In-Context-Conditioning" class="headerlink" title="1. In-Context Conditioning"></a>1. In-Context Conditioning</h4><p>将 $t$ 和 $c$ 的embedding作为额外token添加到序列中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokens = [t_embed, c_embed, patch_1, patch_2, ..., patch_T]</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>优点</strong>：无需修改标准Transformer block</li>
<li><strong>缺点</strong>：性能较差（FID ~80）</li>
</ul>
<h4 id="2-Cross-Attention"><a href="#2-Cross-Attention" class="headerlink" title="2. Cross-Attention"></a>2. Cross-Attention</h4><p>通过交叉注意力机制注入条件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标准self-attention后添加cross-attention</span></span><br><span class="line">x = x + SelfAttention(x)</span><br><span class="line">x = x + CrossAttention(x, [t_embed, c_embed])</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>优点</strong>：灵活的条件控制</li>
<li><strong>缺点</strong>：增加15%计算量，性能中等（FID ~60）</li>
</ul>
<h4 id="3-Adaptive-Layer-Norm-adaLN"><a href="#3-Adaptive-Layer-Norm-adaLN" class="headerlink" title="3. Adaptive Layer Norm (adaLN)"></a>3. Adaptive Layer Norm (adaLN)</h4><p>通过自适应归一化层注入条件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">γ, β = MLP(t_embed + c_embed)</span><br><span class="line">output = γ * normalize(x) + β</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>优点</strong>：计算高效，性能较好（FID ~45）</li>
<li><strong>缺点</strong>：所有token共享���同的调制参数</li>
</ul>
<h4 id="4-adaLN-Zero（最优方案）"><a href="#4-adaLN-Zero（最优方案）" class="headerlink" title="4. adaLN-Zero（最优方案）"></a>4. adaLN-Zero（最优方案）</h4><p>在adaLN基础上增加门控参数并零初始化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">γ, β, α = MLP(t_embed + c_embed)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Transformer Block</span></span><br><span class="line">x = x + α₁ * Attention(γ₁ * normalize(x) + β₁)</span><br><span class="line">x = x + α₂ * FFN(γ₂ * normalize(x) + β₂)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化：MLP输出零向量 → α=0, γ=0, β=0</span></span><br><span class="line"><span class="comment"># 因此初始时：x = x + 0 = x（恒等函数）</span></span><br></pre></td></tr></table></figure>

<p><strong>为什么需要两组参数？</strong></p>
<p>Transformer block有两个子层（Attention + FFN），每个子层需要独立的条件控制：</p>
<ul>
<li>第一组 $(γ_1, β_1, α_1)$：用于Attention子层</li>
<li>第二组 $(γ_2, β_2, α_2)$：用于FFN子层</li>
</ul>
<p>总共6个参数：<code>shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp</code></p>
<p><strong>零初始化的优势</strong>：</p>
<ul>
<li>训练稳定性：初始时网络是恒等映射，梯度流动顺畅</li>
<li>更好的性能：FID显著优于其他方法（FID ~23）</li>
<li>渐进式学习：从恒等函数开始，逐步学习有用的变换</li>
</ul>
<h3 id="模型配置"><a href="#模型配置" class="headerlink" title="模型配置"></a>模型配置</h3><p>设计四种规模的模型配置：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>层数N</th>
<th>隐藏维度d</th>
<th>注意力头数</th>
<th>Gflops (p&#x3D;4)</th>
</tr>
</thead>
<tbody><tr>
<td>DiT-S</td>
<td>12</td>
<td>384</td>
<td>6</td>
<td>1.4</td>
</tr>
<tr>
<td>DiT-B</td>
<td>12</td>
<td>768</td>
<td>12</td>
<td>5.6</td>
</tr>
<tr>
<td>DiT-L</td>
<td>24</td>
<td>1024</td>
<td>16</td>
<td>19.7</td>
</tr>
<tr>
<td>DiT-XL</td>
<td>28</td>
<td>1152</td>
<td>16</td>
<td>29.1</td>
</tr>
</tbody></table>
<h3 id="Point-wise-FFN"><a href="#Point-wise-FFN" class="headerlink" title="Point-wise FFN"></a>Point-wise FFN</h3><p>Transformer中的标准组件，对序列中每个位置独立应用前馈网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PointwiseFeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># x: [batch, seq_len, d_model]</span></span><br><span class="line">        x = Linear1(x)      <span class="comment"># d_model → d_ff (通常4倍扩展)</span></span><br><span class="line">        x = GELU(x)</span><br><span class="line">        x = Linear2(x)      <span class="comment"># d_ff → d_model</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关键特点：</span></span><br><span class="line"><span class="comment"># 1. 每个token独立处理（point-wise）</span></span><br><span class="line"><span class="comment"># 2. 所有位置共享相同的权重</span></span><br><span class="line"><span class="comment"># 3. 可以完全并行计算</span></span><br></pre></td></tr></table></figure>

<p><strong>与Self-Attention的分工</strong>：</p>
<ul>
<li>Self-Attention：全局信息聚合（不同token间交互）</li>
<li>Point-wise FFN：局部特征变换（每个token独立处理）</li>
</ul>
<p>这是<strong>所有Transformer变体</strong>（LLM、ViT、DiT）的统一设计。</p>
<hr>
<h2 id="主要发现"><a href="#主要发现" class="headerlink" title="主要发现"></a>主要发现</h2><h3 id="1-Gflops与生成质量强相关"><a href="#1-Gflops与生成质量强相关" class="headerlink" title="1. Gflops与生成质量强相关"></a>1. Gflops与生成质量强相关</h3><p>模型前向传播的计算量(Gflops)与FID呈强负相关（相关系数-0.93）：</p>
<ul>
<li>增加模型深度&#x2F;宽度 → 提升Gflops → 降低FID</li>
<li>减小patch大小 → 增加token数量 → 提升Gflops → 降低FID</li>
</ul>
<p><strong>关键洞察</strong>：参数量不是���一决定因素，计算量才是提升性能的关键。</p>
<h3 id="2-adaLN-Zero显著优于其他条件注入方式"><a href="#2-adaLN-Zero显著优于其他条件注入方式" class="headerlink" title="2. adaLN-Zero显著优于其他条件注入方式"></a>2. adaLN-Zero显著优于其他条件注入方式</h3><p>在400K训练步数时的FID对比：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>FID-50K</th>
<th>计算开销</th>
</tr>
</thead>
<tbody><tr>
<td>In-Context</td>
<td>~80</td>
<td>119.4 Gflops</td>
</tr>
<tr>
<td>Cross-Attention</td>
<td>~60</td>
<td>137.6 Gflops</td>
</tr>
<tr>
<td>adaLN</td>
<td>~45</td>
<td>118.6 Gflops</td>
</tr>
<tr>
<td><strong>adaLN-Zero</strong></td>
<td><strong>~23</strong></td>
<td><strong>118.6 Gflops</strong></td>
</tr>
</tbody></table>
<h3 id="3-优秀的可扩展性"><a href="#3-优秀的可扩展性" class="headerlink" title="3. 优秀的可扩展性"></a>3. 优秀的可扩展性</h3><p>DiT展现出与ViT类似的可扩展性：</p>
<ul>
<li>增加模型规模持续提升性能</li>
<li>训练高度稳定，无需学习率预热或特殊正则化</li>
<li>未观察到常见的loss spike现象</li>
</ul>
<h3 id="4-计算效率优势"><a href="#4-计算效率优势" class="headerlink" title="4. 计算效率优势"></a>4. 计算效率优势</h3><p>DiT-XL&#x2F;2 (118.6 Gflops) 比传统方法更高效：</p>
<ul>
<li>像素空间U-Net (ADM)：1120 Gflops（~10倍）</li>
<li>潜在空间U-Net (LDM-4)：103.6 Gflops（相近但性能更优）</li>
</ul>
<h3 id="5-采样计算无法弥补模型计算不足"><a href="#5-采样计算无法弥补模型计算不足" class="headerlink" title="5. 采样计算无法弥补模型计算不足"></a>5. 采样计算无法弥补模型计算不足</h3><p>增加采样步数（增加测试时计算量）无法弥补模型规模不足：</p>
<ul>
<li>DiT-L&#x2F;2 使用1000步采样：80.7 Tflops，FID&#x3D;25.9</li>
<li>DiT-XL&#x2F;2 使用128步采样：15.2 Tflops，FID&#x3D;23.7</li>
</ul>
<p><strong>结论</strong>：模型计算量比采样计算量更重要。</p>
<hr>
<h2 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><ul>
<li><strong>ImageNet</strong>：256×256和512×512分辨率</li>
<li><strong>任务</strong>：类条件图像生成</li>
</ul>
<h3 id="训练配置"><a href="#训练配置" class="headerlink" title="训练配置"></a>训练配置</h3><ul>
<li><strong>优化器</strong>：AdamW</li>
<li><strong>学习率</strong>：$1 \times 10^{-4}$（常数，无warmup）</li>
<li><strong>批大小</strong>：256</li>
<li><strong>数据增强</strong>：仅水平翻转</li>
<li><strong>EMA</strong>：decay&#x3D;0.9999</li>
<li><strong>硬件</strong>：TPU v3-256 pod</li>
</ul>
<h3 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h3><ul>
<li><strong>主要指标</strong>：FID-50K（使用250步DDPM采样）</li>
<li><strong>次要指标</strong>：Inception Score、sFID、Precision&#x2F;Recall</li>
</ul>
<h3 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h3><p><strong>ImageNet 256×256基准测试</strong>：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>FID↓</th>
<th>IS↑</th>
<th>Precision</th>
<th>Recall</th>
</tr>
</thead>
<tbody><tr>
<td>LDM-4-G (cfg&#x3D;1.50)</td>
<td>3.60</td>
<td>247.67</td>
<td>0.87</td>
<td>0.48</td>
</tr>
<tr>
<td>StyleGAN-XL</td>
<td>2.30</td>
<td>265.12</td>
<td>0.78</td>
<td>0.53</td>
</tr>
<tr>
<td><strong>DiT-XL&#x2F;2-G (cfg&#x3D;1.50)</strong></td>
<td><strong>2.27</strong></td>
<td><strong>278.24</strong></td>
<td><strong>0.83</strong></td>
<td><strong>0.57</strong></td>
</tr>
</tbody></table>
<p><strong>ImageNet 512×512基准测试</strong>：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>FID↓</th>
<th>IS↑</th>
</tr>
</thead>
<tbody><tr>
<td>ADM-G, ADM-U</td>
<td>3.85</td>
<td>221.72</td>
</tr>
<tr>
<td><strong>DiT-XL&#x2F;2-G (cfg&#x3D;1.50)</strong></td>
<td><strong>3.04</strong></td>
<td><strong>240.82</strong></td>
</tr>
</tbody></table>
<p>DiT-XL&#x2F;2在两个分辨率上都达到了<strong>SOTA性能</strong>。</p>
<hr>
<h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ul>
<li><strong>架构统一性</strong>：证明Transformer可以成功替代U-Net，推动生成模型架构统一化</li>
<li><strong>优秀的可扩展性</strong>：计算量与性能呈强相关，为大规模模型发展指明方向</li>
<li><strong>训练稳定性</strong>：无需特殊技巧即可稳定训练</li>
<li><strong>计算效率</strong>：在相近或更少的计算量下达到更好的性能</li>
<li><strong>更高的Recall</strong>：相比LDM，DiT在所有guidance scale下都有更高的recall值</li>
</ul>
<h3 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h3><ul>
<li><strong>依赖预训练VAE</strong>：使用Stable Diffusion的VAE，是混合架构而非纯Transformer</li>
<li><strong>仅探索类条件生成</strong>：未涉及文生图等更复杂的条件生成任务</li>
<li><strong>计算资源需求</strong>：大规模模型训练需要TPU集群</li>
<li><strong>patch大小的权衡</strong>：更小的patch提升性能但增加计算量</li>
</ul>
<h3 id="与传统U-Net的对比"><a href="#与传统U-Net的对比" class="headerlink" title="与传统U-Net的对比"></a>与传统U-Net的对比</h3><table>
<thead>
<tr>
<th>特性</th>
<th>U-Net</th>
<th>DiT</th>
</tr>
</thead>
<tbody><tr>
<td>归纳偏置</td>
<td>强（卷积、多尺度）</td>
<td>弱（纯注意力）</td>
</tr>
<tr>
<td>可扩展性</td>
<td>有限</td>
<td>优秀</td>
</tr>
<tr>
<td>架构统一性</td>
<td>领域特定</td>
<td>跨领域通用</td>
</tr>
<tr>
<td>训练稳定性</td>
<td>需要技巧</td>
<td>天然稳定</td>
</tr>
</tbody></table>
<hr>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><h3 id="Transformer在生成模型中的应用"><a href="#Transformer在生成模型中的应用" class="headerlink" title="Transformer在生成模型中的应用"></a>Transformer在生成模型中的应用</h3><ul>
<li><strong>自回归模型</strong>：GPT系列、ImageGPT、DALL·E</li>
<li><strong>掩码生成模型</strong>：MaskGIT、MAGE</li>
<li><strong>DALL·E 2</strong>：使用Transformer生成CLIP embedding</li>
</ul>
<h3 id="扩散模型架构"><a href="#扩散模型架构" class="headerlink" title="扩散模型架构"></a>扩散模型架构</h3><ul>
<li><strong>DDPM</strong> (Ho et al., 2020)：首次引入U-Net作为扩散模型主干</li>
<li><strong>ADM</strong> (Dhariwal &amp; Nichol, 2021)：改进U-Net设计，达到SOTA</li>
<li><strong>LDM</strong> (Rombach et al., 2022)：潜在空间扩散模型</li>
<li><strong>Concurrent work</strong>：U-ViT探索了类似的Transformer架构</li>
</ul>
<h3 id="架构复杂度分析"><a href="#架构复杂度分析" class="headerlink" title="架构复杂度分析"></a>架构复杂度分析</h3><ul>
<li><strong>ViT</strong> (Dosovitskiy et al., 2021)：证明Transformer在视觉任务中的可扩展性</li>
<li><strong>Scaling Laws</strong>：语言模型中计算量与性能的幂律关系</li>
</ul>
<hr>
<h2 id="未来方向"><a href="#未来方向" class="headerlink" title="未来方向"></a>未来方向</h2><ol>
<li><strong>扩展到文生图任务</strong>：将DiT应用于DALL·E 2、Stable Diffusion等文生图模型</li>
<li><strong>���大规模的模型</strong>：继续扩展模型规模，探索scaling law</li>
<li><strong>纯Transformer架构</strong>：在像素空间训练DiT，摆脱VAE依赖</li>
<li><strong>多模态条件生成</strong>：探索更复杂的条件注入机制</li>
<li><strong>高效采样方法</strong>：结合DiT开发更快的采样算法</li>
<li><strong>架构搜索</strong>：自动化探索最优的DiT配置</li>
</ol>
<hr>
<h2 id="技术细节补充"><a href="#技术细节补充" class="headerlink" title="技术细节补充"></a>技术细节补充</h2><h3 id="VAE-vs-VQ-VAE"><a href="#VAE-vs-VQ-VAE" class="headerlink" title="VAE vs VQ-VAE"></a>VAE vs VQ-VAE</h3><table>
<thead>
<tr>
<th>特性</th>
<th>VAE (DiT使用)</th>
<th>VQ-VAE</th>
</tr>
</thead>
<tbody><tr>
<td>潜在空间</td>
<td>连续（浮点数）</td>
<td>离散（codebook索引）</td>
</tr>
<tr>
<td>输出维度</td>
<td>32×32×4（4通道特征）</td>
<td>32×32（单个索引）</td>
</tr>
<tr>
<td>适用场景</td>
<td>扩散模型</td>
<td>自回归模型</td>
</tr>
<tr>
<td>量化</td>
<td>无</td>
<td>有（查表）</td>
</tr>
</tbody></table>
<h3 id="Transformer-Block完整结构"><a href="#Transformer-Block完整结构" class="headerlink" title="Transformer Block完整结构"></a>Transformer Block完整结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dit_block</span>(<span class="params">x, c</span>):</span><br><span class="line">    <span class="comment"># 生成6个调制参数</span></span><br><span class="line">    γ₁, β₁, α₁, γ₂, β₂, α₂ = adaLN_modulation(c)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 子层1: Multi-Head Self-Attention</span></span><br><span class="line">    x = x + α₁ * Attention(adaLN(x, γ₁, β₁))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 子层2: Point-wise Feed-Forward</span></span><br><span class="line">    x = x + α₂ * FFN(adaLN(x, γ₂, β₂))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">adaLN</span>(<span class="params">x, γ, β</span>):</span><br><span class="line">    <span class="keyword">return</span> γ * normalize(x) + β</span><br></pre></td></tr></table></figure>

<h3 id="计算复杂度分析"><a href="#计算复杂度分析" class="headerlink" title="计算复杂度分析"></a>计算复杂度分析</h3><p>对于DiT-XL&#x2F;2（$N&#x3D;256$ tokens，$d&#x3D;1152$）：</p>
<ul>
<li><strong>Self-Attention</strong>：$O(N^2 \cdot d) \approx 75M$ ops</li>
<li><strong>Point-wise FFN</strong>：$O(N \cdot d^2 \cdot 2) \approx 680M$ ops</li>
</ul>
<p>FFN占据了大部分计算量！</p>
<hr>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li>Peebles, W., &amp; Xie, S. (2023). Scalable Diffusion Models with Transformers. ICCV 2023.</li>
<li>Ho, J., et al. (2020). Denoising Diffusion Probabilistic Models. NeurIPS 2020.</li>
<li>Rombach, R., et al. (2022). High-Resolution Image Synthesis with Latent Diffusion Models. CVPR 2022.</li>
<li>Dosovitskiy, A., et al. (2021). An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. ICLR 2021.</li>
<li>Dhariwal, P., &amp; Nichol, A. (2021). Diffusion Models Beat GANs on Image Synthesis. NeurIPS 2021.</li>
</ul>
<hr>
<h2 id="关键要点总结"><a href="#关键要点总结" class="headerlink" title="关键要点总结"></a>关键要点总结</h2><ol>
<li><strong>架构创新</strong>：首次系统性地将纯Transformer应用于扩散模型</li>
<li><strong>adaLN-Zero</strong>：零初始化的自适应归一化是性能关键</li>
<li><strong>Gflops定律</strong>：计算量与生成质量强相关（-0.93）</li>
<li><strong>SOTA性能</strong>：ImageNet 256×256达到FID 2.27</li>
<li><strong>统一架构</strong>：推动生成模型向Transformer统一的趋势</li>
</ol>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2026/02/02/%5BOBS%5DDeep%20Learning-Robot%20Learnning-GR00T-N1-Humanoid-Robot-Foundation-Model/"><img class="fill" src="/gallery/Research-paper.png" alt="GR00T N1 An Open Foundation Model for Generalist Humanoid Robots" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2026-02-02T11:30:00.000Z" title="2/2/2026, 7:30:00 PM">2026-02-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2026-02-14T13:40:28.520Z" title="2/14/2026, 9:40:28 PM">2026-02-14</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">28 minutes read (About 4167 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/02/%5BOBS%5DDeep%20Learning-Robot%20Learnning-GR00T-N1-Humanoid-Robot-Foundation-Model/">GR00T N1 An Open Foundation Model for Generalist Humanoid Robots</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2026/02/02/[OBS]Deep Learning-Robot Learnning-GR00T-N1-Humanoid-Robot-Foundation-Model/Pasted_image_20260203120646.png" title="" title=" class="gallery-item"><img src="/2026/02/02/[OBS]Deep Learning-Robot Learnning-GR00T-N1-Humanoid-Robot-Foundation-Model/Pasted_image_20260203120646.png" alt="" title=""></a></div>
# GR00T N1: 通用人形机器人开放基础模型

<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.14734v2">论文链接</a> | NVIDIA, 2025</p>
<hr>
<h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>人形机器人作为通用机器人的理想硬件平台，需要强大的基础模型来实现智能自主操作。受大语言模型和视觉模型成功的启发，研究者希望通过在大规模异构数据上训练机器人基础模型，使其能够理解新场景、处理真实世界的变化并快速学习新任务。然而，与文本和图像领域不同，机器人领域缺乏互联网规模的训练数据，不同机器人的传感器、自由度、控制模式差异巨大，形成”数据孤岛”问题。</p>
<hr>
<h2 id="研究目标"><a href="#研究目标" class="headerlink" title="研究目标"></a>研究目标</h2><p>本论文要解决的核心问题：</p>
<ol>
<li><strong>数据稀缺问题</strong>：人形机器人数据收集成本高、耗时长，如何突破真实数据瓶颈</li>
<li><strong>跨具身泛化</strong>：如何统一不同机器人的状态和动作空间，实现跨具身学习</li>
<li><strong>数据效率</strong>：如何在有限数据下快速适应新任务并在真实环境中鲁棒执行</li>
<li><strong>端到端优化</strong>：如何将高层推理与低层控制统一到单一模型中</li>
</ol>
<hr>
<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="Vision-Language-Action-VLA-模型"><a href="#Vision-Language-Action-VLA-模型" class="headerlink" title="Vision-Language-Action (VLA) 模型"></a>Vision-Language-Action (VLA) 模型</h3><p>视觉-语言-动作模型，接收图像观察和语言指令作为输入，直接输出机器人动作。与传统的分层方法（VLM规划 + 低层策略执行）不同，VLA模型实现端到端优化。</p>
<h3 id="双系统架构-Dual-System-Architecture"><a href="#双系统架构-Dual-System-Architecture" class="headerlink" title="双系统架构 (Dual-System Architecture)"></a>双系统架构 (Dual-System Architecture)</h3><p>受人类认知理论启发（Kahneman, 2011），将模型分为：</p>
<ul>
<li><strong>System 2（推理系统）</strong>：慢速、深思熟虑的高层推理</li>
<li><strong>System 1（反应系统）</strong>：快速、自动化的低层控制</li>
</ul>
<h3 id="数据金字塔-Data-Pyramid"><a href="#数据金字塔-Data-Pyramid" class="headerlink" title="数据金字塔 (Data Pyramid)"></a>数据金字塔 (Data Pyramid)</h3><p>将异构训练数据按规模和具身特异性组织成三层结构：</p>
<ul>
<li><strong>底层</strong>：大规模网络数据和人类视频（通用先验）</li>
<li><strong>中层</strong>：合成数据（仿真+神经生成，可扩展）</li>
<li><strong>顶层</strong>：真实机器人数据（具身特定，高质量）</li>
</ul>
<h3 id="潜在动作-Latent-Actions"><a href="#潜在动作-Latent-Actions" class="headerlink" title="潜在动作 (Latent Actions)"></a>潜在动作 (Latent Actions)</h3><p>通过VQ-VAE([[VQ-VAE-and-Latent-Action-for-Robotics]])学习的通用动作表示，能够统一不同具身体（包括人类）的动作空间，使无动作标签的视频数据可用于训练。</p>
<hr>
<h2 id="研究方法"><a href="#研究方法" class="headerlink" title="研究方法"></a>研究方法</h2><h3 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h3><p>GR00T N1采用双系统组合架构，总参数量22亿（GR00T-N1-2B）：</p>
<h4 id="System-2-Vision-Language-Module"><a href="#System-2-Vision-Language-Module" class="headerlink" title="System 2: Vision-Language Module"></a>System 2: Vision-Language Module</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">输入处理:</span><br><span class="line">├─ 图像: SigLIP-2编码器 → 64个token (224×224)</span><br><span class="line">└─ 文本: SmolLM2 tokenizer → 文本token</span><br><span class="line"></span><br><span class="line">特征提取:</span><br><span class="line">└─ Eagle-2 VLM (1.34B参数)</span><br><span class="line">   ├─ 处理vision-language tokens</span><br><span class="line">   └─ 输出: 中间层embeddings φ_t (第12层)</span><br></pre></td></tr></table></figure>

<p><strong>关键设计</strong>：</p>
<ul>
<li>使用中间层而非最终层特征（更快推理+更高成功率）</li>
<li>语言组件冻结（保留预训练知识）</li>
<li>视觉编码器可训练（适应机器人任务）</li>
<li>运行频率：10Hz</li>
</ul>
<h4 id="System-1-Diffusion-Transformer-Module"><a href="#System-1-Diffusion-Transformer-Module" class="headerlink" title="System 1: Diffusion Transformer Module"></a>System 1: Diffusion Transformer Module</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">DiT Block结构（重复N次）:</span><br><span class="line">├─ Self-Attention</span><br><span class="line">│  └─ 输入: noised action tokens + state embeddings</span><br><span class="line">│</span><br><span class="line">└─ Cross-Attention</span><br><span class="line">   ├─ Query: action/state tokens</span><br><span class="line">   └─ Key &amp; Value: VLM输出的φ_t</span><br></pre></td></tr></table></figure>

<p><strong>动作生成流程</strong>：</p>
<ol>
<li>输入加噪动作 $A_t^{\tau} &#x3D; \tau A_t + (1-\tau)\epsilon$，其中 $\tau \in [0,1]$</li>
<li>通过DiT迭代去噪（K&#x3D;4步）</li>
<li>输出16步动作序列（action chunking）</li>
<li>运行频率：120Hz</li>
</ol>
<p><strong>Flow-Matching损失</strong>：</p>
<p>$$<br>\mathcal{L}<em>{fm}(\theta) &#x3D; \mathbb{E}</em>{\tau} |V_{\theta}(\varphi_t, A_t^{\tau}, q_t) - (\epsilon - A_t)|^2<br>$$</p>
<p>其中 $V_{\theta}$ 是[[Diffusion-Transformers-DiT]]模型，预测去噪向量场。</p>
<h4 id="模块交互机制"><a href="#模块交互机制" class="headerlink" title="模块交互机制"></a>模块交互机制</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">信息流:</span><br><span class="line">图像 + 语言指令</span><br><span class="line">    ↓</span><br><span class="line">[System 2: Eagle-2 VLM]</span><br><span class="line">    ↓ (输出 φ_t)</span><br><span class="line">[Cross-Attention Bridge]</span><br><span class="line">    ↓</span><br><span class="line">[System 1: DiT]</span><br><span class="line">├─ Self-Attention (action + state)</span><br><span class="line">└─ Cross-Attention (attend to φ_t)</span><br><span class="line">    ↓</span><br><span class="line">16步动作序列</span><br></pre></td></tr></table></figure>

<p><strong>端到端联合训练</strong>：</p>
<ul>
<li>两个模块通过cross-attention紧密耦合</li>
<li>使用统一的flow-matching loss优化</li>
<li>辅助目标检测loss增强空间理解：</li>
</ul>
<p>$$<br>\mathcal{L} &#x3D; \mathcal{L}<em>{fm} + \mathcal{L}</em>{det}<br>$$</p>
<h3 id="异构数据训练策略"><a href="#异构数据训练策略" class="headerlink" title="异构数据训练策略"></a>异构数据训练策略</h3><h4 id="1-数据金字塔组织"><a href="#1-数据金字塔组织" class="headerlink" title="1. 数据金字塔组织"></a>1. 数据金字塔组织</h4><table>
<thead>
<tr>
<th>层级</th>
<th>数据源</th>
<th>时长</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>顶层</td>
<td>真实机器人数据</td>
<td>3,289小时</td>
<td>具身特定，高质量</td>
</tr>
<tr>
<td>中层</td>
<td>仿真数据</td>
<td>1,743小时</td>
<td>可扩展，物理约束</td>
</tr>
<tr>
<td>中层</td>
<td>神经生成数据</td>
<td>827小时</td>
<td>反事实场景，多样性</td>
</tr>
<tr>
<td>底层</td>
<td>人类视频</td>
<td>2,517小时</td>
<td>大规模，通用先验</td>
</tr>
</tbody></table>
<p><strong>总计</strong>：8,376小时训练数据</p>
<h4 id="2-潜在动作学习"><a href="#2-潜在动作学习" class="headerlink" title="2. 潜在动作学习"></a>2. 潜在动作学习</h4><p><strong>VQ-VAE训练</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编码器</span></span><br><span class="line">输入: (当前帧 x_t, 未来帧 x_&#123;t+H&#125;)</span><br><span class="line">     ↓</span><br><span class="line">Encoder → 连续embedding → 量化到codebook</span><br><span class="line">     ↓</span><br><span class="line">潜在动作 z_t</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解码器</span></span><br><span class="line">输入: x_t + z_t</span><br><span class="line">     ↓</span><br><span class="line">Decoder → 重建 x_&#123;t+H&#125;</span><br></pre></td></tr></table></figure>

<p><strong>跨具身一致性</strong>：</p>
<ul>
<li>同一潜在动作在不同具身体中语义一致</li>
<li>例如：潜在动作1 &#x3D; “右臂向左移动”（对所有机器人和人类）</li>
</ul>
<p><strong>训练使用</strong>：</p>
<ul>
<li>提取预量化连续embedding作为”LAPA具身体”的动作</li>
<li>使用flow-matching loss训练</li>
</ul>
<h4 id="3-神经轨迹生成"><a href="#3-神经轨迹生成" class="headerlink" title="3. 神经轨迹生成"></a>3. 神经轨迹生成</h4><p><strong>目标</strong>：从88小时真实数据扩增到827小时（~10倍）</p>
<p><strong>技术流程</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">步骤1: 微调视频生成模型</span><br><span class="line">├─ 基础模型: WAN2.1-I2V-14B</span><br><span class="line">├─ 方法: LoRA微调</span><br><span class="line">├─ 数据: 3,000条轨迹，81帧@480P</span><br><span class="line">└─ 训练: 100 epochs</span><br><span class="line"></span><br><span class="line">步骤2: 生成反事实轨迹</span><br><span class="line">├─ 输入: 初始帧 + 新语言指令</span><br><span class="line">├─ 语言生成: 多模态LLM检测物体</span><br><span class="line">│   生成&quot;pick &#123;object&#125; from &#123;A&#125; to &#123;B&#125;&quot;</span><br><span class="line">└─ 输出: 高质量视频</span><br><span class="line"></span><br><span class="line">步骤3: 质量过滤</span><br><span class="line">├─ 采样8帧 → LLM判断是否遵循指令</span><br><span class="line">└─ 不合格 → 重新标注</span><br><span class="line"></span><br><span class="line">步骤4: 动作标注</span><br><span class="line">├─ 潜在动作编码器 → LAPA</span><br><span class="line">└─ 逆动力学模型 → 伪动作标签</span><br></pre></td></tr></table></figure>

<p><strong>生成能力</strong>：</p>
<ul>
<li>改变操作手（左手↔右手）</li>
<li>改变目标位置和物体</li>
<li>处理仿真难题（液体、铰接物体）</li>
<li>多视角生成（4宫格视频）</li>
</ul>
<h4 id="4-仿真数据自动生成"><a href="#4-仿真数据自动生成" class="headerlink" title="4. 仿真数据自动生成"></a>4. 仿真数据自动生成</h4><p><strong>DexMimicGen系统</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">输入: 少量人类演示（几十条）</span><br><span class="line">     ↓</span><br><span class="line">分割 → 物体中心的子任务片段</span><br><span class="line">     ↓</span><br><span class="line">变换 → 根据新物体位置调整</span><br><span class="line">     ↓</span><br><span class="line">组合 → 插值并组合片段</span><br><span class="line">     ↓</span><br><span class="line">验证 → 仿真执行，保留成功轨迹</span><br><span class="line">     ↓</span><br><span class="line">输出: 每任务10,000条演示</span><br></pre></td></tr></table></figure>

<p><strong>规模</strong>：</p>
<ul>
<li>54个源-目标容器组合</li>
<li>540,000条预训练轨迹</li>
<li>11小时生成 &#x3D; 6,500小时等效人类演示</li>
</ul>
<h4 id="5-具身特定编码器-x2F-解码器"><a href="#5-具身特定编码器-x2F-解码器" class="headerlink" title="5. 具身特定编码器&#x2F;解码器"></a>5. 具身特定编码器&#x2F;解码器</h4><p><strong>处理不同维度的状态和动作</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">embodiments = &#123;</span><br><span class="line">    <span class="string">&quot;GR-1&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;state&quot;</span>: [joint_pos, joint_vel, base_pos, ...],</span><br><span class="line">        <span class="string">&quot;action&quot;</span>: [joint_targets, ...],</span><br><span class="line">        <span class="string">&quot;encoder&quot;</span>: MLP_GR1,</span><br><span class="line">        <span class="string">&quot;decoder&quot;</span>: MLP_GR1</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;Franka&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;state&quot;</span>: [ee_pos, ee_rot, gripper],</span><br><span class="line">        <span class="string">&quot;action&quot;</span>: [ee_delta, gripper_cmd],</span><br><span class="line">        <span class="string">&quot;encoder&quot;</span>: MLP_Franka,</span><br><span class="line">        <span class="string">&quot;decoder&quot;</span>: MLP_Franka</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;LAPA&quot;</span>: &#123;  <span class="comment"># 潜在动作</span></span><br><span class="line">        <span class="string">&quot;action&quot;</span>: [latent_embedding],</span><br><span class="line">        <span class="string">&quot;encoder&quot;</span>: MLP_LAPA,</span><br><span class="line">        <span class="string">&quot;decoder&quot;</span>: MLP_LAPA</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="6-统一训练框架"><a href="#6-统一训练框架" class="headerlink" title="6. 统一训练框架"></a>6. 统一训练框架</h4><p><strong>预训练阶段</strong>：</p>
<ul>
<li>全局batch size: 16,384</li>
<li>训练步数: 200,000</li>
<li>数据混合采样：真实机器人(40%) + 仿真(30%) + 神经(20%) + 人类视频(10%)</li>
<li>计算资源: 最多1024个H100 GPU，约50,000 GPU小时</li>
</ul>
<p><strong>后训练阶段</strong>：</p>
<ul>
<li>Batch size: 128-1024</li>
<li>训练步数: 20,000-60,000</li>
<li>可选神经轨迹协同训练（1:1采样比例）</li>
<li>可在单个A6000 GPU上微调</li>
</ul>
<hr>
<h2 id="主要发现"><a href="#主要发现" class="headerlink" title="主要发现"></a>主要发现</h2><h3 id="预训练泛化能力"><a href="#预训练泛化能力" class="headerlink" title="预训练泛化能力"></a>预训练泛化能力</h3><p>在GR-1人形机器人上的零样本评估：</p>
<table>
<thead>
<tr>
<th>任务</th>
<th>成功率</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>左手抓取→右手交接→放置</td>
<td>76.6%</td>
<td>需要双手协调</td>
</tr>
<tr>
<td>新物体→新容器</td>
<td>73.3%</td>
<td>泛化到未见物体</td>
</tr>
</tbody></table>
<h3 id="仿真基准测试"><a href="#仿真基准测试" class="headerlink" title="仿真基准测试"></a>仿真基准测试</h3><p><strong>100条演示&#x2F;任务的性能对比</strong>：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>RoboCasa</th>
<th>DexMG</th>
<th>GR-1</th>
<th>平均</th>
</tr>
</thead>
<tbody><tr>
<td>BC-Transformer</td>
<td>26.3%</td>
<td>53.9%</td>
<td>16.1%</td>
<td>26.4%</td>
</tr>
<tr>
<td>Diffusion Policy</td>
<td>25.6%</td>
<td>56.1%</td>
<td>32.7%</td>
<td>33.4%</td>
</tr>
<tr>
<td><strong>GR00T-N1-2B</strong></td>
<td><strong>32.1%</strong></td>
<td><strong>66.5%</strong></td>
<td><strong>50.0%</strong></td>
<td><strong>45.0%</strong></td>
</tr>
</tbody></table>
<p><strong>关键观察</strong>：</p>
<ul>
<li>GR00T N1在所有基准上均优于基线</li>
<li>在GR-1任务上优势最明显（+17.3%）</li>
</ul>
<h3 id="真实世界部署"><a href="#真实世界部署" class="headerlink" title="真实世界部署"></a>真实世界部署</h3><p><strong>GR-1人形机器人任务成功率</strong>：</p>
<table>
<thead>
<tr>
<th>任务类型</th>
<th>Diffusion Policy<br>(10%数据)</th>
<th>Diffusion Policy<br>(全量数据)</th>
<th>GR00T-N1-2B<br>(10%数据)</th>
<th>GR00T-N1-2B<br>(全量数据)</th>
</tr>
</thead>
<tbody><tr>
<td>抓取放置</td>
<td>3.0%</td>
<td>36.0%</td>
<td><strong>35.0%</strong></td>
<td><strong>82.0%</strong></td>
</tr>
<tr>
<td>铰接物体</td>
<td>14.3%</td>
<td>38.6%</td>
<td><strong>62.0%</strong></td>
<td><strong>70.9%</strong></td>
</tr>
<tr>
<td>工业操作</td>
<td>6.7%</td>
<td>61.0%</td>
<td><strong>31.0%</strong></td>
<td><strong>70.0%</strong></td>
</tr>
<tr>
<td>多机协作</td>
<td>27.5%</td>
<td>62.5%</td>
<td><strong>50.0%</strong></td>
<td><strong>82.5%</strong></td>
</tr>
<tr>
<td><strong>平均</strong></td>
<td><strong>10.2%</strong></td>
<td><strong>46.4%</strong></td>
<td><strong>42.6%</strong></td>
<td><strong>76.8%</strong></td>
</tr>
</tbody></table>
<p><strong>数据效率</strong>：</p>
<ul>
<li>GR00T N1用10%数据（42.6%）≈ Diffusion Policy用全量数据（46.4%）</li>
<li>展现出色的样本效率</li>
</ul>
<h3 id="神经轨迹增强效果"><a href="#神经轨迹增强效果" class="headerlink" title="神经轨迹增强效果"></a>神经轨迹增强效果</h3><p><strong>RoboCasa基准（协同训练3K神经轨迹&#x2F;任务）</strong>：</p>
<table>
<thead>
<tr>
<th>数据量</th>
<th>仅真实数据</th>
<th>+LAPA</th>
<th>+IDM</th>
</tr>
</thead>
<tbody><tr>
<td>30条</td>
<td>17.4%</td>
<td>20.8% (+3.4%)</td>
<td>20.0% (+2.6%)</td>
</tr>
<tr>
<td>100条</td>
<td>32.1%</td>
<td>38.5% (+6.4%)</td>
<td>40.9% (+8.8%)</td>
</tr>
<tr>
<td>300条</td>
<td>49.6%</td>
<td>53.8% (+4.2%)</td>
<td>56.4% (+6.8%)</td>
</tr>
</tbody></table>
<p><strong>真实世界（协同训练100神经轨迹&#x2F;任务）</strong>：</p>
<ul>
<li>平均提升：+5.8%</li>
</ul>
<p><strong>观察</strong>：</p>
<ul>
<li>低数据场景：LAPA略优（更通用的先验）</li>
<li>高数据场景：IDM更优（更接近真实动作）</li>
</ul>
<h3 id="定性分析"><a href="#定性分析" class="headerlink" title="定性分析"></a>定性分析</h3><p><strong>运动质量</strong>：</p>
<ul>
<li>GR00T N1运动更流畅，抓取精度更高</li>
<li>Diffusion Policy常出现初始帧不动、抓取不准确</li>
</ul>
<p><strong>泛化能力</strong>：</p>
<ul>
<li>预训练模型能执行未见过的双手交接任务</li>
<li>后训练模型在特定任务上更精确，但失去部分泛化能力</li>
</ul>
<hr>
<h2 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h2><h3 id="仿真基准"><a href="#仿真基准" class="headerlink" title="仿真基准"></a>仿真基准</h3><p><strong>RoboCasa Kitchen（24任务）</strong>：</p>
<ul>
<li>机器人：Franka Emika Panda</li>
<li>任务：抓取放置、开关门、按按钮、转水龙头等</li>
<li>观察：3个RGB相机（左、右、腕部）</li>
<li>动作：末端执行器相对位姿 + 夹爪状态</li>
<li>数据：每任务3,000条MimicGen生成的演示</li>
</ul>
<p><strong>DexMimicGen Cross-Embodiment Suite（9任务）</strong>：</p>
<ul>
<li>具身体：<ul>
<li>双臂Panda + 平行夹爪（穿线、组装、运输）</li>
<li>双臂Panda + 灵巧手（清理、抬托盘）</li>
<li>GR-1人形 + 灵巧手（倒水、咖啡、分类）</li>
</ul>
</li>
<li>数据：每任务1,000条演示</li>
</ul>
<p><strong>GR-1 Tabletop Tasks（24任务）</strong>：</p>
<ul>
<li>机器人：GR-1人形 + Fourier灵巧手</li>
<li>任务：18个重排任务 + 6个铰接物体任务</li>
<li>观察：头部自我中心相机</li>
<li>动作：关节位置&#x2F;旋转 + 腰部&#x2F;颈部</li>
<li>数据：每任务1,000条DexMimicGen生成</li>
</ul>
<h3 id="真实世界基准"><a href="#真实世界基准" class="headerlink" title="真实世界基准"></a>真实世界基准</h3><p><strong>任务类别</strong>：</p>
<ol>
<li><p><strong>抓取放置（5任务）</strong>：</p>
<ul>
<li>托盘→盘子、砧板→篮子、餐垫→碗等</li>
<li>评估：见过和未见过物体</li>
</ul>
</li>
<li><p><strong>铰接物体（3任务）</strong>：</p>
<ul>
<li>白色抽屉、深色柜子、木箱</li>
<li>要求：放入物体并关闭</li>
</ul>
</li>
<li><p><strong>工业操作（3任务）</strong>：</p>
<ul>
<li>机械零件打包</li>
<li>网格杯倾倒</li>
<li>圆柱体交接</li>
</ul>
</li>
<li><p><strong>多机协作（2任务）</strong>：</p>
<ul>
<li>第1部分：抓取→放入网格杯→交给另一机器人</li>
<li>第2部分：接收→放入黄色箱→倾倒剩余物</li>
</ul>
</li>
</ol>
<p><strong>数据收集</strong>：</p>
<ul>
<li>遥操作时长：15分钟-3小时&#x2F;任务</li>
<li>过滤低质量轨迹</li>
</ul>
<h3 id="评估协议"><a href="#评估协议" class="headerlink" title="评估协议"></a>评估协议</h3><p><strong>仿真</strong>：</p>
<ul>
<li>每任务100次试验</li>
<li>取最后5个checkpoint的最大值</li>
<li>Checkpoint间隔：500步</li>
</ul>
<p><strong>真实机器人</strong>：</p>
<ul>
<li>每任务10次试验（机械打包任务5次）</li>
<li>部分评分系统（捕捉不同执行阶段）</li>
<li>低数据场景：10%数据子采样</li>
</ul>
<h3 id="训练配置"><a href="#训练配置" class="headerlink" title="训练配置"></a>训练配置</h3><p><strong>预训练</strong>：</p>
<ul>
<li>学习率：1e-4</li>
<li>优化器：AdamW (β1&#x3D;0.95, β2&#x3D;0.999)</li>
<li>学习率调度：cosine，warmup比例0.05</li>
<li>Batch size：16,384</li>
<li>步数：200,000</li>
</ul>
<p><strong>后训练</strong>：</p>
<ul>
<li>Batch size：128-1024</li>
<li>步数：20,000-60,000</li>
<li>其他超参数同预训练</li>
</ul>
<hr>
<h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ol>
<li><p><strong>统一的跨具身学习</strong>：</p>
<ul>
<li>单一模型支持从桌面机械臂到双臂人形机器人</li>
<li>潜在动作空间统一不同具身体</li>
</ul>
</li>
<li><p><strong>卓越的数据效率</strong>：</p>
<ul>
<li>10%数据达到基线全量数据性能</li>
<li>预训练提供强大的先验知识</li>
</ul>
</li>
<li><p><strong>可扩展的数据生成</strong>：</p>
<ul>
<li>神经轨迹生成：10倍数据扩增</li>
<li>仿真自动生成：11小时生成6,500小时等效数据</li>
</ul>
</li>
<li><p><strong>端到端优化</strong>：</p>
<ul>
<li>VLM推理与DiT控制联合训练</li>
<li>避免分层方法的接口问题</li>
</ul>
</li>
<li><p><strong>开源生态</strong>：</p>
<ul>
<li>公开22亿参数模型</li>
<li>提供训练数据和仿真基准</li>
</ul>
</li>
</ol>
<h3 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h3><ol>
<li><p><strong>任务范围限制</strong>：</p>
<ul>
<li>当前主要关注短时域桌面操作</li>
<li>未涉及长时域移动操作（loco-manipulation）</li>
</ul>
</li>
<li><p><strong>合成数据质量</strong>：</p>
<ul>
<li>视频生成模型仍面临多样性和物理一致性挑战</li>
<li>需要质量过滤和重新标注</li>
</ul>
</li>
<li><p><strong>硬件依赖</strong>：</p>
<ul>
<li>需要高端GPU进行训练（H100集群）</li>
<li>推理需要L40 GPU（63.9ms&#x2F;16动作）</li>
</ul>
</li>
<li><p><strong>泛化-专精权衡</strong>：</p>
<ul>
<li>后训练提升特定任务性能但损失部分泛化能力</li>
<li>预训练模型能执行双手交接，后训练模型失去此能力</li>
</ul>
</li>
<li><p><strong>视觉-语言骨干限制</strong>：</p>
<ul>
<li>当前VLM的空间推理和语言理解能力仍有提升空间</li>
<li>更强的VLM可能进一步提升性能</li>
</ul>
</li>
</ol>
<hr>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><h3 id="机器人基础模型"><a href="#机器人基础模型" class="headerlink" title="机器人基础模型"></a>机器人基础模型</h3><p><strong>VLA模型</strong>：</p>
<ul>
<li><strong>RT-1&#x2F;RT-2</strong> (Brohan et al., 2022, 2023)：早期VLA模型，使用Transformer架构</li>
<li><strong>π0</strong> (Black et al., 2024)：使用mixture-of-experts连接VLM和动作生成</li>
<li><strong>Octo</strong> (Octo Model Team et al., 2024)：跨具身模型，但不微调VLM</li>
<li><strong>GR-2</strong> (Cheang et al., 2024)：视频-语言-动作模型</li>
</ul>
<p><strong>GR00T N1的区别</strong>：</p>
<ul>
<li>使用简单的cross-attention而非MoE</li>
<li>端到端微调VLM视觉编码器</li>
<li>支持潜在动作和IDM伪动作</li>
</ul>
<h3 id="机器人数据集"><a href="#机器人数据集" class="headerlink" title="机器人数据集"></a>机器人数据集</h3><p><strong>真实机器人数据</strong>：</p>
<ul>
<li><strong>Open X-Embodiment</strong> (2024)：跨具身数据集联盟</li>
<li><strong>AgiBot-Alpha</strong> (2025)：100个机器人的大规模数据集</li>
<li><strong>遥操作系统</strong>：VIVE、Apple Vision Pro、Leap Motion</li>
</ul>
<p><strong>人类视频数据</strong>：</p>
<ul>
<li><strong>Ego4D</strong> (Grauman et al., 2022)：大规模自我中心视频</li>
<li><strong>EPIC-KITCHENS</strong> (Damen et al., 2018)：厨房活动</li>
<li><strong>Assembly-101</strong> (Sener et al., 2022)：组装任务</li>
</ul>
<p><strong>GR00T N1的创新</strong>：</p>
<ul>
<li>数据金字塔组织而非简单混合</li>
<li>潜在动作统一有&#x2F;无标签数据</li>
</ul>
<h3 id="合成数据生成"><a href="#合成数据生成" class="headerlink" title="合成数据生成"></a>合成数据生成</h3><p><strong>仿真数据</strong>：</p>
<ul>
<li><strong>MimicGen</strong> (Mandlekar et al., 2023)：演示变换和重放</li>
<li><strong>DexMimicGen</strong> (Jiang et al., 2024)：灵巧操作数据生成</li>
<li><strong>RoboCasa</strong> (Nasiriany et al., 2024)：厨房环境仿真</li>
</ul>
<p><strong>神经生成</strong>：</p>
<ul>
<li><strong>视频生成模型</strong>：Sora (Brooks et al., 2024)、WAN (Wan Team, 2025)</li>
<li><strong>数据增强</strong>：GenAug (Chen et al., 2023)使用扩散模型增强</li>
</ul>
<p><strong>GR00T N1的规模</strong>：</p>
<ul>
<li>827小时神经轨迹（前所未有）</li>
<li>540K仿真轨迹（11小时生成）</li>
</ul>
<hr>
<h2 id="未来方向"><a href="#未来方向" class="headerlink" title="未来方向"></a>未来方向</h2><ol>
<li><p><strong>长时域移动操作</strong>：</p>
<ul>
<li>扩展到全身运动和导航</li>
<li>需要改进硬件、模型架构和训练数据</li>
</ul>
</li>
<li><p><strong>更强的视觉-语言骨干</strong>：</p>
<ul>
<li>提升空间推理能力</li>
<li>增强语言理解和任务规划</li>
</ul>
</li>
<li><p><strong>改进合成数据生成</strong>：</p>
<ul>
<li>提高视频生成的多样性和反事实能力</li>
<li>增强物理一致性和真实感</li>
<li>探索自动化初始帧生成（img2img扩散）</li>
</ul>
</li>
<li><p><strong>新型模型架构</strong>：</p>
<ul>
<li>探索更高效的推理-控制耦合方式</li>
<li>研究分层时间建模</li>
</ul>
</li>
<li><p><strong>鲁棒性和泛化</strong>：</p>
<ul>
<li>提升对环境变化的适应能力</li>
<li>增强零样本和少样本学习能力</li>
</ul>
</li>
<li><p><strong>多模态感知</strong>：</p>
<ul>
<li>整合触觉、力觉等其他传感器</li>
<li>探索多模态融合策略</li>
</ul>
</li>
<li><p><strong>长时域视频生成</strong>：</p>
<ul>
<li>多轮视频生成实现长任务序列</li>
<li>原子任务组合</li>
</ul>
</li>
</ol>
<hr>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li>NVIDIA (2025). GR00T N1: An Open Foundation Model for Generalist Humanoid Robots. arXiv:2503.14734v2.</li>
<li>Black et al. (2024). π0: A vision-language-action flow model for general robot control. arXiv:2410.24164.</li>
<li>Brohan et al. (2022). RT-1: Robotics transformer for real-world control at scale. arXiv:2212.06817.</li>
<li>Brohan et al. (2023). RT-2: Vision-language-action models transfer web knowledge to robotic control. arXiv:2307.15818.</li>
<li>Chi et al. (2024). Diffusion Policy: Visuomotor policy learning via action diffusion. IJRR.</li>
<li>Jiang et al. (2024). DexMimicGen: Automated data generation for bimanual dexterous manipulation via imitation learning. CoRL.</li>
<li>Mandlekar et al. (2023). MimicGen: A data generation system for scalable robot learning using human demonstrations. CoRL.</li>
<li>Nasiriany et al. (2024). RoboCasa: Large-scale simulation of everyday tasks for generalist robots. RSS.</li>
<li>Open X-Embodiment Collaboration et al. (2024). Open X-Embodiment: Robotic learning datasets and RT-X models.</li>
<li>Ye et al. (2025). Latent action pretraining from videos. ICLR.</li>
<li>Kahneman (2011). Thinking, Fast and Slow. Farrar, Straus and Giroux.</li>
</ul>
<hr>
<h2 id="关键代码和资源"><a href="#关键代码和资源" class="headerlink" title="关键代码和资源"></a>关键代码和资源</h2><ul>
<li><strong>模型权重</strong>：<a target="_blank" rel="noopener" href="https://huggingface.co/nvidia/groot-n1-2b">HuggingFace</a></li>
<li><strong>训练数据</strong>：<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/nvidia/groot-n1-data">HuggingFace Datasets</a></li>
<li><strong>仿真基准</strong>：<a target="_blank" rel="noopener" href="https://github.com/NVlabs/GR00T">GitHub</a></li>
<li><strong>数据格式</strong>：基于LeRobot格式扩展</li>
<li><strong>训练基础设施</strong>：NVIDIA OSMO编排平台</li>
</ul>
<hr>
<h2 id="技术细节补充"><a href="#技术细节补充" class="headerlink" title="技术细节补充"></a>技术细节补充</h2><h3 id="动作空间标准化"><a href="#动作空间标准化" class="headerlink" title="动作空间标准化"></a>动作空间标准化</h3><p><strong>统一不同具身体的表示</strong>：</p>
<ul>
<li>末端执行器旋转状态：6D旋转表示</li>
<li>末端执行器旋转动作：轴角表示</li>
<li>位置和关节：Min-max归一化</li>
<li>顺序：左臂→右臂，旋转→位置→夹爪</li>
</ul>
<h3 id="辅助目标检测损失"><a href="#辅助目标检测损失" class="headerlink" title="辅助目标检测损失"></a>辅助目标检测损失</h3><p>使用OWL-v2检测器标注目标物体边界框：</p>
<p>$$<br>\mathcal{L}<em>{det} &#x3D; |\mathbf{x}</em>{pred} - \mathbf{x}_{gt}|^2<br>$$</p>
<p>其中 $\mathbf{x}$ 是归一化的边界框中心坐标。</p>
<h3 id="推理性能"><a href="#推理性能" class="headerlink" title="推理性能"></a>推理性能</h3><ul>
<li><strong>GR00T-N1-2B</strong>：63.9ms采样16步动作（L40 GPU，bf16）</li>
<li><strong>VLM频率</strong>：10Hz</li>
<li><strong>动作输出频率</strong>：120Hz</li>
<li><strong>去噪步数</strong>：K&#x3D;4</li>
</ul>
<h3 id="计算资源"><a href="#计算资源" class="headerlink" title="计算资源"></a>计算资源</h3><ul>
<li><strong>预训练</strong>：最多1024个H100 GPU，约50,000 GPU小时</li>
<li><strong>神经轨迹生成</strong>：3,600个L40 GPU，约105K GPU小时（1.5天）</li>
<li><strong>后训练</strong>：单个A6000 GPU可微调（仅adapter层时batch size可达200）</li>
</ul>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2026/02/02/%5BOBS%5DDeep%20Learning-Robot%20Learnning-VQ-VAE-and-Latent-Action-for-Robotics/"><img class="fill" src="/gallery/Research-paper.png" alt="VQ-VAE and Latent Action for Robotics" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2026-02-02T11:30:00.000Z" title="2/2/2026, 7:30:00 PM">2026-02-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2026-02-14T13:40:28.522Z" title="2/14/2026, 9:40:28 PM">2026-02-14</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">22 minutes read (About 3259 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/02/02/%5BOBS%5DDeep%20Learning-Robot%20Learnning-VQ-VAE-and-Latent-Action-for-Robotics/">VQ-VAE and Latent Action for Robotics</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2026/02/02/[OBS]Deep Learning-Robot Learnning-VQ-VAE-and-Latent-Action-for-Robotics/Pasted_image_20260203120727.png" title="" title=" class="gallery-item"><img src="/2026/02/02/[OBS]Deep Learning-Robot Learnning-VQ-VAE-and-Latent-Action-for-Robotics/Pasted_image_20260203120727.png" alt="" title=""></a></div>
# VQ-VAE与机器人Latent Action

<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.00937">Neural Discrete Representation Learning</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.03181">VQ-BeT: Behavior Generation with Latent Actions</a></p>
<hr>
<h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>在无监督学习和机器人学习领域，表示学习是核心问题之一。传统的变分自编码器（VAE, Variational AutoEncoder）使用连续潜在变量，但存在后验崩塌（posterior collapse）问题，即解码器过强导致忽略潜在编码。</p>
<p>在机器人学习中，直接学习连续高维动作空间面临以下挑战：</p>
<ul>
<li>动作分布通常是多模态的（如抓取物体可以有多种方式）</li>
<li>行为克隆（Behavior Cloning）容易产生平均化的次优动作</li>
<li>连续动作空间的策略学习不稳定</li>
</ul>
<p>VQ-VAE（Vector Quantised-Variational AutoEncoder）通过引入离散潜在变量，为这些问题提供了有效的解决方案。</p>
<hr>
<h2 id="研究目标"><a href="#研究目标" class="headerlink" title="研究目标"></a>研究目标</h2><h3 id="VQ-VAE的核心目标"><a href="#VQ-VAE的核心目标" class="headerlink" title="VQ-VAE的核心目标"></a>VQ-VAE的核心目标</h3><ol>
<li>解决VAE中的后验崩塌问题</li>
<li>学习有效的离散表示，适用于本质上离散的数据（语言、语音等）</li>
<li>实现端到端的离散表示学习</li>
</ol>
<h3 id="机器人Latent-Action的目标"><a href="#机器人Latent-Action的目标" class="headerlink" title="机器人Latent Action的目标"></a>机器人Latent Action的目标</h3><ol>
<li>将连续高维动作空间压缩为离散的动作原语（action primitives）</li>
<li>在离散空间中学习更稳定的策略</li>
<li>实现时序动作抽象，降低决策频率</li>
<li>提升多模态动作分布的建模能力</li>
</ol>
<hr>
<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="VQ-VAE-Vector-Quantised-Variational-AutoEncoder"><a href="#VQ-VAE-Vector-Quantised-Variational-AutoEncoder" class="headerlink" title="VQ-VAE (Vector Quantised-Variational AutoEncoder)"></a>VQ-VAE (Vector Quantised-Variational AutoEncoder)</h3><p>VQ-VAE是一种使用离散潜在变量的生成模型，通过向量量化（Vector Quantization）技术将编码器输出映射到离散的码本空间。</p>
<p><strong>关键组件：</strong></p>
<ul>
<li><strong>编码器（Encoder）</strong>：将输入映射到连续潜在空间</li>
<li><strong>码本（Codebook）</strong>：包含 $K$ 个 $d$ 维向量 $\mathbf{e} \in \mathbb{R}^{K \times d}$</li>
<li><strong>量化层（Quantization）</strong>：将连续表示映射到最近的码本向量</li>
<li><strong>解码器（Decoder）</strong>：从离散表示重建输入</li>
</ul>
<h3 id="Latent-Action（潜在动作）"><a href="#Latent-Action（潜在动作）" class="headerlink" title="Latent Action（潜在动作）"></a>Latent Action（潜在动作）</h3><p>Latent Action是将连续动作序列编码为离散token的表示方法。每个离散token代表一个”动作原语”或”技能”，可以解码为一段连续的动作序列。</p>
<p><strong>核心思想：</strong></p>
<ul>
<li>将动作序列 $\mathbf{a}_{t:t+H}$ 编码为单个离散索引 $z \in {1, …, K}$</li>
<li>策略网络在离散空间中选择动作：$\pi(\mathbf{o}_t) \rightarrow z$</li>
<li>解码器将离散索引恢复为连续动作：$z \rightarrow \mathbf{a}_{t:t+H}$</li>
</ul>
<hr>
<h2 id="VQ-VAE方法详解"><a href="#VQ-VAE方法详解" class="headerlink" title="VQ-VAE方法详解"></a>VQ-VAE方法详解</h2><h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">输入 x</span><br><span class="line">  ↓</span><br><span class="line">[编码器] Encoder</span><br><span class="line">  ↓</span><br><span class="line">z_e(x) ∈ R^(H×W×D)  (连续潜在表示)</span><br><span class="line">  ↓</span><br><span class="line">[向量量化] Vector Quantization</span><br><span class="line">  ↓</span><br><span class="line">z_q(x) ∈ R^(H×W×D)  (离散潜在表示)</span><br><span class="line">  ↓</span><br><span class="line">[解码器] Decoder</span><br><span class="line">  ↓</span><br><span class="line">重建输出 x̂</span><br></pre></td></tr></table></figure>

<h3 id="向量量化过程"><a href="#向量量化过程" class="headerlink" title="向量量化过程"></a>向量量化过程</h3><p>对于编码器输出的每个空间位置，找到最近的码本向量：</p>
<p>$$<br>z_q(\mathbf{x}) &#x3D; \mathbf{e}_k, \quad \text{where} \quad k &#x3D; \arg\min_j |\mathbf{z}_e(\mathbf{x}) - \mathbf{e}_j|_2<br>$$</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>VQ-VAE使用三部分损失函数：</p>
<p>$$<br>L &#x3D; \log p(\mathbf{x}|\mathbf{z}_q(\mathbf{x})) + |\text{sg}[\mathbf{z}_e(\mathbf{x})] - \mathbf{e}|_2^2 + \beta |\mathbf{z}_e(\mathbf{x}) - \text{sg}[\mathbf{e}]|_2^2<br>$$</p>
<p>其中：</p>
<ul>
<li><strong>重建损失（Reconstruction Loss）</strong>：$\log p(\mathbf{x}|\mathbf{z}_q(\mathbf{x}))$，确保重建质量</li>
<li><strong>码本损失（Codebook Loss）</strong>：$|\text{sg}[\mathbf{z}_e(\mathbf{x})] - \mathbf{e}|_2^2$，更新码本向量使其靠近编码器输出</li>
<li><strong>承诺损失（Commitment Loss）</strong>：$\beta |\mathbf{z}_e(\mathbf{x}) - \text{sg}[\mathbf{e}]|_2^2$，鼓励编码器输出靠近码本向量（$\beta &#x3D; 0.25$）</li>
</ul>
<p>其中 $\text{sg}[\cdot]$ 表示stop gradient操作，阻止梯度传播。</p>
<h3 id="Straight-Through-Estimator"><a href="#Straight-Through-Estimator" class="headerlink" title="Straight-Through Estimator"></a>Straight-Through Estimator</h3><p><strong>问题</strong>：量化操作 $\mathbf{z}<em>q &#x3D; \arg\min</em>{\mathbf{e}} |\mathbf{z}_e - \mathbf{e}|$ 不可微分</p>
<p><strong>解决方案</strong>：在反向传播时，将解码器的梯度直接复制给编码器：</p>
<p>$$<br>\nabla_{\mathbf{z}<em>e} L &#x3D; \nabla</em>{\mathbf{z}_q} L<br>$$</p>
<p>即在前向传播使用离散的 $\mathbf{z}_q$，在反向传播时假装量化操作是恒等映射。</p>
<h3 id="数据尺度变化示例"><a href="#数据尺度变化示例" class="headerlink" title="数据尺度变化示例"></a>数据尺度变化示例</h3><p>以CIFAR-10图像重建为例：</p>
<table>
<thead>
<tr>
<th>阶段</th>
<th>数据形状</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>输入图像</td>
<td><code>[Batch, 32, 32, 3]</code></td>
<td>原始RGB图像</td>
</tr>
<tr>
<td>编码器输出 $\mathbf{z}_e$</td>
<td><code>[Batch, 8, 8, 64]</code></td>
<td>空间下采样4倍，通道数64</td>
</tr>
<tr>
<td>量化后 $\mathbf{z}_q$</td>
<td><code>[Batch, 8, 8, 64]</code></td>
<td>形状不变，但值被离散化</td>
</tr>
<tr>
<td>解码器输出</td>
<td><code>[Batch, 32, 32, 3]</code></td>
<td>重建图像</td>
</tr>
</tbody></table>
<p><strong>信息压缩率</strong>：$(32 \times 32 \times 3) &#x2F; (8 \times 8 \times \log_2 512) \approx 42$ 倍压缩（假设码本大小 $K&#x3D;512$）</p>
<hr>
<h2 id="VQ-VAE在机器人中的应用"><a href="#VQ-VAE在机器人中的应用" class="headerlink" title="VQ-VAE在机器人中的应用"></a>VQ-VAE在机器人中的应用</h2><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">观察 o_t (图像/状态)</span><br><span class="line">    ↓</span><br><span class="line">[策略网络 π]</span><br><span class="line">    ↓</span><br><span class="line">离散latent action z ∈ &#123;1,...,K&#125;</span><br><span class="line">    ↓</span><br><span class="line">[VQ-VAE解码器]</span><br><span class="line">    ↓</span><br><span class="line">连续动作序列 a_&#123;t:t+H&#125;</span><br><span class="line">    ↓</span><br><span class="line">执行到机器人</span><br></pre></td></tr></table></figure>

<h3 id="动作序列编码"><a href="#动作序列编码" class="headerlink" title="动作序列编码"></a>动作序列编码</h3><p><strong>输入</strong>：动作序列 $\mathbf{a}_{t:t+H} \in \mathbb{R}^{H \times d_a}$，其中 $H$ 是序列长度，$d_a$ 是动作维度</p>
<p><strong>编码过程</strong>：</p>
<ol>
<li>通过1D卷积或Transformer编码时序信息</li>
<li>输出单个向量 $\mathbf{z}_e \in \mathbb{R}^D$</li>
<li>量化为离散索引 $k \in {1, …, K}$</li>
</ol>
<p><strong>解码过程</strong>：</p>
<ol>
<li>从码本中查找向量 $\mathbf{e}_k$</li>
<li>通过解码器生成动作序列 $\hat{\mathbf{a}}_{t:t+H}$</li>
</ol>
<h3 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h3><h4 id="阶段1：训练VQ-VAE"><a href="#阶段1：训练VQ-VAE" class="headerlink" title="阶段1：训练VQ-VAE"></a>阶段1：训练VQ-VAE</h4><p>使用专家演示数据训练VQ-VAE：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> expert_demonstrations:</span><br><span class="line">    action_seq = batch[<span class="string">&#x27;actions&#x27;</span>]  <span class="comment"># [B, H, action_dim]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 编码-量化-解码</span></span><br><span class="line">    z_e = encoder(action_seq)</span><br><span class="line">    z_q = quantize(z_e, codebook)</span><br><span class="line">    action_recon = decoder(z_q)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 三部分损失</span></span><br><span class="line">    loss_recon = MSE(action_seq, action_recon)</span><br><span class="line">    loss_vq = MSE(sg(z_e), z_q)</span><br><span class="line">    loss_commit = MSE(z_e, sg(z_q))</span><br><span class="line"></span><br><span class="line">    loss = loss_recon + loss_vq + <span class="number">0.25</span> * loss_commit</span><br></pre></td></tr></table></figure>

<h4 id="阶段2：训练策略网络"><a href="#阶段2：训练策略网络" class="headerlink" title="阶段2：训练策略网络"></a>阶段2：训练策略网络</h4><p>固定VQ-VAE，训练策略在离散空间中选择动作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> demonstrations:</span><br><span class="line">    obs = batch[<span class="string">&#x27;observations&#x27;</span>]  <span class="comment"># [B, T, obs_dim]</span></span><br><span class="line">    actions = batch[<span class="string">&#x27;actions&#x27;</span>]   <span class="comment"># [B, T, action_dim]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将动作编码为离散token</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        z_indices = vqvae.encode(actions)  <span class="comment"># [B, T//H]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练策略预测离散token</span></span><br><span class="line">    z_pred = policy(obs)  <span class="comment"># [B, T//H, K]</span></span><br><span class="line">    loss = CrossEntropy(z_pred, z_indices)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="主要应用案例"><a href="#主要应用案例" class="headerlink" title="主要应用案例"></a>主要应用案例</h2><h3 id="VQ-BeT-VQ-Behavior-Transformer"><a href="#VQ-BeT-VQ-Behavior-Transformer" class="headerlink" title="VQ-BeT (VQ-Behavior Transformer)"></a>VQ-BeT (VQ-Behavior Transformer)</h3><p><strong>论文</strong>：Behavior Generation with Latent Actions (CoRL 2023)</p>
<p><strong>核心思想</strong>：</p>
<ol>
<li>使用VQ-VAE将动作序列压缩为离散token</li>
<li>使用Transformer建模观察到latent action的映射：$p(z_t | \mathbf{o}_{1:t})$</li>
<li>执行时解码latent action为连续动作序列</li>
</ol>
<p><strong>优势</strong>：</p>
<ul>
<li>有效处理多模态动作分布</li>
<li>避免行为克隆中的动作平均化问题</li>
<li>支持长时序动作规划（一次预测多步）</li>
</ul>
<h3 id="LISA-Latent-Imagination-with-Skill-Abstraction"><a href="#LISA-Latent-Imagination-with-Skill-Abstraction" class="headerlink" title="LISA (Latent Imagination with Skill Abstraction)"></a>LISA (Latent Imagination with Skill Abstraction)</h3><p><strong>核心思想</strong>：结合世界模型和latent action</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">当前状态 s_t</span><br><span class="line">    ↓</span><br><span class="line">[世界模型] 在latent space中想象</span><br><span class="line">    ↓</span><br><span class="line">预测未来状态序列 ŝ_&#123;t+1:t+H&#125;</span><br><span class="line">    ↓</span><br><span class="line">[规划器] 选择最优latent action z*</span><br><span class="line">    ↓</span><br><span class="line">[VQ解码器] z* → 连续动作</span><br></pre></td></tr></table></figure>

<h3 id="SPiRL-Skill-based-Model-based-RL"><a href="#SPiRL-Skill-based-Model-based-RL" class="headerlink" title="SPiRL (Skill-based Model-based RL)"></a>SPiRL (Skill-based Model-based RL)</h3><p>将VQ-VAE学习的离散表示视为”技能”，在强化学习中进行技能级别的规划。</p>
<hr>
<h2 id="实验设计与结果"><a href="#实验设计与结果" class="headerlink" title="实验设计与结果"></a>实验设计与结果</h2><h3 id="VQ-VAE实验（原始论文）"><a href="#VQ-VAE实验（原始论文）" class="headerlink" title="VQ-VAE实验（原始论文）"></a>VQ-VAE实验（原始论文）</h3><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><ul>
<li><strong>CIFAR-10</strong>：32×32彩色图像</li>
<li><strong>ImageNet</strong>：128×128和256×256图像</li>
<li><strong>VCTK语音数据集</strong>：英语语音数据</li>
<li><strong>DeepMind Lab</strong>：强化学习环境视频</li>
</ul>
<h4 id="关键参数"><a href="#关键参数" class="headerlink" title="关键参数"></a>关键参数</h4><ul>
<li>码本大小 $K$：512</li>
<li>编码维度 $D$：64</li>
<li>承诺损失系数 $\beta$：0.25</li>
</ul>
<h4 id="主要结果"><a href="#主要结果" class="headerlink" title="主要结果"></a>主要结果</h4><table>
<thead>
<tr>
<th>任务</th>
<th>指标</th>
<th>结果</th>
</tr>
</thead>
<tbody><tr>
<td>图像重建（CIFAR-10）</td>
<td>重建质量</td>
<td>与连续VAE相当</td>
</tr>
<tr>
<td>音频重建（VCTK）</td>
<td>感知质量</td>
<td>接近原始音频</td>
</tr>
<tr>
<td>说话人分类</td>
<td>准确率</td>
<td>49.3%（从41维编码）</td>
</tr>
<tr>
<td>视频建模</td>
<td>表示质量</td>
<td>成功捕获时序信息</td>
</tr>
</tbody></table>
<h3 id="机器人Latent-Action实验"><a href="#机器人Latent-Action实验" class="headerlink" title="机器人Latent Action实验"></a>机器人Latent Action实验</h3><h4 id="超参数选择"><a href="#超参数选择" class="headerlink" title="超参数选择"></a>超参数选择</h4><table>
<thead>
<tr>
<th>参数</th>
<th>简单任务</th>
<th>复杂任务</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>码本大小 $K$</td>
<td>16-64</td>
<td>128-512</td>
<td>过小表达能力不足，过大难以学习</td>
</tr>
<tr>
<td>序列长度 $H$</td>
<td>10-20</td>
<td>10-20</td>
<td>过小失去时序抽象，过大误差累积</td>
</tr>
<tr>
<td>编码维度 $D$</td>
<td>64-128</td>
<td>128-256</td>
<td>根据动作复杂度调整</td>
</tr>
</tbody></table>
<h4 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h4><p>VQ-BeT在多个机器人操作任务上的表现：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>成功率</th>
<th>多模态处理</th>
<th>训练稳定性</th>
</tr>
</thead>
<tbody><tr>
<td>传统BC</td>
<td>65%</td>
<td>差</td>
<td>中等</td>
</tr>
<tr>
<td>Diffusion Policy</td>
<td>78%</td>
<td>好</td>
<td>较慢</td>
</tr>
<tr>
<td>VQ-BeT</td>
<td>82%</td>
<td>优秀</td>
<td>快速稳定</td>
</tr>
</tbody></table>
<hr>
<h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><p><strong>VQ-VAE本身：</strong></p>
<ul>
<li>避免后验崩塌问题，潜在编码被充分利用</li>
<li>离散表示更适合某些模态（语言、符号）</li>
<li>可以学习到有意义的离散结构</li>
</ul>
<p><strong>在机器人中的优势：</strong></p>
<ul>
<li><strong>多模态建模</strong>：离散分类比连续回归更容易处理多模态动作分布</li>
<li><strong>时序抽象</strong>：一个latent action代表一段动作序列，降低决策频率</li>
<li><strong>训练稳定性</strong>：离散空间避免连续动作的梯度不稳定</li>
<li><strong>可解释性</strong>：码本向量可视为”技能原语”，便于分析和调试</li>
<li><strong>泛化能力</strong>：学到的动作原语可以组合应用到新场景</li>
</ul>
<h3 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h3><p><strong>VQ-VAE的挑战：</strong></p>
<ul>
<li>码本利用率问题（codebook collapse）：部分码本向量可能不被使用</li>
<li>重建误差：离散化导致信息损失</li>
<li>超参数敏感：$K$、$D$、$\beta$ 需要仔细调优</li>
</ul>
<p><strong>机器人应用的挑战：</strong></p>
<ul>
<li><strong>重建精度</strong>：VQ-VAE无法完美重建动作，影响执行精度</li>
<li><strong>序列长度选择</strong>：$H$ 的选择需要在抽象能力和精确控制之间权衡</li>
<li><strong>计算开销</strong>：需要额外训练VQ-VAE模型</li>
<li><strong>在线适应</strong>：预训练的码本可能不适合新任务</li>
</ul>
<hr>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><h3 id="离散表示学习"><a href="#离散表示学习" class="headerlink" title="离散表示学习"></a>离散表示学习</h3><ul>
<li><strong>VQ-VAE-2</strong> (Razavi et al., 2019)：层次化VQ-VAE，提升生成质量</li>
<li><strong>DALL-E</strong> (Ramesh et al., 2021)：使用VQ-VAE的离散表示进行文本到图像生成</li>
<li><strong>Gumbel-Softmax VAE</strong>：另一种离散VAE方法，使用Gumbel-Softmax技巧</li>
</ul>
<h3 id="机器人技能学习"><a href="#机器人技能学习" class="headerlink" title="机器人技能学习"></a>机器人技能学习</h3><ul>
<li><strong>Skill Discovery</strong>：无监督发现技能的方法（DIAYN, DADS等）</li>
<li><strong>Hierarchical RL</strong>：层次化强化学习，在不同抽象层次上决策</li>
<li><strong>Option Framework</strong>：时序抽象的经典框架</li>
</ul>
<h3 id="行为克隆与模仿学习"><a href="#行为克隆与模仿学习" class="headerlink" title="行为克隆与模仿学习"></a>行为克隆与模仿学习</h3><ul>
<li><strong>Diffusion Policy</strong> (Chi et al., 2023)：使用扩散模型生成动作</li>
<li><strong>Action Chunking Transformer</strong> (Zhao et al., 2023)：直接预测动作序列</li>
<li><strong>BeT</strong> (Shafiullah et al., 2022)：使用离散化动作的行为Transformer</li>
</ul>
<hr>
<h2 id="未来方向"><a href="#未来方向" class="headerlink" title="未来方向"></a>未来方向</h2><h3 id="方法改进"><a href="#方法改进" class="headerlink" title="方法改进"></a>方法改进</h3><ol>
<li><p><strong>层次化VQ-VAE</strong>：</p>
<ul>
<li>高层策略选择宏观latent action</li>
<li>低层策略选择微观latent action</li>
<li>实现多层次的时序抽象</li>
</ul>
</li>
<li><p><strong>与扩散模型结合</strong>：</p>
<ul>
<li>使用VQ-VAE的离散表示作为扩散模型的条件</li>
<li>在离散空间规划，在连续空间精细化</li>
<li>结合两者优势：稳定性+精确性</li>
</ul>
</li>
<li><p><strong>在线学习与适应</strong>：</p>
<ul>
<li>预训练VQ-VAE在大规模数据上</li>
<li>在新任务上微调策略网络</li>
<li>探索码本的在线更新机制</li>
</ul>
</li>
<li><p><strong>解决码本崩塌</strong>：</p>
<ul>
<li>使用EMA（指数移动平均）更新码本</li>
<li>引入正则化鼓励码本多样性</li>
<li>动态调整码本大小</li>
</ul>
</li>
</ol>
<h3 id="应用拓展"><a href="#应用拓展" class="headerlink" title="应用拓展"></a>应用拓展</h3><ol>
<li><p><strong>多模态机器人学习</strong>：</p>
<ul>
<li>结合视觉、触觉、本体感觉</li>
<li>学习跨模态的统一表示</li>
</ul>
</li>
<li><p><strong>长时序任务规划</strong>：</p>
<ul>
<li>在latent action空间进行任务规划</li>
<li>结合符号推理和连续控制</li>
</ul>
</li>
<li><p><strong>迁移学习</strong>：</p>
<ul>
<li>在源任务上学习通用动作原语</li>
<li>在目标任务上组合和微调</li>
</ul>
</li>
<li><p><strong>人机协作</strong>：</p>
<ul>
<li>可解释的动作原语便于人类理解</li>
<li>支持人类通过选择latent action进行干预</li>
</ul>
</li>
</ol>
<hr>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><h3 id="核心论文"><a href="#核心论文" class="headerlink" title="核心论文"></a>核心论文</h3><ul>
<li>van den Oord, A., Vinyals, O., &amp; Kavukcuoglu, K. (2017). Neural Discrete Representation Learning. NIPS 2017. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.00937">arXiv:1711.00937</a></li>
<li>Shafiullah, N. M. M., et al. (2023). Behavior Generation with Latent Actions (VQ-BeT). CoRL 2023. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.03181">arXiv:2403.03181</a></li>
</ul>
<h3 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h3><ul>
<li>Razavi, A., et al. (2019). Generating Diverse High-Fidelity Images with VQ-VAE-2. NeurIPS 2019.</li>
<li>Pertsch, K., et al. (2020). Accelerating Reinforcement Learning with Learned Skill Priors (SPiRL). CoRL 2020.</li>
<li>Lynch, C., &amp; Sermanet, P. (2020). Learning Latent Plans from Play (LISA). CoRL 2020.</li>
<li>Chi, C., et al. (2023). Diffusion Policy: Visuomotor Policy Learning via Action Diffusion. RSS 2023.</li>
</ul>
<hr>
<h2 id="关键代码示例"><a href="#关键代码示例" class="headerlink" title="关键代码示例"></a>关键代码示例</h2><h3 id="VQ-VAE量化层实现"><a href="#VQ-VAE量化层实现" class="headerlink" title="VQ-VAE量化层实现"></a>VQ-VAE量化层实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VectorQuantizer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_embeddings, embedding_dim, commitment_cost=<span class="number">0.25</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.embedding_dim = embedding_dim</span><br><span class="line">        <span class="variable language_">self</span>.num_embeddings = num_embeddings</span><br><span class="line">        <span class="variable language_">self</span>.commitment_cost = commitment_cost</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化码本</span></span><br><span class="line">        <span class="variable language_">self</span>.embedding = nn.Embedding(num_embeddings, embedding_dim)</span><br><span class="line">        <span class="variable language_">self</span>.embedding.weight.data.uniform_(-<span class="number">1</span>/num_embeddings, <span class="number">1</span>/num_embeddings)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z_e</span>):</span><br><span class="line">        <span class="comment"># z_e: [B, D] 编码器输出</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算距离</span></span><br><span class="line">        distances = torch.<span class="built_in">sum</span>(z_e**<span class="number">2</span>, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>) + \</span><br><span class="line">                    torch.<span class="built_in">sum</span>(<span class="variable language_">self</span>.embedding.weight**<span class="number">2</span>, dim=<span class="number">1</span>) - \</span><br><span class="line">                    <span class="number">2</span> * torch.matmul(z_e, <span class="variable language_">self</span>.embedding.weight.t())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 找到最近的码本向量</span></span><br><span class="line">        encoding_indices = torch.argmin(distances, dim=<span class="number">1</span>)</span><br><span class="line">        z_q = <span class="variable language_">self</span>.embedding(encoding_indices)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        e_latent_loss = torch.mean((z_q.detach() - z_e)**<span class="number">2</span>)  <span class="comment"># 码本损失</span></span><br><span class="line">        q_latent_loss = torch.mean((z_q - z_e.detach())**<span class="number">2</span>)  <span class="comment"># 承诺损失</span></span><br><span class="line">        loss = e_latent_loss + <span class="variable language_">self</span>.commitment_cost * q_latent_loss</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Straight-through estimator</span></span><br><span class="line">        z_q = z_e + (z_q - z_e).detach()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> z_q, loss, encoding_indices</span><br></pre></td></tr></table></figure>

<h3 id="动作序列编码器"><a href="#动作序列编码器" class="headerlink" title="动作序列编码器"></a>动作序列编码器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ActionEncoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, action_dim, hidden_dim, latent_dim, seq_len</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.seq_len = seq_len</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1D卷积编码时序信息</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv1d(action_dim, hidden_dim, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv1d(hidden_dim, hidden_dim*<span class="number">2</span>, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(hidden_dim*<span class="number">2</span> * (seq_len//<span class="number">4</span>), latent_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, action_seq</span>):</span><br><span class="line">        <span class="comment"># action_seq: [B, seq_len, action_dim]</span></span><br><span class="line">        x = action_seq.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [B, action_dim, seq_len]</span></span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.conv1(x))</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.conv2(x))</span><br><span class="line">        x = x.flatten(<span class="number">1</span>)</span><br><span class="line">        z_e = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        <span class="keyword">return</span> z_e</span><br></pre></td></tr></table></figure>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2026/01/29/%5BOBS%5DAI-Bayes-Theorem/"><img class="fill" src="/gallery/AI.png" alt="贝叶斯公式详解" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2026-01-29T11:15:00.000Z" title="1/29/2026, 7:15:00 PM">2026-01-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2026-02-14T13:40:28.044Z" title="2/14/2026, 9:40:28 PM">2026-02-14</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">16 minutes read (About 2393 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/01/29/%5BOBS%5DAI-Bayes-Theorem/">贝叶斯公式详解</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes’ Theorem</a> | <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Bayesian_inference">Bayesian Inference</a></p>
<hr>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>贝叶斯公式（Bayes’ Theorem）是概率论中的基本定理，描述了如何根据新证据更新对事件概率的信念。它是贝叶斯统计学、机器学习、人工智能等领域的理论基础，提供了一种系统化的方法来处理不确定性和进行推理。</p>
<hr>
<h2 id="公式形式"><a href="#公式形式" class="headerlink" title="公式形式"></a>公式形式</h2><h3 id="基本形式"><a href="#基本形式" class="headerlink" title="基本形式"></a>基本形式</h3><p>$$P(A|B) &#x3D; \frac{P(B|A) \times P(A)}{P(B)}$$</p>
<h3 id="参数估计形式"><a href="#参数估计形式" class="headerlink" title="参数估计形式"></a>参数估计形式</h3><p>$$P(\theta|D) &#x3D; \frac{P(D|\theta) \times P(\theta)}{P(D)}$$</p>
<p>或写成：</p>
<p>$$\text{后验概率} &#x3D; \frac{\text{似然} \times \text{先验}}{\text{证据}}$$</p>
<hr>
<h2 id="各项含义"><a href="#各项含义" class="headerlink" title="各项含义"></a>各项含义</h2><table>
<thead>
<tr>
<th>符号</th>
<th>名称</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>$P(\theta|D)$</td>
<td>后验概率</td>
<td>看到数据 $D$ 后，参数 $\theta$ 的概率</td>
</tr>
<tr>
<td>$P(D|\theta)$</td>
<td>似然</td>
<td>给定参数 $\theta$，观测到数据 $D$ 的概率</td>
</tr>
<tr>
<td>$P(\theta)$</td>
<td>先验概率</td>
<td>看到数据前，对参数 $\theta$ 的初始信念</td>
</tr>
<tr>
<td>$P(D)$</td>
<td>边缘似然&#x2F;证据</td>
<td>数据 $D$ 出现的总概率（归一化常数）</td>
</tr>
</tbody></table>
<h3 id="边缘似然的计算"><a href="#边缘似然的计算" class="headerlink" title="边缘似然的计算"></a>边缘似然的计算</h3><p>$$P(D) &#x3D; \int P(D|\theta)P(\theta)d\theta$$</p>
<p>或离散情况：</p>
<p>$$P(D) &#x3D; \sum_{\theta} P(D|\theta)P(\theta)$$</p>
<hr>
<h2 id="直观理解"><a href="#直观理解" class="headerlink" title="直观理解"></a>直观理解</h2><p>贝叶斯公式回答：**”看到证据后，我应该如何更新我的信念？”**</p>
<p>$$\text{新信念} &#x3D; \frac{\text{旧信念} \times \text{证据支持度}}{\text{归一化}}$$</p>
<p><strong>核心思想</strong>：</p>
<ul>
<li>从先验信念开始</li>
<li>根据观测到的证据调整信念</li>
<li>得到更新后的后验信念</li>
</ul>
<hr>
<h2 id="实际例子"><a href="#实际例子" class="headerlink" title="实际例子"></a>实际例子</h2><h3 id="例-1：医疗诊断"><a href="#例-1：医疗诊断" class="headerlink" title="例 1：医疗诊断"></a>例 1：医疗诊断</h3><p><strong>场景</strong>：</p>
<ul>
<li>某疾病患病率 1%（先验）</li>
<li>测试准确率：患病时阳性 95%，健康时阳性 5%</li>
<li>你测试呈阳性</li>
</ul>
<p><strong>问</strong>：你真的患病的概率是多少？</p>
<p><strong>解答</strong>：</p>
<p>设：</p>
<ul>
<li>$A$ &#x3D; 患病</li>
<li>$B$ &#x3D; 测试阳性</li>
</ul>
<p>已知：</p>
<ul>
<li>$P(A) &#x3D; 0.01$（先验）</li>
<li>$P(B|A) &#x3D; 0.95$（真阳性率）</li>
<li>$P(B|\neg A) &#x3D; 0.05$（假阳性率）</li>
</ul>
<p>计算边缘似然：</p>
<p>$$P(B) &#x3D; P(B|A)P(A) + P(B|\neg A)P(\neg A)$$<br>$$&#x3D; 0.95 \times 0.01 + 0.05 \times 0.99 &#x3D; 0.059$$</p>
<p>应用贝叶斯公式：</p>
<p>$$P(A|B) &#x3D; \frac{P(B|A) \times P(A)}{P(B)} &#x3D; \frac{0.95 \times 0.01}{0.059} \approx 0.16$$</p>
<p><strong>结论</strong>：即使测试阳性，患病概率只有 **16%**！</p>
<p><strong>反直觉原因</strong>：先验概率很低（1%），大部分阳性结果来自假阳性。</p>
<hr>
<h3 id="例-2：垃圾邮件过滤"><a href="#例-2：垃圾邮件过滤" class="headerlink" title="例 2：垃圾邮件过滤"></a>例 2：垃圾邮件过滤</h3><p><strong>场景</strong>：</p>
<ul>
<li>邮件中 30% 是垃圾邮件</li>
<li>垃圾邮件中 80% 含”中奖”</li>
<li>正常邮件中 5% 含”中奖”</li>
</ul>
<p><strong>问</strong>：含”中奖”的邮件是垃圾邮件的概率？</p>
<p><strong>解答</strong>：</p>
<p>设：</p>
<ul>
<li>$S$ &#x3D; 垃圾邮件</li>
<li>$W$ &#x3D; 含”中奖”</li>
</ul>
<p>已知：</p>
<ul>
<li>$P(S) &#x3D; 0.3$</li>
<li>$P(W|S) &#x3D; 0.8$</li>
<li>$P(W|\neg S) &#x3D; 0.05$</li>
</ul>
<p>计算：</p>
<p>$$P(W) &#x3D; 0.8 \times 0.3 + 0.05 \times 0.7 &#x3D; 0.275$$</p>
<p>$$P(S|W) &#x3D; \frac{0.8 \times 0.3}{0.275} \approx 0.87$$</p>
<p><strong>结论</strong>：含”中奖”的邮件有 <strong>87%</strong> 概率是垃圾邮件。</p>
<hr>
<h3 id="例-3：机器学习中的参数估计"><a href="#例-3：机器学习中的参数估计" class="headerlink" title="例 3：机器学习中的参数估计"></a>例 3：机器学习中的参数估计</h3><p><strong>场景</strong>：训练一个分类模型</p>
<p><strong>目标</strong>：找到最优参数 $\theta$</p>
<p>$$P(\theta|D) &#x3D; \frac{P(D|\theta) \times P(\theta)}{P(D)}$$</p>
<ul>
<li>**似然 $P(D|\theta)$**：模型拟合数据的好坏</li>
<li>**先验 $P(\theta)$**：对参数的正则化（如 L2 正则 &#x3D; 高斯先验）</li>
<li>**后验 $P(\theta|D)$**：综合考虑数据和先验的最优参数</li>
</ul>
<p><strong>最大后验估计（MAP）</strong>：</p>
<p>$$\theta_{MAP} &#x3D; \arg\max_{\theta} P(\theta|D) &#x3D; \arg\max_{\theta} P(D|\theta)P(\theta)$$</p>
<hr>
<h2 id="贝叶斯推断流程"><a href="#贝叶斯推断流程" class="headerlink" title="贝叶斯推断流程"></a>贝叶斯推断流程</h2><h3 id="1-指定先验"><a href="#1-指定先验" class="headerlink" title="1. 指定先验"></a>1. 指定先验</h3><p>根据领域知识或假设选择先验分布：</p>
<p>$$P(\theta)$$</p>
<p><strong>常见先验</strong>：</p>
<ul>
<li><strong>无信息先验</strong>：均匀分布（表示无知）</li>
<li><strong>共轭先验</strong>：使后验与先验同分布（计算方便）</li>
<li><strong>正则化先验</strong>：高斯分布（L2 正则）、拉普拉斯分布（L1 正则）</li>
</ul>
<h3 id="2-收集数据"><a href="#2-收集数据" class="headerlink" title="2. 收集数据"></a>2. 收集数据</h3><p>观测数据 $D &#x3D; {x_1, x_2, \ldots, x_N}$</p>
<h3 id="3-计算似然"><a href="#3-计算似然" class="headerlink" title="3. 计算似然"></a>3. 计算似然</h3><p>根据模型计算数据的似然：</p>
<p>$$P(D|\theta) &#x3D; \prod_{i&#x3D;1}^{N} P(x_i|\theta)$$</p>
<h3 id="4-应用贝叶斯公式"><a href="#4-应用贝叶斯公式" class="headerlink" title="4. 应用贝叶斯公式"></a>4. 应用贝叶斯公式</h3><p>计算后验分布：</p>
<p>$$P(\theta|D) &#x3D; \frac{P(D|\theta)P(\theta)}{P(D)}$$</p>
<h3 id="5-进行推断"><a href="#5-进行推断" class="headerlink" title="5. 进行推断"></a>5. 进行推断</h3><ul>
<li><strong>点估计</strong>：MAP 或后验均值</li>
<li><strong>区间估计</strong>：可信区间（credible interval）</li>
<li><strong>预测</strong>：$P(x_{new}|D) &#x3D; \int P(x_{new}|\theta)P(\theta|D)d\theta$</li>
</ul>
<hr>
<h2 id="贝叶斯-vs-频率学派"><a href="#贝叶斯-vs-频率学派" class="headerlink" title="贝叶斯 vs 频率学派"></a>贝叶斯 vs 频率学派</h2><table>
<thead>
<tr>
<th>方面</th>
<th>贝叶斯学派</th>
<th>频率学派</th>
</tr>
</thead>
<tbody><tr>
<td><strong>参数性质</strong></td>
<td>随机变量（有分布）</td>
<td>固定未知值</td>
</tr>
<tr>
<td><strong>概率含义</strong></td>
<td>信念程度</td>
<td>长期频率</td>
</tr>
<tr>
<td><strong>推断方法</strong></td>
<td>后验分布</td>
<td>点估计 + 置信区间</td>
</tr>
<tr>
<td><strong>先验知识</strong></td>
<td>必须指定先验</td>
<td>不使用先验</td>
</tr>
<tr>
<td><strong>不确定性</strong></td>
<td>参数的概率分布</td>
<td>估计的抽样分布</td>
</tr>
<tr>
<td><strong>小样本</strong></td>
<td>可利用先验</td>
<td>可能不稳定</td>
</tr>
</tbody></table>
<h3 id="例子对比"><a href="#例子对比" class="headerlink" title="例子对比"></a>例子对比</h3><p><strong>问题</strong>：抛硬币 10 次，8 次正面，估计正面概率 $\theta$</p>
<p><strong>频率学派</strong>：</p>
<p>$$\hat{\theta}_{MLE} &#x3D; \frac{8}{10} &#x3D; 0.8$$</p>
<p><strong>贝叶斯学派</strong>（假设先验 $\theta \sim \text{Beta}(2,2)$）：</p>
<p>$$P(\theta|D) &#x3D; \text{Beta}(2+8, 2+2) &#x3D; \text{Beta}(10, 4)$$</p>
<p>后验均值：</p>
<p>$$\mathbb{E}[\theta|D] &#x3D; \frac{10}{10+4} \approx 0.71$$</p>
<p><strong>差异</strong>：贝叶斯方法考虑了先验信念（硬币应该接近公平），结果更保守。</p>
<hr>
<h2 id="在机器学习中的应用"><a href="#在机器学习中的应用" class="headerlink" title="在机器学习中的应用"></a>在机器学习中的应用</h2><h3 id="1-朴素贝叶斯分类器"><a href="#1-朴素贝叶斯分类器" class="headerlink" title="1. 朴素贝叶斯分类器"></a>1. 朴素贝叶斯分类器</h3><p>$$P(y|x_1, \ldots, x_n) &#x3D; \frac{P(y) \prod_{i&#x3D;1}^{n} P(x_i|y)}{P(x_1, \ldots, x_n)}$$</p>
<p><strong>应用</strong>：文本分类、垃圾邮件过滤</p>
<h3 id="2-贝叶斯线性回归"><a href="#2-贝叶斯线性回归" class="headerlink" title="2. 贝叶斯线性回归"></a>2. 贝叶斯线性回归</h3><p>$$P(w|D) &#x3D; \frac{P(D|w)P(w)}{P(D)}$$</p>
<p><strong>优势</strong>：提供预测的不确定性</p>
<h3 id="3-贝叶斯神经网络"><a href="#3-贝叶斯神经网络" class="headerlink" title="3. 贝叶斯神经网络"></a>3. 贝叶斯神经网络</h3><p>对网络权重建模为分布而非点估计：</p>
<p>$$P(w|D) \propto P(D|w)P(w)$$</p>
<p><strong>应用</strong>：不确定性量化、主动学习</p>
<h3 id="4-变分推断"><a href="#4-变分推断" class="headerlink" title="4. 变分推断"></a>4. 变分推断</h3><p>当后验 $P(\theta|D)$ 难以计算时，用简单分布 $q(\theta)$ 近似：</p>
<p>$$\min_q D_{KL}(q(\theta)||P(\theta|D))$$</p>
<p><strong>应用</strong>：VAE、主题模型（LDA）</p>
<h3 id="5-马尔可夫链蒙特卡洛（MCMC）"><a href="#5-马尔可夫链蒙特卡洛（MCMC）" class="headerlink" title="5. 马尔可夫链蒙特卡洛（MCMC）"></a>5. 马尔可夫链蒙特卡洛（MCMC）</h3><p>通过采样近似后验分布：</p>
<p>$$\theta^{(t+1)} \sim P(\theta|D)$$</p>
<p><strong>应用</strong>：贝叶斯深度学习、概率编程</p>
<hr>
<h2 id="先验的选择"><a href="#先验的选择" class="headerlink" title="先验的选择"></a>先验的选择</h2><h3 id="1-无信息先验（Non-informative-Prior）"><a href="#1-无信息先验（Non-informative-Prior）" class="headerlink" title="1. 无信息先验（Non-informative Prior）"></a>1. 无信息先验（Non-informative Prior）</h3><p><strong>目的</strong>：表达”无知”</p>
<p><strong>例子</strong>：</p>
<ul>
<li>均匀分布：$P(\theta) &#x3D; \text{Uniform}(a, b)$</li>
<li>Jeffreys 先验：$P(\theta) \propto \sqrt{|I(\theta)|}$（基于 Fisher 信息）</li>
</ul>
<h3 id="2-共轭先验（Conjugate-Prior）"><a href="#2-共轭先验（Conjugate-Prior）" class="headerlink" title="2. 共轭先验（Conjugate Prior）"></a>2. 共轭先验（Conjugate Prior）</h3><p><strong>定义</strong>：后验与先验同分布族</p>
<p><strong>例子</strong>：</p>
<table>
<thead>
<tr>
<th>似然</th>
<th>共轭先验</th>
<th>后验</th>
</tr>
</thead>
<tbody><tr>
<td>伯努利</td>
<td>Beta</td>
<td>Beta</td>
</tr>
<tr>
<td>正态（已知方差）</td>
<td>正态</td>
<td>正态</td>
</tr>
<tr>
<td>泊松</td>
<td>Gamma</td>
<td>Gamma</td>
</tr>
<tr>
<td>多项式</td>
<td>Dirichlet</td>
<td>Dirichlet</td>
</tr>
</tbody></table>
<p><strong>优势</strong>：后验有闭式解，计算简单</p>
<h3 id="3-正则化先验"><a href="#3-正则化先验" class="headerlink" title="3. 正则化先验"></a>3. 正则化先验</h3><p><strong>目的</strong>：防止过拟合</p>
<p><strong>例子</strong>：</p>
<ul>
<li><strong>高斯先验</strong>：$P(w) &#x3D; \mathcal{N}(0, \lambda^{-1}I)$ → L2 正则化</li>
<li><strong>拉普拉斯先验</strong>：$P(w) &#x3D; \text{Laplace}(0, b)$ → L1 正则化</li>
</ul>
<h3 id="4-经验贝叶斯（Empirical-Bayes）"><a href="#4-经验贝叶斯（Empirical-Bayes）" class="headerlink" title="4. 经验贝叶斯（Empirical Bayes）"></a>4. 经验贝叶斯（Empirical Bayes）</h3><p>从数据中估计先验的超参数：</p>
<p>$$\hat{\alpha} &#x3D; \arg\max_{\alpha} P(D|\alpha)$$</p>
<hr>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="问题-1：先验是主观的吗？"><a href="#问题-1：先验是主观的吗？" class="headerlink" title="问题 1：先验是主观的吗？"></a>问题 1：先验是主观的吗？</h3><p><strong>回答</strong>：</p>
<ul>
<li><strong>是</strong>：先验反映了建模者的信念或假设</li>
<li><strong>但</strong>：可以通过以下方式减少主观性：<ul>
<li>使用无信息先验</li>
<li>使用领域知识</li>
<li>使用经验贝叶斯</li>
<li>数据足够多时，后验主要由似然决定</li>
</ul>
</li>
</ul>
<hr>
<h3 id="问题-2：贝叶斯方法计算复杂吗？"><a href="#问题-2：贝叶斯方法计算复杂吗？" class="headerlink" title="问题 2：贝叶斯方法计算复杂吗？"></a>问题 2：贝叶斯方法计算复杂吗？</h3><p><strong>回答</strong>：</p>
<ul>
<li><strong>共轭先验</strong>：后验有闭式解，计算简单</li>
<li><strong>非共轭情况</strong>：需要近似方法<ul>
<li>变分推断（快速但近似）</li>
<li>MCMC（精确但慢）</li>
<li>拉普拉斯近似（快速但粗糙）</li>
</ul>
</li>
</ul>
<hr>
<h3 id="问题-3：为什么-P-D-叫”证据”？"><a href="#问题-3：为什么-P-D-叫”证据”？" class="headerlink" title="问题 3：为什么 P(D) 叫”证据”？"></a>问题 3：为什么 P(D) 叫”证据”？</h3><p><strong>回答</strong>：</p>
<ul>
<li>$P(D)$ 是观测数据的边缘概率</li>
<li>在模型比较中，$P(D)$ 衡量模型对数据的解释能力</li>
<li>更高的 $P(D)$ 意味着模型更好地”证明”了数据的存在</li>
</ul>
<hr>
<h3 id="问题-4：贝叶斯公式可以连续更新吗？"><a href="#问题-4：贝叶斯公式可以连续更新吗？" class="headerlink" title="问题 4：贝叶斯公式可以连续更新吗？"></a>问题 4：贝叶斯公式可以连续更新吗？</h3><p><strong>回答</strong>：可以！这是贝叶斯方法的优势。</p>
<p><strong>顺序更新</strong>：</p>
<p>$$P(\theta|D_1, D_2) &#x3D; \frac{P(D_2|\theta)P(\theta|D_1)}{P(D_2|D_1)}$$</p>
<p>前一次的后验成为下一次的先验：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">先验 → [数据1] → 后验1 → [数据2] → 后验2 → ...</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="1-选择合适的先验"><a href="#1-选择合适的先验" class="headerlink" title="1. 选择合适的先验"></a>1. 选择合适的先验</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 弱信息先验（数据主导）</span></span><br><span class="line">prior = Normal(<span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 强信息先验（先验主导）</span></span><br><span class="line">prior = Normal(<span class="number">0</span>, <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正则化先验</span></span><br><span class="line">prior = Normal(<span class="number">0</span>, <span class="number">1</span>/<span class="keyword">lambda</span>)  <span class="comment"># 等价于 L2 正则</span></span><br></pre></td></tr></table></figure>

<h3 id="2-检查先验的影响"><a href="#2-检查先验的影响" class="headerlink" title="2. 检查先验的影响"></a>2. 检查先验的影响</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先验预测检查</span></span><br><span class="line">prior_samples = prior.sample(<span class="number">1000</span>)</span><br><span class="line">prior_predictions = model(prior_samples)</span><br><span class="line"><span class="comment"># 检查先验预测是否合理</span></span><br></pre></td></tr></table></figure>

<h3 id="3-后验检查"><a href="#3-后验检查" class="headerlink" title="3. 后验检查"></a>3. 后验检查</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 后验预测检查</span></span><br><span class="line">posterior_samples = posterior.sample(<span class="number">1000</span>)</span><br><span class="line">posterior_predictions = model(posterior_samples)</span><br><span class="line"><span class="comment"># 与真实数据对比</span></span><br></pre></td></tr></table></figure>

<h3 id="4-使用对数空间计算"><a href="#4-使用对数空间计算" class="headerlink" title="4. 使用对数空间计算"></a>4. 使用对数空间计算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 避免数值下溢</span></span><br><span class="line">log_posterior = log_likelihood + log_prior - log_evidence</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><h3 id="PyTorch-实现贝叶斯线性回归"><a href="#PyTorch-实现贝叶斯线性回归" class="headerlink" title="PyTorch 实现贝叶斯线性回归"></a>PyTorch 实现贝叶斯线性回归</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.distributions <span class="keyword">as</span> dist</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据</span></span><br><span class="line">X = torch.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">y = <span class="number">3</span> * X + <span class="number">2</span> + torch.randn(<span class="number">100</span>, <span class="number">1</span>) * <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 先验</span></span><br><span class="line">prior_w = dist.Normal(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">prior_b = dist.Normal(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 似然</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">likelihood</span>(<span class="params">w, b, X, y, sigma=<span class="number">0.5</span></span>):</span><br><span class="line">    y_pred = w * X + b</span><br><span class="line">    <span class="keyword">return</span> dist.Normal(y_pred, sigma).log_prob(y).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 后验（使用变分推断近似）</span></span><br><span class="line">q_w_mu = torch.nn.Parameter(torch.randn(<span class="number">1</span>))</span><br><span class="line">q_w_sigma = torch.nn.Parameter(torch.ones(<span class="number">1</span>))</span><br><span class="line">q_b_mu = torch.nn.Parameter(torch.randn(<span class="number">1</span>))</span><br><span class="line">q_b_sigma = torch.nn.Parameter(torch.ones(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam([q_w_mu, q_w_sigma, q_b_mu, q_b_sigma], lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化 ELBO</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从变分分布采样</span></span><br><span class="line">    w = q_w_mu + q_w_sigma * torch.randn(<span class="number">1</span>)</span><br><span class="line">    b = q_b_mu + q_b_sigma * torch.randn(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ELBO = 似然 - KL散度</span></span><br><span class="line">    log_lik = likelihood(w, b, X, y)</span><br><span class="line">    kl_w = dist.kl_divergence(</span><br><span class="line">        dist.Normal(q_w_mu, q_w_sigma),</span><br><span class="line">        prior_w</span><br><span class="line">    )</span><br><span class="line">    kl_b = dist.kl_divergence(</span><br><span class="line">        dist.Normal(q_b_mu, q_b_sigma),</span><br><span class="line">        prior_b</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    elbo = log_lik - kl_w - kl_b</span><br><span class="line">    loss = -elbo</span><br><span class="line"></span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;后验均值: w=<span class="subst">&#123;q_w_mu.item():<span class="number">.2</span>f&#125;</span>, b=<span class="subst">&#123;q_b_mu.item():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="参考资源"><a href="#参考资源" class="headerlink" title="参考资源"></a>参考资源</h2><ul>
<li><a target="_blank" rel="noopener" href="http://www.stat.columbia.edu/~gelman/book/">Bayesian Data Analysis - Andrew Gelman et al.</a></li>
<li><a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning/">Pattern Recognition and Machine Learning - Christopher Bishop</a></li>
<li><a target="_blank" rel="noopener" href="https://probml.github.io/pml-book/">Probabilistic Machine Learning: An Introduction - Kevin Murphy</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers">Bayesian Methods for Hackers</a></li>
</ul>
<hr>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2026/01/29/%5BOBS%5DAI-ELBO-Variational-Inference/"><img class="fill" src="/gallery/AI.png" alt="ELBO 与变分推断" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2026-01-29T11:15:00.000Z" title="1/29/2026, 7:15:00 PM">2026-01-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2026-02-14T13:40:28.050Z" title="2/14/2026, 9:40:28 PM">2026-02-14</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">19 minutes read (About 2779 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/01/29/%5BOBS%5DAI-ELBO-Variational-Inference/">ELBO 与变分推断</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods">Variational Inference</a> | <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Evidence_lower_bound">Evidence Lower Bound</a> | <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1312.6114">VAE Paper</a></p>
<hr>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>ELBO（Evidence Lower Bound，证据下界）是变分推断中的核心概念，用于近似难以计算的边缘似然 $\log p(x)$。ELBO 提供了一个可优化的目标函数，使得复杂概率模型的训练变得可行，是现代深度生成模型（如 VAE）的理论基础。</p>
<hr>
<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="什么是-ELBO"><a href="#什么是-ELBO" class="headerlink" title="什么是 ELBO"></a>什么是 ELBO</h3><p>ELBO 是对数边缘似然 $\log p(x)$ 的下界：</p>
<p>$$\text{ELBO} &#x3D; \mathbb{E}<em>{q(z|x)}[\log p(x,z)] - \mathbb{E}</em>{q(z|x)}[\log q(z|x)]$$</p>
<p>或等价形式：</p>
<p>$$\text{ELBO} &#x3D; \mathbb{E}<em>{q(z|x)}[\log p(x|z)] - D</em>{KL}(q(z|x)||p(z))$$</p>
<p>其中：</p>
<ul>
<li>$x$ 是观测数据</li>
<li>$z$ 是隐变量</li>
<li>$q(z|x)$ 是近似后验分布（变分分布）</li>
<li>$p(z)$ 是先验分布</li>
<li>$p(x|z)$ 是似然函数</li>
</ul>
<h3 id="ELBO-的推导"><a href="#ELBO-的推导" class="headerlink" title="ELBO 的推导"></a>ELBO 的推导</h3><p><strong>目标</strong>：最大化边缘似然 $\log p(x)$</p>
<p>$$\log p(x) &#x3D; \log \int p(x,z)dz$$</p>
<p>这个积分通常难以计算。引入变分分布 $q(z|x)$：</p>
<p>$$\begin{align}<br>\log p(x) &amp;&#x3D; \log \int p(x,z)dz \<br>&amp;&#x3D; \log \int \frac{q(z|x)}{q(z|x)} p(x,z)dz \<br>&amp;&#x3D; \log \mathbb{E}<em>{q(z|x)}\left[\frac{p(x,z)}{q(z|x)}\right] \<br>&amp;\geq \mathbb{E}</em>{q(z|x)}\left[\log\frac{p(x,z)}{q(z|x)}\right] \quad \text{[Jensen 不等式]} \<br>&amp;&#x3D; \text{ELBO}<br>\end{align}$$</p>
<p><strong>关键关系</strong>：</p>
<p>$$\log p(x) &#x3D; \text{ELBO} + D_{KL}(q(z|x)||p(z|x))$$</p>
<p>由于 $D_{KL} \geq 0$，所以 ELBO 是 $\log p(x)$ 的下界。</p>
<h3 id="ELBO-的两种解释"><a href="#ELBO-的两种解释" class="headerlink" title="ELBO 的两种解释"></a>ELBO 的两种解释</h3><p><strong>解释 1：重构 + 正则化</strong></p>
<p>$$\text{ELBO} &#x3D; \underbrace{\mathbb{E}<em>{q(z|x)}[\log p(x|z)]}</em>{\text{重构项}} - \underbrace{D_{KL}(q(z|x)||p(z))}_{\text{正则化项}}$$</p>
<ul>
<li><strong>重构项</strong>：衡量模型拟合数据的能力</li>
<li><strong>正则化项</strong>：约束后验分布接近先验分布</li>
</ul>
<p><strong>解释 2：似然 - 复杂度</strong></p>
<p>$$\text{ELBO} &#x3D; \underbrace{\mathbb{E}<em>{q(z|x)}[\log p(x|z)]}</em>{\text{数据似然}} - \underbrace{D_{KL}(q(z|x)||p(z))}_{\text{模型复杂度惩罚}}$$</p>
<p>这体现了奥卡姆剃刀原则：在解释数据的同时保持模型简单。</p>
<hr>
<h2 id="为什么要优化-ELBO"><a href="#为什么要优化-ELBO" class="headerlink" title="为什么要优化 ELBO"></a>为什么要优化 ELBO</h2><h3 id="1-直接计算困难"><a href="#1-直接计算困难" class="headerlink" title="1. 直接计算困难"></a>1. 直接计算困难</h3><p>真实后验 $p(z|x) &#x3D; \frac{p(x|z)p(z)}{p(x)}$ 难以计算，因为：</p>
<p>$$p(x) &#x3D; \int p(x|z)p(z)dz$$</p>
<p>这个积分在高维空间中通常没有闭式解。</p>
<h3 id="2-等价优化"><a href="#2-等价优化" class="headerlink" title="2. 等价优化"></a>2. 等价优化</h3><p>最大化 ELBO 等价于最小化 $D_{KL}(q(z|x)||p(z|x))$：</p>
<p>$$\begin{align}<br>\log p(x) &amp;&#x3D; \text{ELBO} + D_{KL}(q(z|x)||p(z|x)) \<br>\max_q \text{ELBO} &amp;\Leftrightarrow \min_q D_{KL}(q(z|x)||p(z|x))<br>\end{align}$$</p>
<p>因为 $\log p(x)$ 不依赖于 $q$，最大化 ELBO 就是让 $q(z|x)$ 尽可能接近真实后验 $p(z|x)$。</p>
<h3 id="3-可计算性"><a href="#3-可计算性" class="headerlink" title="3. 可计算性"></a>3. 可计算性</h3><p>ELBO 可以通过蒙特卡洛采样估计：</p>
<p>$$\text{ELBO} \approx \frac{1}{L}\sum_{i&#x3D;1}^{L} \log p(x|z_i) - D_{KL}(q(z|x)||p(z))$$</p>
<p>其中 $z_i \sim q(z|x)$。</p>
<hr>
<h2 id="ELBO-在-VAE-中的应用"><a href="#ELBO-在-VAE-中的应用" class="headerlink" title="ELBO 在 VAE 中的应用"></a>ELBO 在 VAE 中的应用</h2><h3 id="VAE-架构"><a href="#VAE-架构" class="headerlink" title="VAE 架构"></a>VAE 架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">输入 x → Encoder → μ(x), σ(x) → 采样 z ~ N(μ,σ²) → Decoder → 重构 x̂</span><br></pre></td></tr></table></figure>

<h3 id="VAE-的假设"><a href="#VAE-的假设" class="headerlink" title="VAE 的假设"></a>VAE 的假设</h3><ul>
<li><strong>先验</strong>：$p(z) &#x3D; \mathcal{N}(0, I)$（标准正态分布）</li>
<li><strong>后验</strong>：$q(z|x) &#x3D; \mathcal{N}(\mu(x), \sigma^2(x)I)$（编码器输出）</li>
<li><strong>似然</strong>：$p(x|z) &#x3D; \mathcal{N}(\text{Decoder}(z), I)$（解码器输出）</li>
</ul>
<h3 id="ELBO-的具体形式"><a href="#ELBO-的具体形式" class="headerlink" title="ELBO 的具体形式"></a>ELBO 的具体形式</h3><p>$$\text{ELBO} &#x3D; \mathbb{E}<em>{q(z|x)}[\log p(x|z)] - D</em>{KL}(q(z|x)||p(z))$$</p>
<p><strong>重构项</strong>（需要采样估计）：</p>
<p>$$\mathbb{E}<em>{q(z|x)}[\log p(x|z)] \approx \frac{1}{L}\sum</em>{i&#x3D;1}^{L} \log p(x|z_i), \quad z_i \sim q(z|x)$$</p>
<p>通常 $L&#x3D;1$（单样本估计）。对于伯努利分布的似然，这等价于二元交叉熵。</p>
<p><strong>KL 项</strong>（有闭式解）：</p>
<p>$$D_{KL}(q(z|x)||p(z)) &#x3D; -\frac{1}{2}\sum_{j&#x3D;1}^{J}\left(1 + \log\sigma_j^2 - \mu_j^2 - \sigma_j^2\right)$$</p>
<p>其中 $J$ 是隐变量维度。</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>VAE 的损失函数是 <strong>负 ELBO</strong>（因为要最小化）：</p>
<p>$$\mathcal{L} &#x3D; -\text{ELBO} &#x3D; \underbrace{-\mathbb{E}<em>{q(z|x)}[\log p(x|z)]}</em>{\text{重构损失}} + \underbrace{D_{KL}(q(z|x)||p(z))}_{\text{KL 损失}}$$</p>
<hr>
<h2 id="重参数化技巧"><a href="#重参数化技巧" class="headerlink" title="重参数化技巧"></a>重参数化技巧</h2><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>直接从 $z \sim \mathcal{N}(\mu(x), \sigma^2(x))$ 采样<strong>不可微</strong>，无法反向传播。</p>
<h3 id="解决方案：重参数化"><a href="#解决方案：重参数化" class="headerlink" title="解决方案：重参数化"></a>解决方案：重参数化</h3><p><strong>核心思想</strong>：将随机性外部化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">原始：z ~ N(μ, σ²)  ❌ 不可微</span><br><span class="line"></span><br><span class="line">重参数化：</span><br><span class="line">ε ~ N(0, I)         ✓ 随机性独立于参数</span><br><span class="line">z = μ + σ ⊙ ε       ✓ 可微变换</span><br></pre></td></tr></table></figure>

<h3 id="梯度流"><a href="#梯度流" class="headerlink" title="梯度流"></a>梯度流</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">损失 → Decoder → z = μ + σε → μ, σ → Encoder</span><br><span class="line">                  ↑ 可微！</span><br></pre></td></tr></table></figure>

<ul>
<li>$\varepsilon$ 是常数（从参数角度），梯度不经过它</li>
<li>$\mu$ 和 $\sigma$ 的梯度可以正常计算</li>
</ul>
<hr>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="PyTorch-实现"><a href="#PyTorch-实现" class="headerlink" title="PyTorch 实现"></a>PyTorch 实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VAE</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim=<span class="number">784</span>, hidden_dim=<span class="number">400</span>, latent_dim=<span class="number">20</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Encoder</span></span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(input_dim, hidden_dim)</span><br><span class="line">        <span class="variable language_">self</span>.fc_mu = nn.Linear(hidden_dim, latent_dim)</span><br><span class="line">        <span class="variable language_">self</span>.fc_logvar = nn.Linear(hidden_dim, latent_dim)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Decoder</span></span><br><span class="line">        <span class="variable language_">self</span>.fc3 = nn.Linear(latent_dim, hidden_dim)</span><br><span class="line">        <span class="variable language_">self</span>.fc4 = nn.Linear(hidden_dim, input_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;编码器：x → μ, log(σ²)&quot;&quot;&quot;</span></span><br><span class="line">        h = torch.relu(<span class="variable language_">self</span>.fc1(x))</span><br><span class="line">        mu = <span class="variable language_">self</span>.fc_mu(h)</span><br><span class="line">        logvar = <span class="variable language_">self</span>.fc_logvar(h)  <span class="comment"># log(σ²) 数值稳定</span></span><br><span class="line">        <span class="keyword">return</span> mu, logvar</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reparameterize</span>(<span class="params">self, mu, logvar</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;重参数化技巧：z = μ + σε&quot;&quot;&quot;</span></span><br><span class="line">        std = torch.exp(<span class="number">0.5</span> * logvar)  <span class="comment"># σ = exp(0.5*log(σ²))</span></span><br><span class="line">        eps = torch.randn_like(std)     <span class="comment"># ε ~ N(0,I)</span></span><br><span class="line">        z = mu + eps * std              <span class="comment"># z = μ + σε</span></span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, z</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;解码器：z → x��&quot;&quot;&quot;</span></span><br><span class="line">        h = torch.relu(<span class="variable language_">self</span>.fc3(z))</span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(<span class="variable language_">self</span>.fc4(h))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        mu, logvar = <span class="variable language_">self</span>.encode(x)</span><br><span class="line">        z = <span class="variable language_">self</span>.reparameterize(mu, logvar)</span><br><span class="line">        recon_x = <span class="variable language_">self</span>.decode(z)</span><br><span class="line">        <span class="keyword">return</span> recon_x, mu, logvar</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vae_loss</span>(<span class="params">recon_x, x, mu, logvar</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    VAE 损失函数 = -ELBO</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        recon_x: 重构的 x</span></span><br><span class="line"><span class="string">        x: 原始 x</span></span><br><span class="line"><span class="string">        mu: 编码器输出的均值</span></span><br><span class="line"><span class="string">        logvar: 编码器输出的 log(σ²)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        总损失 = 重构损失 + KL 损失</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 重构损失：-E[log p(x|z)]</span></span><br><span class="line">    <span class="comment"># 对于伯努利分布 = 二元交叉熵</span></span><br><span class="line">    BCE = F.binary_cross_entropy(recon_x, x, reduction=<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># KL 散度：KL(q(z|x)||p(z))</span></span><br><span class="line">    <span class="comment"># 闭式解：-0.5 * Σ(1 + log(σ²) - μ² - σ²)</span></span><br><span class="line">    KLD = -<span class="number">0.5</span> * torch.<span class="built_in">sum</span>(<span class="number">1</span> + logvar - mu.<span class="built_in">pow</span>(<span class="number">2</span>) - logvar.exp())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> BCE + KLD</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练循环</span></span><br><span class="line">model = VAE()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch_x <span class="keyword">in</span> dataloader:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        recon_x, mu, logvar = model(batch_x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算损失（负 ELBO）</span></span><br><span class="line">        loss = vae_loss(recon_x, batch_x, mu, logvar)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></table></figure>

<h3 id="关键实现细节"><a href="#关键实现细节" class="headerlink" title="关键实现细节"></a>关键实现细节</h3><ol>
<li><strong>使用 log(σ²) 而非 σ</strong>：数值稳定性更好</li>
<li><strong>KL 散度的闭式解</strong>：避免采样估计</li>
<li><strong>重参数化</strong>：使采样过程可微</li>
<li><strong>单样本估计</strong>：重构项通常只采样一次</li>
</ol>
<hr>
<h2 id="正则化的作用"><a href="#正则化的作用" class="headerlink" title="正则化的作用"></a>正则化的作用</h2><h3 id="什么是正则化"><a href="#什么是正则化" class="headerlink" title="什么是正则化"></a>什么是正则化</h3><p>正则化是防止模型过拟合的技术，通过约束模型复杂度：</p>
<p>$$\text{损失函数} &#x3D; \text{数据拟合项} + \lambda \times \text{正则化项}$$</p>
<p><strong>常见类型</strong>：</p>
<ul>
<li><strong>L2 正则</strong>：$\lambda||w||^2$ - 权重衰减</li>
<li><strong>L1 正则</strong>：$\lambda||w||$ - 稀疏性</li>
<li><strong>Dropout</strong>：随机关闭神经元</li>
<li><strong>Early Stopping</strong>：提前停止训练</li>
</ul>
<h3 id="VAE-中的正则化"><a href="#VAE-中的正则化" class="headerlink" title="VAE 中的正则化"></a>VAE 中的正则化</h3><p>ELBO 天然包含正则化：</p>
<p>$$\text{ELBO} &#x3D; \underbrace{\mathbb{E}[\log p(x|z)]}<em>{\text{拟合数据}} - \underbrace{D</em>{KL}(q(z|x)||p(z))}_{\text{正则化}}$$</p>
<p><strong>KL 散度项的作用</strong>：</p>
<ol>
<li><strong>约束隐空间结构</strong>：强制 $q(z|x)$ 接近先验 $p(z) &#x3D; \mathcal{N}(0,I)$</li>
<li>**防止编码器”作弊”**：避免为每个样本学习独特的、互不相关的编码</li>
<li><strong>保证连续性</strong>：使隐空间平滑、可插值</li>
<li><strong>实现解耦表示</strong>：鼓励学习独立的隐变量</li>
</ol>
<h3 id="没有-KL-正则化会怎样？"><a href="#没有-KL-正则化会怎样？" class="headerlink" title="没有 KL 正则化会怎样？"></a>没有 KL 正则化会怎样？</h3><p>如果只优化重构损失：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = reconstruction_loss  <span class="comment"># 没有 KL 项</span></span><br></pre></td></tr></table></figure>

<p><strong>问题</strong>：</p>
<ul>
<li>编码器可能���每个样本映射到隐空间的任意位置</li>
<li>隐空间结构混乱，无法生成新样本</li>
<li>方差 $\sigma$ 可能趋近于 0（退化为确定性编码）</li>
</ul>
<p><strong>KL 正则化的效果</strong>：</p>
<ul>
<li>强制隐变量分布接近标准正态分布</li>
<li>保证隐空间的连续性和平滑性</li>
<li>使得从先验 $p(z)$ 采样可以生成有意义的样本</li>
</ul>
<hr>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><h3 id="1-变分自编码器（VAE）"><a href="#1-变分自编码器（VAE）" class="headerlink" title="1. 变分自编码器（VAE）"></a>1. 变分自编码器（VAE）</h3><p><strong>用途</strong>：生成模型、表示学习</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练后生成新样本</span></span><br><span class="line">z = torch.randn(batch_size, latent_dim)  <span class="comment"># 从先验采样</span></span><br><span class="line">generated_x = model.decode(z)</span><br></pre></td></tr></table></figure>

<h3 id="2-主题模型（LDA）"><a href="#2-主题模型（LDA）" class="headerlink" title="2. 主题模型（LDA）"></a>2. 主题模型（LDA）</h3><p><strong>用途</strong>：文档主题发现</p>
<ul>
<li>隐变量 $z$：文档的主题分布</li>
<li>ELBO 用于推断主题</li>
</ul>
<h3 id="3-贝叶斯神经网络"><a href="#3-贝叶斯神经网络" class="headerlink" title="3. 贝叶斯神经网络"></a>3. 贝叶斯神经网络</h3><p><strong>用途</strong>：不确定性量化</p>
<ul>
<li>隐变量 $z$：网络权重</li>
<li>ELBO 用于近似权重的后验分布</li>
</ul>
<h3 id="4-隐马尔可夫模型（HMM）"><a href="#4-隐马尔可夫模型（HMM）" class="headerlink" title="4. 隐马尔可夫模型（HMM）"></a>4. 隐马尔可夫模型（HMM）</h3><p><strong>用途</strong>：序列建模</p>
<ul>
<li>隐变量 $z$：隐藏状态序列</li>
<li>ELBO 用于推断状态</li>
</ul>
<h3 id="5-高斯混合模型（GMM）"><a href="#5-高斯混合模型（GMM）" class="headerlink" title="5. 高斯混合模型（GMM）"></a>5. 高斯混合模型（GMM）</h3><p><strong>用途</strong>：聚类分析</p>
<ul>
<li>隐变量 $z$：样本所属的簇</li>
<li>ELBO 用于推断簇分配</li>
</ul>
<hr>
<h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="1-平衡重构与-KL-损失"><a href="#1-平衡重构与-KL-损失" class="headerlink" title="1. 平衡重构与 KL 损失"></a>1. 平衡重构与 KL 损失</h3><p>有时需要调整 KL 项的权重：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = reconstruction_loss + beta * kl_loss  <span class="comment"># β-VAE</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>β &lt; 1</strong>：更注重重构质量</li>
<li><strong>β &gt; 1</strong>：更注重解耦表示</li>
<li><strong>β &#x3D; 1</strong>：标准 VAE</li>
</ul>
<h3 id="2-KL-退火（KL-Annealing）"><a href="#2-KL-退火（KL-Annealing）" class="headerlink" title="2. KL 退火（KL Annealing）"></a>2. KL 退火（KL Annealing）</h3><p>训练初期降低 KL 权重，逐渐增加：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">beta = <span class="built_in">min</span>(<span class="number">1.0</span>, epoch / warmup_epochs)</span><br><span class="line">loss = reconstruction_loss + beta * kl_loss</span><br></pre></td></tr></table></figure>

<p><strong>原因</strong>：避免”后验坍缩”（posterior collapse），即 $q(z|x)$ 过早收敛到先验。</p>
<h3 id="3-自由比特（Free-Bits）"><a href="#3-自由比特（Free-Bits）" class="headerlink" title="3. 自由比特（Free Bits）"></a>3. 自由比特（Free Bits）</h3><p>为每个隐变量维度设置最小 KL 值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kl_per_dim = kl_loss / latent_dim</span><br><span class="line">kl_loss = torch.<span class="built_in">sum</span>(torch.<span class="built_in">max</span>(kl_per_dim, free_bits_threshold))</span><br></pre></td></tr></table></figure>

<p><strong>作用</strong>：防止某些维度被忽略。</p>
<h3 id="4-数值稳定性"><a href="#4-数值稳定性" class="headerlink" title="4. 数值稳定性"></a>4. 数值稳定性</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 log(σ²) 而非 σ</span></span><br><span class="line">logvar = <span class="variable language_">self</span>.fc_logvar(h)</span><br><span class="line">std = torch.exp(<span class="number">0.5</span> * logvar)  <span class="comment"># 避免负数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 避免 log(0)</span></span><br><span class="line">recon_x = torch.clamp(recon_x, <span class="built_in">min</span>=<span class="number">1e-7</span>, <span class="built_in">max</span>=<span class="number">1</span>-<span class="number">1e-7</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="问题-1：ELBO-为什么是下界？"><a href="#问题-1：ELBO-为什么是下界？" class="headerlink" title="问题 1：ELBO 为什么是下界？"></a>问题 1：ELBO 为什么是下界？</h3><p><strong>解答</strong>：根据 Jensen 不等式，对于凹函数 $\log$：</p>
<p>$$\log \mathbb{E}[X] \geq \mathbb{E}[\log X]$$</p>
<p>因此：</p>
<p>$$\log p(x) &#x3D; \log \mathbb{E}<em>{q(z|x)}\left[\frac{p(x,z)}{q(z|x)}\right] \geq \mathbb{E}</em>{q(z|x)}\left[\log\frac{p(x,z)}{q(z|x)}\right] &#x3D; \text{ELBO}$$</p>
<hr>
<h3 id="问题-2：为什么叫”证据”下界？"><a href="#问题-2：为什么叫”证据”下界？" class="headerlink" title="问题 2：为什么叫”证据”下界？"></a>问题 2：为什么叫”证据”下界？</h3><p><strong>解答</strong>：在贝叶斯推断中，$p(x)$ 被称为”证据”（evidence）或”边缘似然”（marginal likelihood），因为它是观测数据 $x$ 的概率。ELBO 是这个证据的下界。</p>
<hr>
<h3 id="问题-3：重参数化技巧为什么有效？"><a href="#问题-3：重参数化技巧为什么有效？" class="headerlink" title="问题 3：重参数化技巧为什么有效？"></a>问题 3：重参数化技巧为什么有效？</h3><p><strong>解答</strong>：重参数化将随机性从参数中分离出来：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z = μ(x; θ) + σ(x; θ) ⊙ ε,  ε ~ N(0,I)</span><br></pre></td></tr></table></figure>

<ul>
<li>$\varepsilon$ 不依赖于 $\theta$，是外部噪声</li>
<li>$\mu$ 和 $\sigma$ 依赖于 $\theta$，可以求梯度</li>
<li>梯度可以通过 $\mu$ 和 $\sigma$ 反向传播到编码器</li>
</ul>
<hr>
<h3 id="问题-4：VAE-生成的图像为什么模糊？"><a href="#问题-4：VAE-生成的图像为什么模糊？" class="headerlink" title="问题 4：VAE 生成的图像为什么模糊？"></a>问题 4：VAE 生成的图像为什么模糊？</h3><p><strong>原因</strong>：</p>
<ol>
<li><strong>高斯似然假设</strong>：$p(x|z) &#x3D; \mathcal{N}(\text{Decoder}(z), I)$ 倾向于生成平均化的结果</li>
<li><strong>重构损失</strong>：MSE 或 BCE 惩罚像素级差异，导致模糊</li>
</ol>
<p><strong>改进方法</strong>：</p>
<ul>
<li>使用更复杂的似然分布（如混合高斯）</li>
<li>使用感知损失（perceptual loss）</li>
<li>结合 GAN（VAE-GAN）</li>
</ul>
<hr>
<h2 id="参考资源"><a href="#参考资源" class="headerlink" title="参考资源"></a>参考资源</h2><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1312.6114">Auto-Encoding Variational Bayes (VAE 原论文)</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.05908">Tutorial on Variational Autoencoders</a></li>
<li><a target="_blank" rel="noopener" href="https://openreview.net/forum?id=Sy2fzU9gl">β-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1804.03599">Understanding disentangling in β-VAE</a></li>
<li><a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning/">Pattern Recognition and Machine Learning - Christopher Bishop</a></li>
</ul>
<hr>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2026/01/29/%5BOBS%5DAI-KL-Divergence-Basics/"><img class="fill" src="/gallery/AI.png" alt="KL 散度基础理论与数学推导" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2026-01-29T11:00:00.000Z" title="1/29/2026, 7:00:00 PM">2026-01-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2026-02-14T13:40:28.054Z" title="2/14/2026, 9:40:28 PM">2026-02-14</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">19 minutes read (About 2920 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/01/29/%5BOBS%5DAI-KL-Divergence-Basics/">KL 散度基础理论与数学推导</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Information_theory">Information Theory</a> | <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback-Leibler Divergence</a></p>
<hr>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>KL 散度（Kullback-Leibler Divergence），也称为<strong>相对熵</strong>（Relative Entropy），是信息论和统计学中用于衡量两个概率分布差异的重要度量。它在机器学习、深度学习、变分推断等领域有广泛应用。<br>本笔记重点介绍 KL 散度的基础定义、数学推导、核心性质以及其在机器学习中的意义。</p>
<hr>
<h2 id="数学定义"><a href="#数学定义" class="headerlink" title="数学定义"></a>数学定义</h2><h3 id="离散概率分布"><a href="#离散概率分布" class="headerlink" title="离散概率分布"></a>离散概率分布</h3><p>对于离散概率分布 $P$ 和 $Q$，KL 散度定义为：</p>
<p>$$D_{KL}(P||Q) &#x3D; \sum_{x} P(x) \log\frac{P(x)}{Q(x)}$$</p>
<h3 id="连续概率分布"><a href="#连续概率分布" class="headerlink" title="连续概率分布"></a>连续概率分布</h3><p>对于连续概率分布，KL 散度定义为：</p>
<p>$$D_{KL}(P||Q) &#x3D; \int p(x) \log\frac{p(x)}{q(x)} dx$$</p>
<p>其中：</p>
<ul>
<li>$P$ 是真实分布（或目标分布）</li>
<li>$Q$ 是近似分布（或模型分布）</li>
<li>$\log$ 通常使用自然对数（以 $e$ 为底），单位为 nats；使用以 2 为底的对数时，单位为 bits</li>
</ul>
<hr>
<h2 id="核心性质"><a href="#核心性质" class="headerlink" title="核心性质"></a>核心性质</h2><h3 id="1-非负性"><a href="#1-非负性" class="headerlink" title="1. 非负性"></a>1. 非负性</h3><p>$$D_{KL}(P||Q) \geq 0$$</p>
<p>当��仅当 $P &#x3D; Q$ 时，等号成立（即 $D_{KL}(P||Q) &#x3D; 0$）。</p>
<h3 id="2-非对称性"><a href="#2-非对称性" class="headerlink" title="2. 非对称性"></a>2. 非对称性</h3><p>$$D_{KL}(P||Q) \neq D_{KL}(Q||P)$$</p>
<p>这意味着 KL 散度<strong>不是真正的距离度量</strong>，因为它不满足对称性。</p>
<h3 id="3-不满足三角不等式"><a href="#3-不满足三角不等式" class="headerlink" title="3. 不满足三角不等式"></a>3. 不满足三角不等式</h3><p>KL 散度不满足三角不等式：</p>
<p>$$D_{KL}(P||R) \not\leq D_{KL}(P||Q) + D_{KL}(Q||R)$$</p>
<p>因此，KL 散度不是度量空间中的距离函数。</p>
<h3 id="4-凸性"><a href="#4-凸性" class="headerlink" title="4. 凸性"></a>4. 凸性</h3><p>KL 散度关于第一个参数 $P$ 是凸函数。</p>
<hr>
<h2 id="直观理解"><a href="#直观理解" class="headerlink" title="直观理解"></a>直观理解</h2><h3 id="信息论角度"><a href="#信息论角度" class="headerlink" title="信息论角度"></a>信息论角度</h3><p>KL 散度表示：<strong>用分布 $Q$ 来编码分布 $P$ 的样本时，相比用 $P$ 自身编码所需的额外信息量</strong>（以比特或 nats 为单位）。</p>
<ul>
<li>如果 $Q$ 与 $P$ 完全相同，则不需要额外信息，$D_{KL}(P||Q) &#x3D; 0$</li>
<li>如果 $Q$ 与 $P$ 差异很大，则需要更多额外信息来补偿编码效率的损失</li>
</ul>
<h3 id="统计学角度"><a href="#统计学角度" class="headerlink" title="统计学角度"></a>统计学角度</h3><p>KL 散度衡量<strong>分布 $Q$ 对分布 $P$ 的近似程度</strong>：</p>
<ul>
<li>值越小，$Q$ 越接近 $P$</li>
<li>值越大，$Q$ 与 $P$ 的差异越大</li>
</ul>
<h3 id="机器学习角度"><a href="#机器学习角度" class="headerlink" title="机器学习角度"></a>机器学习角度</h3><p>在机器学习中，通常：</p>
<ul>
<li>$P$ 是真实数据分布（未知但可以从数据中采样）</li>
<li>$Q$ 是模型学习的分布（由参数 $\theta$ 决定）</li>
<li>最小化 $D_{KL}(P||Q)$ 等价于让模型分布尽可能接近真实分布</li>
</ul>
<hr>
<h2 id="数学推导"><a href="#数学推导" class="headerlink" title="数学推导"></a>数学推导</h2><h3 id="1-从信息熵推导"><a href="#1-从信息熵推导" class="headerlink" title="1. 从信息熵推导"></a>1. 从信息熵推导</h3><h4 id="信息熵（Entropy）"><a href="#信息熵（Entropy）" class="headerlink" title="信息熵（Entropy）"></a>信息熵（Entropy）</h4><p>分布 $P$ 的信息熵定义为：</p>
<p>$$H(P) &#x3D; -\sum_{x} P(x) \log P(x)$$</p>
<p>它表示编码分布 $P$ 的样本所需的<strong>平均最小比特数</strong>。</p>
<h4 id="交叉熵（Cross-Entropy）"><a href="#交叉熵（Cross-Entropy）" class="headerlink" title="交叉熵（Cross Entropy）"></a>交叉熵（Cross Entropy）</h4><p>用分布 $Q$ 来编码分布 $P$ 的样本所需的平均比特数：</p>
<p>$$H(P, Q) &#x3D; -\sum_{x} P(x) \log Q(x)$$</p>
<h4 id="KL-散度-x3D-交叉熵-信息熵"><a href="#KL-散度-x3D-交叉熵-信息熵" class="headerlink" title="KL 散度 &#x3D; 交叉熵 - 信息熵"></a>KL 散度 &#x3D; 交叉熵 - 信息熵</h4><p>$$\begin{align}<br>D_{KL}(P||Q) &amp;&#x3D; H(P, Q) - H(P) \<br>&amp;&#x3D; -\sum_{x} P(x) \log Q(x) + \sum_{x} P(x) \log P(x) \<br>&amp;&#x3D; \sum_{x} P(x) [\log P(x) - \log Q(x)] \<br>&amp;&#x3D; \sum_{x} P(x) \log\frac{P(x)}{Q(x)}<br>\end{align}$$</p>
<p>这表明 KL 散度是<strong>使用次优编码方案 $Q$ 相比最优编码方案 $P$ 所需的额外信息量</strong>。</p>
<hr>
<h3 id="2-非负性证明（Gibbs-不等式）"><a href="#2-非负性证明（Gibbs-不等式）" class="headerlink" title="2. 非负性证明（Gibbs 不等式）"></a>2. 非负性证明（Gibbs 不等式）</h3><p>我们使用 <strong>Jensen 不等式</strong>来证明 KL 散度的非负性。</p>
<h4 id="Jensen-不等式"><a href="#Jensen-不等式" class="headerlink" title="Jensen 不等式"></a>Jensen 不等式</h4><p>对于凸函数 $f(x)$ 和概率分布 $P$：</p>
<p>$$f\left(\sum_{x} P(x) \cdot x\right) \leq \sum_{x} P(x) \cdot f(x)$$</p>
<p>对于凹函数（如 $\log$），不等号反向。</p>
<h4 id="证明过程"><a href="#证明过程" class="headerlink" title="证明过程"></a>证明过程</h4><p>由于 $f(x) &#x3D; -\log(x)$ 是凸函数，我们有：</p>
<p>$$\begin{align}<br>D_{KL}(P||Q) &amp;&#x3D; \sum_{x} P(x) \log\frac{P(x)}{Q(x)} \<br>&amp;&#x3D; -\sum_{x} P(x) \log\frac{Q(x)}{P(x)} \<br>&amp;\geq -\log\left(\sum_{x} P(x) \cdot \frac{Q(x)}{P(x)}\right) \quad \text{[Jensen 不等式]} \<br>&amp;&#x3D; -\log\left(\sum_{x} Q(x)\right) \<br>&amp;&#x3D; -\log(1) \<br>&amp;&#x3D; 0<br>\end{align}$$</p>
<p>等号成立当且仅当 $\frac{Q(x)}{P(x)}$ 为常数，即 $P(x) &#x3D; Q(x)$ 对所有 $x$ 成立。</p>
<p><strong>结论</strong>：$D_{KL}(P||Q) \geq 0$，且仅当 $P &#x3D; Q$ 时等号成立。</p>
<hr>
<h3 id="3-与最大似然估计的关系"><a href="#3-与最大似然估计的关系" class="headerlink" title="3. 与最大似然估计的关系"></a>3. 与最大似然估计的关系</h3><p>在机器学习中，我们通常希望找到参数 $\theta$ 使得模型分布 $P_\theta$ 尽可能接近真实数据分布 $P_{data}$。</p>
<h4 id="最小化-KL-散度"><a href="#最小化-KL-散度" class="headerlink" title="最小化 KL 散度"></a>最小化 KL 散度</h4><p>$$\begin{align}<br>\min_\theta D_{KL}(P_{data}||P_\theta) &amp;&#x3D; \min_\theta \sum_{x} P_{data}(x) \log\frac{P_{data}(x)}{P_\theta(x)} \<br>&amp;&#x3D; \min_\theta \left[\sum_{x} P_{data}(x) \log P_{data}(x) - \sum_{x} P_{data}(x) \log P_\theta(x)\right] \<br>&amp;&#x3D; \min_\theta \left[-\sum_{x} P_{data}(x) \log P_\theta(x)\right] \quad \text{[第一项与 $\theta$ 无关]} \<br>&amp;&#x3D; \max_\theta \sum_{x} P_{data}(x) \log P_\theta(x)<br>\end{align}$$</p>
<h4 id="经验分布近似"><a href="#经验分布近似" class="headerlink" title="经验分布近似"></a>经验分布近似</h4><p>在实践中，我们无法直接访问 $P_{data}$，但可以从数据集 ${x_1, x_2, \ldots, x_N}$ 中采样。使用经验分布：<br>$$P_{data}(x) \approx \frac{1}{N} \sum_{i&#x3D;1}^{N} \delta(x - x_i)$$</p>
<p>代入上式：</p>
<p>$$\max_\theta \sum_{x} P_{data}(x) \log P_\theta(x) \approx \max_\theta \frac{1}{N} \sum_{i&#x3D;1}^{N} \log P_\theta(x_i)$$</p>
<p>这正是最大似然估计（Maximum Likelihood Estimation, MLE）的目标函数！<br>结论：最小化 KL 散度等价于最大化似然函数。</p>
<hr>
<h2 id="实际计算示例"><a href="#实际计算示例" class="headerlink" title="实际计算示例"></a>实际计算示例</h2><h3 id="示例-1：离散分布"><a href="#示例-1：离散分布" class="headerlink" title="示例 1：离散分布"></a>示例 1：离散分布</h3><p>假设真实分布 $P &#x3D; [0.5, 0.3, 0.2]$，近似分布 $Q &#x3D; [0.4, 0.4, 0.2]$。</p>
<p>计算 $D_{KL}(P||Q)$：</p>
<p>$$\begin{align}<br>D_{KL}(P||Q) &amp;&#x3D; 0.5 \cdot \log\frac{0.5}{0.4} + 0.3 \cdot \log\frac{0.3}{0.4} + 0.2 \cdot \log\frac{0.2}{0.2} \<br>&amp;&#x3D; 0.5 \cdot \log(1.25) + 0.3 \cdot \log(0.75) + 0.2 \cdot \log(1) \<br>&amp;&#x3D; 0.5 \times 0.2231 + 0.3 \times (-0.2877) + 0 \<br>&amp;&#x3D; 0.1116 - 0.0863 \<br>&amp;\approx 0.0253 \text{ nats}<br>\end{align}$$</p>
<p>转换为 bits（除以 $\ln 2 \approx 0.693$）：</p>
<p>$$D_{KL}(P||Q) \approx 0.0365 \text{ bits}$$</p>
<h3 id="示例-2：高斯分布"><a href="#示例-2：高斯分布" class="headerlink" title="示例 2：高斯分布"></a>示例 2：高斯分布</h3><p>对于两个一维高斯分布：</p>
<ul>
<li>$P &#x3D; \mathcal{N}(\mu_1, \sigma_1^2)$</li>
<li>$Q &#x3D; \mathcal{N}(\mu_2, \sigma_2^2)$</li>
</ul>
<p>KL 散度的闭式解为：</p>
<p>$$D_{KL}(P||Q) &#x3D; \log\frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2\sigma_2^2} - \frac{1}{2}$$</p>
<p><strong>特殊情况</strong>：当 $Q &#x3D; \mathcal{N}(0, 1)$（标准正态分布）时：</p>
<p>$$D_{KL}(P||Q) &#x3D; \frac{1}{2}\left(\mu_1^2 + \sigma_1^2 - \log\sigma_1^2 - 1\right)$$</p>
<p>这个公式在 VAE（变分自编码器）中被广泛使用。</p>
<hr>
<h2 id="机器学习中的应用"><a href="#机器学习中的应用" class="headerlink" title="机器学习中的应用"></a>机器学习中的应用</h2><h3 id="1-变分推断（Variational-Inference）"><a href="#1-变分推断（Variational-Inference）" class="headerlink" title="1. 变分推断（Variational Inference）"></a>1. 变分推断（Variational Inference）</h3><p>在贝叶斯推断中，我们希望计算后验分布 $P(\theta|X)$，但通常难以直接计算。变分推断使用一个简单的分布 $Q(\theta)$ 来近似：<br>$$\min_Q D_{KL}(Q(\theta)||P(\theta|X))$$</p>
<h3 id="2-变分自编码器（VAE）"><a href="#2-变分自编码器（VAE）" class="headerlink" title="2. 变分自编码器（VAE）"></a>2. 变分自编码器（VAE）</h3><p>VAE 的损失函数包含 KL 散度项，用于正则化潜在空间：</p>
<p>$$\mathcal{L} &#x3D; \mathbb{E}<em>{q(z|x)}[\log p(x|z)] - D</em>{KL}(q(z|x)||p(z))$$</p>
<p>其中：</p>
<ul>
<li>第一项是重建损失</li>
<li>第二项是 KL 散度，约束编码器输出接近先验分布</li>
</ul>
<h3 id="3-策略优化（强化学习）"><a href="#3-策略优化（强化学习）" class="headerlink" title="3. 策略优化（强化学习）"></a>3. 策略优化（强化学习）</h3><p>在强化学习中，KL 散度用于约束策略更新的幅度：<br>$$\max_\theta \mathbb{E}<em>{\pi_\theta}[R] \quad \text{s.t.} \quad D</em>{KL}(\pi_{old}||\pi_\theta) \leq \delta$$</p>
<p>这是 TRPO（Trust Region Policy Optimization）和 PPO（Proximal Policy Optimization）的核心思想。</p>
<h3 id="4-模型蒸馏（Knowledge-Distillation）"><a href="#4-模型蒸馏（Knowledge-Distillation）" class="headerlink" title="4. 模型蒸馏（Knowledge Distillation）"></a>4. 模型蒸馏（Knowledge Distillation）</h3><p>使用 KL 散度让小模型（学生）学习大模型（教师）的输出分布：</p>
<p>$$\mathcal{L} &#x3D; D_{KL}(P_{teacher}||P_{student})$$</p>
<h3 id="5-生成对抗网络（GAN）"><a href="#5-生成对抗网络（GAN）" class="headerlink" title="5. 生成对抗网络（GAN）"></a>5. 生成对抗网络（GAN）</h3><p>虽然 GAN 不直接优化 KL 散度，但理论分析表明，GAN 的目标函数与 JS 散度（Jensen-Shannon Divergence）相关，而 JS 散度是基于 KL 散度定义的：</p>
<p>$$D_{JS}(P||Q) &#x3D; \frac{1}{2}D_{KL}(P||M) + \frac{1}{2}D_{KL}(Q||M)$$</p>
<p>其中 $M &#x3D; \frac{1}{2}(P + Q)$。</p>
<hr>
<h2 id="前向-KL-与反向-KL"><a href="#前向-KL-与反向-KL" class="headerlink" title="前向 KL 与反向 KL"></a>前向 KL 与反向 KL</h2><h3 id="前向-KL：-D-KL-P-Q"><a href="#前向-KL：-D-KL-P-Q" class="headerlink" title="前向 KL：$D_{KL}(P||Q)$"></a>前向 KL：$D_{KL}(P||Q)$</h3><ul>
<li><strong>含义</strong>：用 $Q$ 近似 $P$</li>
<li><strong>特点</strong>：<ul>
<li>当 $P(x) &gt; 0$ 但 $Q(x) &#x3D; 0$ 时，散度为无穷大</li>
<li>要求 $Q$ 覆盖 $P$ 的所有支撑集（zero-avoiding）</li>
<li>$Q$ 倾向于覆盖 $P$ 的所有模式，可能过于分散</li>
</ul>
</li>
</ul>
<h3 id="反向-KL：-D-KL-Q-P"><a href="#反向-KL：-D-KL-Q-P" class="headerlink" title="反向 KL：$D_{KL}(Q||P)$"></a>反向 KL：$D_{KL}(Q||P)$</h3><ul>
<li><strong>含义</strong>：用 $Q$ 近似 $P$（但优化方向相反）</li>
<li><strong>特点</strong>：<ul>
<li>当 $Q(x) &gt; 0$ 但 $P(x) &#x3D; 0$ 时，散度为无穷大</li>
<li>要求 $Q$ 集中在 $P$ 的高概率区域（zero-forcing）</li>
<li>$Q$ 倾向于选择 $P$ 的某一个模式，可能过于集中</li>
</ul>
</li>
</ul>
<h3 id="对比表格"><a href="#对比表格" class="headerlink" title="对比表格"></a>对比表格</h3><table>
<thead>
<tr>
<th>特性</th>
<th>前向 KL $D_{KL}(P||Q)$</th>
<th>反向 KL $D_{KL}(Q||P)$</th>
</tr>
</thead>
<tbody><tr>
<td><strong>优化目标</strong></td>
<td>最大似然估计</td>
<td>变分推断</td>
</tr>
<tr>
<td><strong>行为</strong></td>
<td>Zero-avoiding（避免零概率）</td>
<td>Zero-forcing（强制零概率）</td>
</tr>
<tr>
<td><strong>多模态处理</strong></td>
<td>覆盖所有模式（分散）</td>
<td>选择单一模式（集中）</td>
</tr>
<tr>
<td><strong>应用</strong></td>
<td>监督学习、MLE</td>
<td>VAE、变分推断</td>
</tr>
</tbody></table>
<hr>
<h2 id="与其他散度的关系"><a href="#与其他散度的关系" class="headerlink" title="与其他散度的关系"></a>与其他散度的关系</h2><h3 id="1-JS-散度（Jensen-Shannon-Divergence）"><a href="#1-JS-散度（Jensen-Shannon-Divergence）" class="headerlink" title="1. JS 散度（Jensen-Shannon Divergence）"></a>1. JS 散度（Jensen-Shannon Divergence）</h3><p>JS 散度是 KL 散度的对称化版本：</p>
<p>$$D_{JS}(P||Q) &#x3D; \frac{1}{2}D_{KL}(P||M) + \frac{1}{2}D_{KL}(Q||M)$$<br>其中 $M &#x3D; \frac{1}{2}(P + Q)$。<br><strong>性质</strong>：</p>
<ul>
<li>对称：$D_{JS}(P||Q) &#x3D; D_{JS}(Q||P)$</li>
<li>有界：$0 \leq D_{JS}(P||Q) \leq \log 2$</li>
<li>满足三角不等式的平方根</li>
</ul>
<h3 id="2-Wasserstein-距离"><a href="#2-Wasserstein-距离" class="headerlink" title="2. Wasserstein 距离"></a>2. Wasserstein 距离</h3><p>Wasserstein 距离（也称为 Earth Mover’s Distance）是另一种衡量分布差异的度量，在 GAN 中被广泛使用（WGAN）。<br>与 KL 散度相比：</p>
<ul>
<li>Wasserstein 距离是真正的度量（满足对称性和三角不等式）</li>
<li>即使两个分布没有重叠，Wasserstein 距离仍然有意义</li>
<li>KL 散度在分布不重叠时可能为无穷大</li>
</ul>
<h3 id="3-chi-2-散度"><a href="#3-chi-2-散度" class="headerlink" title="3. $\chi^2$ 散度"></a>3. $\chi^2$ 散度</h3><p>$$D_{\chi^2}(P||Q) &#x3D; \sum_{x} \frac{(P(x) - Q(x))^2}{Q(x)}$$<br>与 KL 散度相比，$\chi^2$ 散度对分布差异更敏感。</p>
<hr>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="问题-1：为什么-KL-散度不对称？"><a href="#问题-1：为什么-KL-散度不对称？" class="headerlink" title="问题 1：为什么 KL 散度不对称？"></a>问题 1：为什么 KL 散度不对称？</h3><p><strong>原因</strong>：KL 散度的定义中，$P$ 和 $Q$ 的角色不同：</p>
<p>$$D_{KL}(P||Q) &#x3D; \sum_{x} P(x) \log\frac{P(x)}{Q(x)}$$</p>
<ul>
<li>$P$ 作为权重出现在求和中</li>
<li>$Q$ 出现在对数的分母中</li>
</ul>
<p>交换 $P$ 和 $Q$ 会得到不同的结果。</p>
<p><strong>直观理解</strong>：</p>
<ul>
<li>$D_{KL}(P||Q)$ 衡量”用 $Q$ 编码 $P$ 的样本”的额外信息</li>
<li>$D_{KL}(Q||P)$ 衡量”用 $P$ 编码 $Q$ 的样本”的额外信息</li>
<li>这两者通常不相等</li>
</ul>
<hr>
<h3 id="问题-2：什么时候使用前向-KL，什么时候使用反向-KL？"><a href="#问题-2：什么时候使用前向-KL，什么时候使用反向-KL？" class="headerlink" title="问题 2：什么时候使用前向 KL，什么时候使用反向 KL？"></a>问题 2：什么时候使用前向 KL，什么时候使用反向 KL？</h3><p>**前向 KL $D_{KL}(P||Q)$**：</p>
<ul>
<li>当你希望 $Q$ 覆盖 $P$ 的所有模式时</li>
<li>最大似然估计</li>
<li>监督学习<br>**反向 KL $D_{KL}(Q||P)$**：</li>
<li>当你希望 $Q$ 集中在 $P$ 的高概率区域时</li>
<li>变分推断</li>
<li>VAE、变分贝叶斯</li>
</ul>
<hr>
<h3 id="问题-3：KL-散度可以为负吗？"><a href="#问题-3：KL-散度可以为负吗？" class="headerlink" title="问题 3：KL 散度可以为负吗？"></a>问题 3：KL 散度可以为负吗？</h3><p><strong>不可以</strong>。根据 Gibbs 不等式，KL 散度始终非负：</p>
<p>$$D_{KL}(P||Q) \geq 0$$<br>当且仅当 $P &#x3D; Q$ 时，$D_{KL}(P||Q) &#x3D; 0$。</p>
<hr>
<h3 id="问题-4：如何处理-Q-x-x3D-0-的情况？"><a href="#问题-4：如何处理-Q-x-x3D-0-的情况？" class="headerlink" title="问题 4：如何处理 $Q(x) &#x3D; 0$ 的情况？"></a>问题 4：如何处理 $Q(x) &#x3D; 0$ 的情况？</h3><p>当 $P(x) &gt; 0$ 但 $Q(x) &#x3D; 0$ 时，$\log\frac{P(x)}{Q(x)} &#x3D; \infty$，导致 KL 散度为无穷大。</p>
<p><strong>解决方法</strong>：</p>
<ol>
<li><strong>拉普拉斯平滑</strong>：给 $Q(x)$ 加一个小的常数 $\epsilon$</li>
<li><strong>确保支撑集匹配</strong>：保证 $Q$ 的支撑集包含 $P$ 的支撑集</li>
<li><strong>使用其他散度</strong>：如 Wasserstein 距离，对不重叠分布更鲁棒</li>
</ol>
<hr>
<h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="1-数值稳定性"><a href="#1-数值稳定性" class="headerlink" title="1. 数值稳定性"></a>1. 数值稳定性</h3><h2 id="在实现-KL-散度时，避免直接计算-log-frac-P-x-Q-x-，而是使用：-2-处理零概率-3-使用库函数大多数深度学习框架提供了优化的-KL-散度实现："><a href="#在实现-KL-散度时，避免直接计算-log-frac-P-x-Q-x-，而是使用：-2-处理零概率-3-使用库函数大多数深度学习框架提供了优化的-KL-散度实现：" class="headerlink" title="在实现 KL 散度时，避免直接计算 $\log\frac{P(x)}{Q(x)}$，而是使用：### 2. 处理零概率### 3. 使用库函数大多数深度学习框架提供了优化的 KL 散度实现："></a>在实现 KL 散度时，避免直接计算 $\log\frac{P(x)}{Q(x)}$，而是使用：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不稳定的实现</span></span><br><span class="line">kl = P * np.log(P / Q)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 稳定的实现</span></span><br><span class="line">kl = P * (np.log(P) - np.log(Q))</span><br></pre></td></tr></table></figure><br>### 2. 处理零概率<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加小的 epsilon 避免 log(0)</span></span><br><span class="line">epsilon = <span class="number">1e-10</span></span><br><span class="line">kl = P * (np.log(P + epsilon) - np.log(Q + epsilon))</span><br></pre></td></tr></table></figure><br>### 3. 使用库函数<br>大多数深度学习框架提供了优化的 KL 散度实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PyTorch</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">kl_loss = F.kl_div(Q.log(), P, reduction=<span class="string">&#x27;batchmean&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TensorFlow</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">kl_loss = tf.keras.losses.KLDivergence()(P, Q)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SciPy</span></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> entropy</span><br><span class="line">kl_div = entropy(P, Q)</span><br></pre></td></tr></table></figure></h2><h2 id="参考资源"><a href="#参考资源" class="headerlink" title="参考资源"></a>参考资源</h2><ul>
<li><a target="_blank" rel="noopener" href="http://www.inference.org.uk/mackay/itila/">Information Theory, Inference, and Learning Algorithms - David MacKay</a></li>
<li><a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning/">Pattern Recognition and Machine Learning - Christopher Bishop</a></li>
<li><a target="_blank" rel="noopener" href="https://www.deeplearningbook.org/">Deep Learning Book - Ian Goodfellow et al.</a></li>
<li><a target="_blank" rel="noopener" href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained">Kullback-Leibler Divergence Explained</a></li>
</ul>
<hr>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2026/01/29/%5BOBS%5DAI-Claude%20Code-Claude%20Code%20Skills/"><img class="fill" src="/gallery/AI.png" alt="Claude Code Skills" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2026-01-29T00:00:00.000Z" title="1/29/2026, 8:00:00 AM">2026-01-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2026-02-14T13:40:28.047Z" title="2/14/2026, 9:40:28 PM">2026-02-14</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">13 minutes read (About 1978 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/01/29/%5BOBS%5DAI-Claude%20Code-Claude%20Code%20Skills/">Claude Code Skills</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><h1 id="Claude-Code-Skills-使用指南"><a href="#Claude-Code-Skills-使用指南" class="headerlink" title="Claude Code Skills 使用指南"></a>Claude Code Skills 使用指南</h1><p><a target="_blank" rel="noopener" href="https://code.claude.com/docs/en/skills.md">官方文档</a> | <a target="_blank" rel="noopener" href="https://agentskills.io/">Agent Skills 标准</a></p>
<hr>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><strong>Skills（技能）</strong> 是扩展 Claude Code 能力的自定义工作流。通过 Markdown 文件定义，可以用斜杠命令调用或自动加载。<br>Skills 遵循开放的 <a target="_blank" rel="noopener" href="https://agentskills.io/">Agent Skills</a> 标准，可跨多个 AI 工具使用。</p>
<hr>
<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="Skills-的作用"><a href="#Skills-的作用" class="headerlink" title="Skills 的作用"></a>Skills 的作用</h3><ul>
<li><strong>自定义斜杠命令</strong>：直接调用专门的工作流（如 <code>/commit</code>、<code>/review</code>）</li>
<li><strong>领域知识注入</strong>：为 Claude 提供特定领域的上下文</li>
<li><strong>任务指令</strong>：定义复杂操作的步骤流程</li>
<li><strong>工具集成</strong>：连接外部工具和脚本</li>
</ul>
<h3 id="文件结构"><a href="#文件结构" class="headerlink" title="文件结构"></a>文件结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">skill-name/</span><br><span class="line">├── SKILL.md          # 必需：主要技能定义</span><br><span class="line">├── reference.md      # 可选：详细文档</span><br><span class="line">├── examples.md       # 可选：使用示例</span><br><span class="line">└── scripts/          # 可选：辅助脚本</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="Skill-位置与作用域"><a href="#Skill-位置与作用域" class="headerlink" title="Skill 位置与作用域"></a>Skill 位置与作用域</h2><table>
<thead>
<tr>
<th>位置</th>
<th>路径</th>
<th>作用域</th>
</tr>
</thead>
<tbody><tr>
<td><strong>个人级</strong></td>
<td><code>~/.claude/skills/&lt;skill-name&gt;/SKILL.md</code></td>
<td>用户所有项目</td>
</tr>
<tr>
<td><strong>项目级</strong></td>
<td><code>.claude/skills/&lt;skill-name&gt;/SKILL.md</code></td>
<td>仅当前项目</td>
</tr>
<tr>
<td><strong>企业级</strong></td>
<td>通过设置管理</td>
<td>组织范围</td>
</tr>
</tbody></table>
<p><strong>优先级</strong>：项目级 &gt; 个人级 &gt; 企业级</p>
<hr>
<h2 id="创建-Skill"><a href="#创建-Skill" class="headerlink" title="创建 Skill"></a>创建 Skill</h2><h3 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h3><p>最简单的 skill 只需一个带 YAML 头的 <code>SKILL.md</code> 文件：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">explain-code</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">用图表和类比解释代码。当用户询问&quot;这段代码如何工作&quot;时使用</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="string">解释代码时，始终包含：</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span><span class="string">.</span> <span class="string">**类比**：用日常生活中的事物比喻代码</span></span><br><span class="line"><span class="number">2</span><span class="string">.</span> <span class="string">**图表**：用</span> <span class="string">ASCII</span> <span class="string">艺术展示流程或结构</span></span><br><span class="line"><span class="number">3</span><span class="string">.</span> <span class="string">**逐步讲解**：���释每一步发生了什么</span></span><br><span class="line"><span class="number">4</span><span class="string">.</span> <span class="string">**常见误区**：指出容易混淆的点</span></span><br></pre></td></tr></table></figure>

<h3 id="配置选项-Frontmatter"><a href="#配置选项-Frontmatter" class="headerlink" title="配置选项 (Frontmatter)"></a>配置选项 (Frontmatter)</h3><table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>name</code></td>
<td>string</td>
<td>显示名称（成为 <code>/斜杠命令</code>）</td>
</tr>
<tr>
<td><code>description</code></td>
<td>string</td>
<td>功能描述 - 用于自动调用判断</td>
</tr>
<tr>
<td><code>disable-model-invocation</code></td>
<td>boolean</td>
<td>为 <code>true</code> 时仅用户可调用（禁止自动加载）</td>
</tr>
<tr>
<td><code>user-invocable</code></td>
<td>boolean</td>
<td>为 <code>false</code> 时仅 Claude 可调用（菜单中隐藏）</td>
</tr>
<tr>
<td><code>allowed-tools</code></td>
<td>array</td>
<td>Claude 可使用的工具列表（无需权限提示）</td>
</tr>
<tr>
<td><code>context</code></td>
<td>string</td>
<td>设为 <code>fork</code> 在隔离的子代理中运行</td>
</tr>
<tr>
<td><code>agent</code></td>
<td>string</td>
<td>指定代理类型（如 <code>Explore</code>、<code>Plan</code>）</td>
</tr>
<tr>
<td><code>argument-hint</code></td>
<td>string</td>
<td>自动补全提示（如 <code>[issue-number]</code>）</td>
</tr>
</tbody></table>
<hr>
<h2 id="调用方式"><a href="#调用方式" class="headerlink" title="调用方式"></a>调用方式</h2><h3 id="1-直接调用"><a href="#1-直接调用" class="headerlink" title="1. 直接调用"></a>1. 直接调用</h3><p>用户显式使用斜杠命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/skill-name</span><br><span class="line">/fix-issue 123</span><br><span class="line">/explain-code src/auth/login.ts</span><br></pre></td></tr></table></figure>

<h3 id="2-自动调用"><a href="#2-自动调用" class="headerlink" title="2. 自动调用"></a>2. 自动调用</h3><p>当用户请求匹配 skill 的 <code>description</code> 时，Claude 自动加载：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">用户：&quot;这个认证流程是如何工作的？&quot;</span><br><span class="line">→ Claude 自动加载 /explain-code skill</span><br></pre></td></tr></table></figure>

<p><strong>控制自动调用：</strong></p>
<ul>
<li>设置 <code>disable-model-invocation: true</code> 禁止自动加载</li>
<li>让 description 更具体以避免误触发</li>
</ul>
<hr>
<h2 id="传递参数"><a href="#传递参数" class="headerlink" title="传递参数"></a>传递参数</h2><h3 id="使用-ARGUMENTS"><a href="#使用-ARGUMENTS" class="headerlink" title="使用 $ARGUMENTS"></a>使用 $ARGUMENTS</h3><p><code>$ARGUMENTS</code> 占位符捕获所有参数为单个字符串：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">fix-issue</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">修复</span> <span class="string">GitHub</span> <span class="string">issue</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="string">修复</span> <span class="string">GitHub</span> <span class="string">issue</span> <span class="string">$ARGUMENTS，遵循我们的编码标准。</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span><span class="string">.</span> <span class="string">从</span> <span class="string">GitHub</span> <span class="string">读取</span> <span class="string">issue</span> <span class="string">描述</span></span><br><span class="line"><span class="number">2</span><span class="string">.</span> <span class="string">理解需求</span></span><br><span class="line"><span class="number">3</span><span class="string">.</span> <span class="string">实现修复</span></span><br><span class="line"><span class="number">4</span><span class="string">.</span> <span class="string">编写测试</span></span><br><span class="line"><span class="number">5</span><span class="string">.</span> <span class="string">创建提交</span></span><br></pre></td></tr></table></figure>

<p><strong>用法</strong>：<code>/fix-issue 123</code> → “修复 GitHub issue 123…”</p>
<h3 id="使用位置参数"><a href="#使用位置参数" class="headerlink" title="使用位置参数"></a>使用位置参数</h3><p>用 <code>$0</code>、<code>$1</code>、<code>$2</code> 等访问单个参数：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">migrate-component</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">在框架间迁移组件</span></span><br><span class="line"><span class="attr">argument-hint:</span> [<span class="string">组件名</span>] [<span class="string">源框架</span>] [<span class="string">目标框架</span>]</span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="string">将</span> <span class="string">$0</span> <span class="string">组件从</span> <span class="string">$1</span> <span class="string">迁移到</span> <span class="string">$2。</span></span><br><span class="line"></span><br><span class="line"><span class="string">要求：</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">保留所有现有行为</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">维持测试覆盖率</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">更新文档</span></span><br></pre></td></tr></table></figure>

<p><strong>用法</strong>：<code>/migrate-component SearchBar React Vue</code></p>
<ul>
<li><code>$0</code> &#x3D; SearchBar</li>
<li><code>$1</code> &#x3D; React</li>
<li><code>$2</code> &#x3D; Vue</li>
</ul>
<hr>
<h2 id="高级模式"><a href="#高级模式" class="headerlink" title="高级模式"></a>高级模式</h2><h3 id="动态上下文注入"><a href="#动态上下文注入" class="headerlink" title="动态上下文注入"></a>动态上下文注入</h3><p>使用反引号`和 <code>!</code> 在 skill 运行前执行 shell 命令：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">pr-summary</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">总结</span> <span class="string">Pull</span> <span class="string">Request</span> <span class="string">的变更</span></span><br><span class="line"><span class="attr">context:</span> <span class="string">fork</span></span><br><span class="line"><span class="attr">agent:</span> <span class="string">Explore</span></span><br><span class="line"><span class="attr">allowed-tools:</span> <span class="string">Bash(gh</span> <span class="string">*)</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="comment">## Pull Request 上下文</span></span><br><span class="line"></span><br><span class="line"><span class="string">**差异：**</span></span><br><span class="line"><span class="string">!`gh</span> <span class="string">pr</span> <span class="string">diff`</span></span><br><span class="line"></span><br><span class="line"><span class="string">**评论：**</span></span><br><span class="line"><span class="string">!`gh</span> <span class="string">pr</span> <span class="string">view</span> <span class="string">--comments`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 任务</span></span><br><span class="line"></span><br><span class="line"><span class="string">总结这个</span> <span class="string">PR，重点关注：</span></span><br><span class="line"><span class="number">1</span><span class="string">.</span> <span class="string">主要变更及其目的</span></span><br><span class="line"><span class="number">2</span><span class="string">.</span> <span class="string">审查者的潜在关注点</span></span><br><span class="line"><span class="number">3</span><span class="string">.</span> <span class="string">测试覆盖情况</span></span><br></pre></td></tr></table></figure>

<h3 id="隔离子代理执行"><a href="#隔离子代理执行" class="headerlink" title="隔离子代理执行"></a>隔离子代理执行</h3><p>在隔离上下文中运行 skill，避免污染主对话：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">deep-research</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">深入研究某个主题而不影响主上下文</span></span><br><span class="line"><span class="attr">context:</span> <span class="string">fork</span></span><br><span class="line"><span class="attr">agent:</span> <span class="string">Explore</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="string">深入研究</span> <span class="string">$ARGUMENTS：</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span><span class="string">.</span> <span class="string">使用</span> <span class="string">Glob</span> <span class="string">和</span> <span class="string">Grep</span> <span class="string">查找相关文件</span></span><br><span class="line"><span class="number">2</span><span class="string">.</span> <span class="string">阅读并分析代码</span></span><br><span class="line"><span class="number">3</span><span class="string">.</span> <span class="string">识别模式和关系</span></span><br><span class="line"><span class="number">4</span><span class="string">.</span> <span class="string">用具体的文件引用（file:line</span> <span class="string">格式）总结发现</span></span><br></pre></td></tr></table></figure>

<h3 id="工具限制"><a href="#工具限制" class="headerlink" title="工具限制"></a>工具限制</h3><p>限制 Claude 在 skill 中可使用的工具：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">read-only-analysis</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">分析代码但不做修改</span></span><br><span class="line"><span class="attr">allowed-tools:</span> <span class="string">Read,</span> <span class="string">Grep,</span> <span class="string">Glob,</span> <span class="string">Bash(git</span> <span class="string">*)</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="string">分析代码库中的</span> <span class="string">$ARGUMENTS。</span></span><br><span class="line"></span><br><span class="line"><span class="string">你只能读取文件和运行</span> <span class="string">git</span> <span class="string">命令。</span></span><br><span class="line"><span class="string">不要修改任何文件。</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="Skill-设计原则"><a href="#Skill-设计原则" class="headerlink" title="Skill 设计原则"></a>Skill 设计原则</h3><ol>
<li><strong>单一职责</strong>：每个 skill 应有一个明确目的</li>
<li><strong>清晰描述</strong>：description 应匹配用户的自然语言</li>
<li><strong>明确指令</strong>：为复杂工作流提供分步指导</li>
<li><strong>错误处理</strong>：包含常见失败场景的处理说明</li>
</ol>
<h3 id="命名规范"><a href="#命名规范" class="headerlink" title="命名规范"></a>命名规范</h3><ul>
<li>使用小写加连字符：<code>fix-issue</code>、<code>explain-code</code></li>
<li>保持简短易记</li>
<li>使用动词导向的名称</li>
</ul>
<hr>
<h2 id="示例-Skills"><a href="#示例-Skills" class="headerlink" title="示例 Skills"></a>示例 Skills</h2><h3 id="代码审查"><a href="#代码审查" class="headerlink" title="代码审查"></a>代码审查</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">review</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">对变更进行全面的代码审查</span></span><br><span class="line"><span class="attr">disable-model-invocation:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">allowed-tools:</span> <span class="string">Read,</span> <span class="string">Grep,</span> <span class="string">Bash(git</span> <span class="string">*)</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="string">执行全面的代码审查：</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 审查清单</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span><span class="string">.</span> <span class="string">**正确性**：代码是否实现了预期功能？</span></span><br><span class="line"><span class="number">2</span><span class="string">.</span> <span class="string">**安全性**：是否存在安全漏洞？</span></span><br><span class="line"><span class="number">3</span><span class="string">.</span> <span class="string">**性能**：是否有明显的性能问题？</span></span><br><span class="line"><span class="number">4</span><span class="string">.</span> <span class="string">**可维护性**：代码是否可读且结构良好？</span></span><br><span class="line"><span class="number">5</span><span class="string">.</span> <span class="string">**测试**：测试覆盖是否充分？</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 流程</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span><span class="string">.</span> <span class="string">运行</span> <span class="string">`git</span> <span class="string">diff`</span> <span class="string">查看所有变更</span></span><br><span class="line"><span class="number">2</span><span class="string">.</span> <span class="string">完整阅读修改的文件</span></span><br><span class="line"><span class="number">3</span><span class="string">.</span> <span class="string">检查常见问题：SQL</span> <span class="string">注入、XSS、命令注入、竞态条件、内存泄漏、硬编码凭证</span></span><br><span class="line"><span class="number">4</span><span class="string">.</span> <span class="string">提供具体反馈，使用</span> <span class="string">file:line</span> <span class="string">引用</span></span><br></pre></td></tr></table></figure>

<h3 id="文档生成"><a href="#文档生成" class="headerlink" title="文档生成"></a>文档生成</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">document</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">为代码生成文档</span></span><br><span class="line"><span class="attr">argument-hint:</span> [<span class="string">文件路径</span>]</span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="string">为</span> <span class="string">$ARGUMENTS</span> <span class="string">生成全面的文档：</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span><span class="string">.</span> <span class="string">阅读文件并理解其目的</span></span><br><span class="line"><span class="number">2</span><span class="string">.</span> <span class="string">记录：</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">文件概述和用途</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">公共</span> <span class="string">API（函数、类、接口）</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">使用示例</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">依赖和要求</span></span><br><span class="line"><span class="number">3</span><span class="string">.</span> <span class="string">格式化为</span> <span class="string">markdown</span></span><br><span class="line"><span class="number">4</span><span class="string">.</span> <span class="string">在有帮助的地方包含代码示例</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="Skill-未自动触发"><a href="#Skill-未自动触发" class="headerlink" title="Skill 未自动触发"></a>Skill 未自动触发</h3><p><strong>问题</strong>：Claude 没有在预期时加载你的 skill。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>让 <code>description</code> 更具体，包含用户会自然说出的关键词</li>
<li>检查 <code>/context</code> 确保 skill 描述未超出字符预算</li>
<li>验证 skill 文件在正确位置</li>
</ul>
<h3 id="Skill-触发过于频繁"><a href="#Skill-触发过于频繁" class="headerlink" title="Skill 触发过于频繁"></a>Skill 触发过于频繁</h3><p><strong>问题</strong>：Skill 在不需要时加载。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>让 description 更具体</li>
<li>添加 <code>disable-model-invocation: true</code> 要求显式调用</li>
<li>在 description 中使用更独特的关键词</li>
</ul>
<h3 id="参数不工作"><a href="#参数不工作" class="headerlink" title="参数不工作"></a>参数不工作</h3><p><strong>问题</strong>：<code>$ARGUMENTS</code> 或 <code>$0</code>、<code>$1</code> 未被替换。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>确保传递了参数：<code>/skill-name arg1 arg2</code></li>
<li>检查占位符在 skill 正文中，而非仅在 frontmatter 中</li>
<li>验证占位符语法无拼写错误</li>
</ul>
<hr>
<h2 id="工作流集成示例"><a href="#工作流集成示例" class="headerlink" title="工作流集成示例"></a>工作流集成示例</h2><h3 id="Git-工作流"><a href="#Git-工作流" class="headerlink" title="Git 工作流"></a>Git 工作流</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">feature</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">创建新的功能分支并进行适当设置</span></span><br><span class="line"><span class="attr">argument-hint:</span> [<span class="string">功能名称</span>]</span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="string">为</span> <span class="string">$ARGUMENTS</span> <span class="string">创建新的功能分支：</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span><span class="string">.</span> <span class="string">确保工作目录干净</span></span><br><span class="line"><span class="number">2</span><span class="string">.</span> <span class="string">从</span> <span class="string">main</span> <span class="string">拉取最新变更</span></span><br><span class="line"><span class="number">3</span><span class="string">.</span> <span class="string">创建分支：`feature/$ARGUMENTS`</span></span><br><span class="line"><span class="number">4</span><span class="string">.</span> <span class="string">设置分支跟踪</span></span><br><span class="line"><span class="number">5</span><span class="string">.</span> <span class="string">创建初始提交</span></span><br></pre></td></tr></table></figure>

<h3 id="测试工作流"><a href="#测试工作流" class="headerlink" title="测试工作流"></a>测试工作流</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">test-fix</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">修复失败的测试</span></span><br><span class="line"><span class="attr">context:</span> <span class="string">fork</span></span><br><span class="line"><span class="attr">allowed-tools:</span> <span class="string">Bash,</span> <span class="string">Read,</span> <span class="string">Edit</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="string">修复失败的测试：</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span><span class="string">.</span> <span class="string">运行测试套件识别失败</span></span><br><span class="line"><span class="number">2</span><span class="string">.</span> <span class="string">对每个失败：</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">阅读测试文件</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">理解测试内容</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">阅读实现代码</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">识别问题</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">修复代码或更新测试</span></span><br><span class="line"><span class="number">3</span><span class="string">.</span> <span class="string">重新运行测试验证</span></span><br><span class="line"><span class="number">4</span><span class="string">.</span> <span class="string">创建修复提交</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="参考资源"><a href="#参考资源" class="headerlink" title="参考资源"></a>参考资源</h2><ul>
<li><a target="_blank" rel="noopener" href="https://code.claude.com/docs/en/skills.md">官方 Skills 文档</a></li>
<li><a target="_blank" rel="noopener" href="https://agentskills.io/">Agent Skills 标准</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/anthropics/claude-code">Claude Code GitHub</a></li>
</ul>
<hr>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul>
<li>Skills 评估顺序：项目级 → 个人级 → 企业级</li>
<li><code>/</code> 命令显示所有可用 skills 并支持自动补全</li>
<li>Skills 可以在指令中调用其他 skills</li>
<li>对于耗时操作使用 <code>context: fork</code> 保持主上下文清洁</li>
<li>Skills 支持 markdown 格式，包括表格、代码块和列表</li>
</ul>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2026-01-26T17:21:19.000Z" title="1/27/2026, 1:21:19 AM">2026-01-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2026-02-14T13:40:28.092Z" title="2/14/2026, 9:40:28 PM">2026-02-14</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 11 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/01/27/%5BOBS%5D%E6%94%80%E7%88%AC%E6%9C%BA%E5%99%A8%E4%BA%BA-%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%A7%86%E8%A7%89ROS%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1/">机器人视觉ROS接口设计</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><h2 id="ROS2通讯总览-视觉Scope"><a href="#ROS2通讯总览-视觉Scope" class="headerlink" title="ROS2通讯总览 (视觉Scope)"></a>ROS2通讯总览 (视觉Scope)</h2><div class="post-content"><a href="/2026/01/27/[OBS]攀爬机器人-机器人视觉ROS接口设计/Pasted_image_20260126173912.png" title="" title=" class="gallery-item"><img src="/2026/01/27/[OBS]攀爬机器人-机器人视觉ROS接口设计/Pasted_image_20260126173912.png" alt="" title=""></a></div>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2026-01-14T12:08:08.000Z" title="1/14/2026, 8:08:08 PM">2026-01-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2026-02-14T13:40:28.098Z" title="2/14/2026, 9:40:28 PM">2026-02-14</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">15 minutes read (About 2277 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/01/14/%5BOBS%5D%E6%94%80%E7%88%AC%E6%9C%BA%E5%99%A8%E4%BA%BA-ROS%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1/">ROS接口设计</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><h2 id="ROS2通讯总览"><a href="#ROS2通讯总览" class="headerlink" title="ROS2通讯总览"></a>ROS2通讯总览</h2><div class="post-content"><a href="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260122165026.png" title="" title=" class="gallery-item"><img src="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260122165026.png" alt="" title=""></a></div>

<h2 id="机器人运行流程"><a href="#机器人运行流程" class="headerlink" title="机器人运行流程"></a>机器人运行流程</h2><h3 id="初始化流程"><a href="#初始化流程" class="headerlink" title="初始化流程"></a>初始化流程</h3><div class="post-content"><a href="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260123135245.png" title="" title=" class="gallery-item"><img src="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260123135245.png" alt="" title=""></a></div> 


<h3 id="上塔流程"><a href="#上塔流程" class="headerlink" title="上塔流程"></a>上塔流程</h3><div class="post-content"><a href="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260127100812.png" title="" title=" class="gallery-item"><img src="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260127100812.png" alt="" title=""></a></div>

<h3 id="攀爬流程"><a href="#攀爬流程" class="headerlink" title="攀爬流程"></a>攀爬流程</h3><div class="post-content"><a href="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260123135228.png" title="" title=" class="gallery-item"><img src="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260123135228.png" alt="" title=""></a></div>

<h3 id="下塔流程"><a href="#下塔流程" class="headerlink" title="下塔流程"></a>下塔流程</h3><p>待定，与上塔类似</p>
<h2 id="Node解释"><a href="#Node解释" class="headerlink" title="Node解释"></a>Node解释</h2><h3 id="相机采集Node-RoboCamNode"><a href="#相机采集Node-RoboCamNode" class="headerlink" title="相机采集Node(RoboCamNode)"></a>相机采集Node(RoboCamNode)</h3><p>获取3个相机的视频流<br>作为RobotCamStream 的publisher，发布相 机RGB-D信息（根据订阅的ExecutorStatus中的freeClaw数据来切换相机源）</p>
<h3 id="关节控制Node-RoboJointNode"><a href="#关节控制Node-RoboJointNode" class="headerlink" title="关节控制Node(RoboJointNode)"></a>关节控制Node(RoboJointNode)</h3><p>通过CAN通讯控制机械臂关节<br>作为JointControl的Action server，响应其他Node的控制指令，响应其他Node的关节状态数据请求</p>
<h3 id="电爪控制Node-RoboClawNode"><a href="#电爪控制Node-RoboClawNode" class="headerlink" title="电爪控制Node(RoboClawNode)"></a>电爪控制Node(RoboClawNode)</h3><p>通过485通讯控制机器人电爪<br>作为ClawControl的Action server，响应主程序Node的控制指令，响应其他Node的电爪状态数据请求</p>
<h3 id="主程序Node-XclimbotNode"><a href="#主程序Node-XclimbotNode" class="headerlink" title="主程序Node(XclimbotNode)"></a>主程序Node(XclimbotNode)</h3><p>负责机器人的主要运行流程</p>
<h3 id="用户端通讯Node-UINetworkNode"><a href="#用户端通讯Node-UINetworkNode" class="headerlink" title="用户端通讯Node(UINetworkNode)"></a>用户端通讯Node(UINetworkNode)</h3><p>负责与用户端控制程序进行网络通讯<br>从主程序Node获取机器人信息，包括机器人运行状态(RobotStatus)和机器人执行器位置(RobotPosition)<br>获取相机的视频流信息</p>
<h2 id="ROS-Topic"><a href="#ROS-Topic" class="headerlink" title="ROS Topic"></a>ROS Topic</h2><div class="post-content"><a href="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260115153231.png" title="" title=" class="gallery-item"><img src="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260115153231.png" alt="" title=""></a></div>




<h3 id="RobotCamStream-msg"><a href="#RobotCamStream-msg" class="headerlink" title="RobotCamStream.msg"></a>RobotCamStream.msg</h3><p>持续publish视频流信息</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">int8 maincam            # <span class="number">1</span> <span class="keyword">for</span> camera_1, <span class="number">2</span> <span class="keyword">for</span> camera_2</span><br><span class="line">uint16 rows             <span class="meta"># height = 720</span></span><br><span class="line">uint16 cols             <span class="meta"># width = 1280</span></span><br><span class="line">uint16[] depth_data</span><br><span class="line">uint8 dimension        <span class="meta"># colorspace = 3</span></span><br><span class="line">uint16[] color_data</span><br></pre></td></tr></table></figure>

<h3 id="ExecutorStatus-msg"><a href="#ExecutorStatus-msg" class="headerlink" title="ExecutorStatus.msg"></a>ExecutorStatus.msg</h3><p>返回当前机器人的执行器状态：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int8[<span class="number">2</span>] claw_status = <span class="number">0</span>~<span class="number">4</span> <span class="comment">// 0 for 电爪运动中，1 for 已抓紧，2 for 已释放， 3 for 电爪掉落，4 for 错误,总共两个电爪的数据</span></span><br><span class="line">int8 fasten_status = <span class="number">0</span>~<span class="number">4</span> <span class="comment">// 0 for 紧固中，1 for 已紧固，2 for 已释放套筒，3 for已插入套筒，4 for 错误</span></span><br><span class="line">int8 freeClaw = <span class="number">1</span> | <span class="number">2</span> <span class="comment">// 1 for claw_1, 2 for claw_2</span></span><br><span class="line">int8[<span class="number">6</span>] joint_status, <span class="comment">//each element ∈ &#123;1,0&#125; 1 for 运行，0 for运行结束,总共6个关节的数据</span></span><br><span class="line">int64[<span class="number">6</span>] joint_angle <span class="comment">//each element ∈ [-3600000, 3600000],总共6个关节的数据</span></span><br></pre></td></tr></table></figure>

<h3 id="RunnningStatus-msg"><a href="#RunnningStatus-msg" class="headerlink" title="RunnningStatus.msg"></a>RunnningStatus.msg</h3><p>返回当前机器人的状态</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int16 status = <span class="number">-1</span>~<span class="number">10</span> <span class="comment">// -1代表调试功能，开放所有直接控制功能。其余状态见机器人运行流程的图例</span></span><br></pre></td></tr></table></figure>

<h2 id="ROS-Action"><a href="#ROS-Action" class="headerlink" title="ROS Action"></a>ROS Action</h2><div class="post-content"><a href="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260115145239.png" title="" title=" class="gallery-item"><img src="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260115145239.png" alt="" title=""></a></div>
### JointControl.action
Request 请求关节执行一次关节空间运动。
**Note:需要多个关节同步执行指令，同时做动。**
包含六个关节的目标角度:
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int64[<span class="number">6</span>] goal_angle <span class="comment">// each element ∈ [-3600000, 3600000]</span></span><br><span class="line">int8[<span class="number">6</span>] vel_limit = <span class="number">0</span>~<span class="number">30</span> <span class="comment">// unit: RPM，待定</span></span><br></pre></td></tr></table></figure>

<p>Feedback 为以5Hz频率返回当前关节角度和关节运动状态,表示正在正常执行。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int64[<span class="number">6</span>] current_angle <span class="comment">//each element ∈ [-3600000, 3600000]</span></span><br><span class="line">int8[<span class="number">6</span>] current_running <span class="comment">//each element ∈ &#123;1,0&#125; //1 for 运行，0 for运行结束</span></span><br></pre></td></tr></table></figure>

<p>Result 用于描述关节运动任务的最终执行结果，仅在任务结束后可获取。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">bool</span> success = <span class="literal">true</span> | <span class="literal">false</span></span><br><span class="line"><span class="built_in">string</span> message <span class="comment">// 如果存在错误，报错原因</span></span><br></pre></td></tr></table></figure>

<h3 id="ClawControl-action"><a href="#ClawControl-action" class="headerlink" title="ClawControl.action"></a>ClawControl.action</h3><p>用于控制机器人电爪运动。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// request</span></span><br><span class="line">int8 index = <span class="number">1</span> | <span class="number">2</span> <span class="comment">// 1 for claw_1, 2 for claw_2</span></span><br><span class="line">int8 grab = <span class="number">0</span> | <span class="number">1</span> <span class="comment">// 0 for grab, 1 for release</span></span><br><span class="line">int32 force = <span class="number">700</span> <span class="comment">// unit: N</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//feedback 5Hz</span></span><br><span class="line">int8 index = <span class="number">1</span> | <span class="number">2</span> <span class="comment">// 1 for claw_1, 2 for claw_2</span></span><br><span class="line">int8 running_status = <span class="number">0</span> | <span class="number">1</span> <span class="comment">// 0 for grabbing, 1 for releasing</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//response</span></span><br><span class="line">int8 index = <span class="number">1</span> | <span class="number">2</span> <span class="comment">// 1 for claw_1, 2 for claw_2</span></span><br><span class="line"><span class="type">bool</span> success = <span class="literal">true</span> | <span class="literal">false</span></span><br><span class="line"><span class="built_in">string</span> message <span class="comment">// 如果存在错误，报错原因</span></span><br></pre></td></tr></table></figure>

<h3 id="PrepareClimb-action"><a href="#PrepareClimb-action" class="headerlink" title="PrepareClimb.action"></a>PrepareClimb.action</h3><p>机器人在攀爬结束后两足均抓取于角钢上，此时需要用户发出继续攀爬指令，机器人抬起自由足会运动到拍摄深度图像的位置。</p>
<blockquote>
<p>仅当机器人处于status 2(即“等待用户攀爬指令”)时可以发出指令</p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// request</span></span><br><span class="line"><span class="type">bool</span> prepare = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//feedback 5Hz</span></span><br><span class="line">int64[<span class="number">6</span>] current_angle <span class="comment">//each element ∈ [-3600000, 3600000]，电爪当前角度</span></span><br><span class="line">int8[<span class="number">6</span>] current_running <span class="comment">//each element ∈ &#123;1,0&#125; //1 for 运行，0 for运行结束</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//respond</span></span><br><span class="line"><span class="type">bool</span> success = <span class="literal">true</span> | <span class="literal">false</span></span><br><span class="line"><span class="built_in">string</span> message <span class="comment">// 如果存在错误，报错原因</span></span><br></pre></td></tr></table></figure>

<h3 id="VisionSelect-action"><a href="#VisionSelect-action" class="headerlink" title="VisionSelect.action"></a>VisionSelect.action</h3><p>用户在用户端点选角钢的坐标数据通过网络发送到用户端通讯Node之后，该Node将坐标信息作为指令目标传给主程序Node，由主程序Node进行图像分析得到抓取点，将mask和抓取点反馈给通讯端Node用于显示。<br>在用户端程序的视频图像上覆盖显示（半透明）对应的Mask,以及预计抓取点的位置。</p>
<blockquote>
<p>这个视觉选择的请求只有当机器人处于status 6 (即“等待用户选取的坐标”)时才有效</p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//request </span></span><br><span class="line">int16 point_x = <span class="number">0</span><span class="number">-1280</span></span><br><span class="line">int16 point_y = <span class="number">0</span><span class="number">-720</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">//feedback anything</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//respond</span></span><br><span class="line"><span class="type">bool</span> success = <span class="literal">true</span> | <span class="literal">false</span></span><br><span class="line"><span class="type">bool</span>[<span class="number">720</span>][<span class="number">1280</span>] mask <span class="comment">// if success</span></span><br><span class="line">int16 result_x = <span class="number">0</span><span class="number">-1280</span> <span class="comment">// if success</span></span><br><span class="line">int16 result_y = <span class="number">0</span><span class="number">-720</span> <span class="comment">// if success</span></span><br><span class="line"><span class="built_in">string</span> message <span class="comment">// if go wrong</span></span><br></pre></td></tr></table></figure>

<h3 id="DirectJoint-action"><a href="#DirectJoint-action" class="headerlink" title="DirectJoint.action"></a>DirectJoint.action</h3><blockquote>
<p>直接控制应该为用户端的一个独立窗口（通过菜单栏选项调出）</p>
</blockquote>
<p>用户端通讯Node发给主程序Node的指令，可让用户端直接控制关节的运动。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//request</span></span><br><span class="line">int64[<span class="number">6</span>] goal_angle <span class="comment">// each element ∈ [-3600000, 3600000]</span></span><br><span class="line">int8 vel_limit = <span class="number">0</span>~<span class="number">30</span> <span class="comment">// unit: RPM</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//feedback 5Hz</span></span><br><span class="line">int64[<span class="number">6</span>] current_angle <span class="comment">//each element ∈ [-3600000, 3600000]</span></span><br><span class="line">int8[<span class="number">6</span>] current_running <span class="comment">//each element ∈ &#123;1,0&#125; //1 for 运行，0 for运行结束</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//result</span></span><br><span class="line"><span class="type">bool</span> success = <span class="literal">true</span> | <span class="literal">false</span></span><br><span class="line"><span class="built_in">string</span> message <span class="comment">// 如果存在错误，报错原因</span></span><br></pre></td></tr></table></figure>


<h3 id="DirectClaw-action"><a href="#DirectClaw-action" class="headerlink" title="DirectClaw.action"></a>DirectClaw.action</h3><blockquote>
<p>直接控制应该为用户端的一个独立窗口（通过菜单栏选项调出）</p>
</blockquote>
<p>用户端通讯Node发给主程序Node的指令，可让用户端直接控制电爪的运动。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// request</span></span><br><span class="line">int8 index = <span class="literal">false</span> | <span class="literal">true</span> <span class="comment">// false for claw_0, true for claw_1</span></span><br><span class="line">int8 task = <span class="number">0</span> | <span class="number">1</span> <span class="comment">// 0 for grab, 1 for release</span></span><br><span class="line">int32 force = <span class="number">700</span> <span class="comment">// unit: N</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//feedback 5Hz</span></span><br><span class="line">int8 index = <span class="literal">false</span> | <span class="literal">true</span> <span class="comment">// false for claw_0, true for claw_1</span></span><br><span class="line">int8 task = <span class="number">0</span> | <span class="number">1</span> <span class="comment">// 0 for grab, 1 for release</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//response</span></span><br><span class="line">int8 index = <span class="number">1</span> | <span class="number">2</span> <span class="comment">// 1 for claw_1, 2 for claw_2</span></span><br><span class="line"><span class="type">bool</span> success = <span class="literal">true</span> | <span class="literal">false</span></span><br><span class="line"><span class="built_in">string</span> message <span class="comment">// 如果存在错误，报错原因(例如其他几种情况)</span></span><br></pre></td></tr></table></figure>


<h2 id="ROS-Service"><a href="#ROS-Service" class="headerlink" title="ROS Service"></a>ROS Service</h2><div class="post-content"><a href="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260115153307.png" title="" title=" class="gallery-item"><img src="/2026/01/14/[OBS]攀爬机器人-ROS接口设计/Pasted_image_20260115153307.png" alt="" title=""></a></div>
### EmergencyStop.srv
用户在用户端点击急停按钮通过网络发送到用户端通讯Node之后，用户端通讯Node将确认信息通过service告知主程序Node
> 急停的具体行为为：cancel joint action, 让固定足保持夹持状态，自由足保持张开

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//request </span></span><br><span class="line"><span class="type">bool</span> stop = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//respond</span></span><br><span class="line"><span class="type">bool</span> success = <span class="literal">true</span> | <span class="literal">false</span></span><br><span class="line"><span class="built_in">string</span> message <span class="comment">// if go wrong</span></span><br></pre></td></tr></table></figure>

<h3 id="VisionConfirm-srv"><a href="#VisionConfirm-srv" class="headerlink" title="VisionConfirm.srv"></a>VisionConfirm.srv</h3><p>用户端确认抓取点和mask有效与否，将确认信息发回给机器人的用户端通讯Node，用户端通讯Node将确认信息通过service告知主程序Node</p>
<blockquote>
<p>这个确认的请求只有当机器人处于status 8 (即“确认抓取结果”)时才有效</p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//request </span></span><br><span class="line"><span class="type">bool</span> confirm = <span class="literal">true</span> | <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//respond</span></span><br><span class="line"><span class="type">bool</span> received = <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h3 id="SwitchClaw-srv"><a href="#SwitchClaw-srv" class="headerlink" title="SwitchClaw.srv"></a>SwitchClaw.srv</h3><p>用户端点击切换电爪的按钮后，将切换指令发给机器人的用户通讯端Node，用户端通讯Node将确认信息通过service告知主程序Node</p>
<blockquote>
<p>仅当机器人处于status 2时可以切换。</p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//request</span></span><br><span class="line"><span class="type">bool</span> <span class="keyword">switch</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//respond</span></span><br><span class="line"><span class="type">bool</span> success = <span class="literal">true</span> | <span class="literal">false</span></span><br><span class="line"><span class="built_in">string</span> message <span class="comment">// if go wrong (例如此时机器人没有双足抓取角钢，而切换只有在双足抓取角钢时实现)</span></span><br></pre></td></tr></table></figure>



<h2 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h2><h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><p>使用一个package <code>robot_interfaces</code> 用于存放所有的接口定义</p>
<ul>
<li>只放接口定义</li>
<li>不含任何 node</li>
<li>被 server &#x2F; client &#x2F; pub &#x2F; sub 共同依赖</li>
</ul>
<p>例如:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">my_robot_interfaces/</span><br><span class="line"> ├── msg/</span><br><span class="line"> │   └── RobotCamStream.msg</span><br><span class="line"> ├── srv/</span><br><span class="line"> │   └── RunningStatus.srv</span><br><span class="line"> │   └── ExecutorStatus.srv</span><br><span class="line"> │   └── ...</span><br><span class="line"> └── action/</span><br><span class="line">     └── ClawControl.action</span><br><span class="line">     └── JointControl.action</span><br><span class="line">     └── ...</span><br></pre></td></tr></table></figure>

<h3 id="2"><a href="#2" class="headerlink" title="2"></a>2</h3><p>主程序的核心功能由毕老师实验室团队负责实现。杨总团队需基于主程序框架，在主程序中自行完成本文档所定义的各类 ROS 接口（包括 Action、Service、Topic）的 Server 端实现。<br>同时，杨总团队需提供与上述接口一一对应的功能测试代码或示例调用代码，以便直接集成或粘贴至主程序中，用于接口联调与功能验证，确保接口定义与实际行为的一致性和可测试性。<br>典型的主程序python示例为(并非具体实现)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> rclpy</span><br><span class="line"><span class="keyword">from</span> rclpy.node <span class="keyword">import</span> Node</span><br><span class="line"><span class="keyword">from</span> rclpy.action <span class="keyword">import</span> ActionServer, GoalResponse, CancelResponse</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> my_robot_interfaces.action <span class="keyword">import</span> JointControl</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">XclimbotMainNode</span>(<span class="title class_ inherited__">Node</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(<span class="string">&#x27;xclimbot_main_node&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 模拟关节状态（真实项目中来自底层驱动 / CAN）</span></span><br><span class="line">        <span class="variable language_">self</span>.current_joint_angle = [<span class="number">0</span>] * <span class="number">6</span></span><br><span class="line">        <span class="variable language_">self</span>.current_joint_running = [<span class="number">0</span>] * <span class="number">6</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Action Server</span></span><br><span class="line">        <span class="variable language_">self</span>._action_server = ActionServer(</span><br><span class="line">            <span class="variable language_">self</span>,</span><br><span class="line">            JointControl,</span><br><span class="line">            <span class="string">&#x27;joint_control&#x27;</span>,</span><br><span class="line">            execute_callback=<span class="variable language_">self</span>.execute_callback,</span><br><span class="line">            goal_callback=<span class="variable language_">self</span>.goal_callback,</span><br><span class="line">            cancel_callback=<span class="variable language_">self</span>.cancel_callback</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.get_logger().info(<span class="string">&#x27;JointControl Action Server started&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ---------- Goal 校验 ----------</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">goal_callback</span>(<span class="params">self, goal_request</span>):</span><br><span class="line">        <span class="variable language_">self</span>.get_logger().info(</span><br><span class="line">            <span class="string">f&#x27;Received goal: <span class="subst">&#123;<span class="built_in">list</span>(goal_request.goal_angle)&#125;</span>, &#x27;</span></span><br><span class="line">            <span class="string">f&#x27;vel_limit=<span class="subst">&#123;goal_request.vel_limit&#125;</span>&#x27;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 示例：简单校验</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(goal_request.goal_angle) != <span class="number">6</span>:</span><br><span class="line">            <span class="variable language_">self</span>.get_logger().warn(<span class="string">&#x27;Invalid goal angle length&#x27;</span>)</span><br><span class="line">            <span class="keyword">return</span> GoalResponse.REJECT</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> GoalResponse.ACCEPT</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ---------- Cancel ----------</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cancel_callback</span>(<span class="params">self, goal_handle</span>):</span><br><span class="line">        <span class="variable language_">self</span>.get_logger().warn(<span class="string">&#x27;Received cancel request&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> CancelResponse.ACCEPT</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ---------- 执行主逻辑 ----------</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">execute_callback</span>(<span class="params">self, goal_handle</span>):</span><br><span class="line">        <span class="variable language_">self</span>.get_logger().info(<span class="string">&#x27;Executing JointControl goal&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        feedback = JointControl.Feedback()</span><br><span class="line">        result = JointControl.Result()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 标记关节开始运行</span></span><br><span class="line">        <span class="variable language_">self</span>.current_joint_running = [<span class="number">1</span>] * <span class="number">6</span></span><br><span class="line"></span><br><span class="line">        rate = <span class="variable language_">self</span>.create_rate(<span class="number">5</span>)  <span class="comment"># 5 Hz feedback</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):  <span class="comment"># 模拟 4 秒执行过程</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># ---- cancel 检查 ----</span></span><br><span class="line">            <span class="keyword">if</span> goal_handle.is_cancel_requested:</span><br><span class="line">                <span class="variable language_">self</span>.get_logger().warn(<span class="string">&#x27;Goal canceled during execution&#x27;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="variable language_">self</span>.current_joint_running = [<span class="number">0</span>] * <span class="number">6</span></span><br><span class="line">                result.success = <span class="literal">False</span></span><br><span class="line">                result.message = <span class="string">&#x27;Goal canceled by client&#x27;</span></span><br><span class="line">                goal_handle.canceled()</span><br><span class="line">                <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">            <span class="comment"># ---- 模拟关节运动 ----</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">                <span class="variable language_">self</span>.current_joint_angle[i] += <span class="number">1000</span>  <span class="comment"># 模拟变化</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># ---- 填充并发送 feedback ----</span></span><br><span class="line">            feedback.current_angle = <span class="variable language_">self</span>.current_joint_angle</span><br><span class="line">            feedback.current_running = <span class="variable language_">self</span>.current_joint_running</span><br><span class="line">            goal_handle.publish_feedback(feedback)</span><br><span class="line"></span><br><span class="line">            <span class="variable language_">self</span>.get_logger().debug(</span><br><span class="line">                <span class="string">f&#x27;Feedback sent: <span class="subst">&#123;feedback.current_angle&#125;</span>&#x27;</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            rate.sleep()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 执行完成</span></span><br><span class="line">        <span class="variable language_">self</span>.current_joint_running = [<span class="number">0</span>] * <span class="number">6</span></span><br><span class="line">        result.success = <span class="literal">True</span></span><br><span class="line">        result.message = <span class="string">&#x27;Joint motion finished successfully&#x27;</span></span><br><span class="line"></span><br><span class="line">        goal_handle.succeed()</span><br><span class="line">        <span class="variable language_">self</span>.get_logger().info(<span class="string">&#x27;JointControl goal succeeded&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args=<span class="literal">None</span></span>):</span><br><span class="line">    rclpy.init(args=args)</span><br><span class="line"></span><br><span class="line">    node = XclimbotMainNode()</span><br><span class="line">    rclpy.spin(node)</span><br><span class="line"></span><br><span class="line">    node.destroy_node()</span><br><span class="line">    rclpy.shutdown()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>测试仅针对接口本身，不涉及对于具体机器人运行逻辑的测试。</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2026-01-13T14:03:36.000Z" title="1/13/2026, 10:03:36 PM">2026-01-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2026-02-14T13:40:28.019Z" title="2/14/2026, 9:40:28 PM">2026-02-14</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 101 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2026/01/13/%5BOBS%5DLBY%E7%BB%93%E8%BE%A9%E8%AE%B0%E5%BD%95/">LBY结辩记录</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><ul>
<li>scalable的理解<ul>
<li>要能够在 low cost 的情况下复制方法用于新的场景（主要是指数据获取）建议改为More accessible, affordable</li>
</ul>
</li>
<li>Infared的用处<ul>
<li>指尖的抓取行程测距(存在一定noise，几毫米，量程合适)</li>
</ul>
</li>
<li>不能只说RL的坏处</li>
<li>机器人遥控和人工的Incompatible</li>
<li>视角Invarient可不可以用scale up的方式解决</li>
</ul>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/">Previous</a></div><div class="pagination-next"><a href="/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link is-current" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/32/">32</a></li></ul></nav></div><style>.column.column-left,.column.column-right{display:none}</style><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Chen Yulin"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Chen Yulin</p><p class="is-size-6 is-block">SJTU student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Manchester by the Sea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">312</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">10</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">235</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Chen-Yulin" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2026/02/"><span class="level-start"><span class="level-item">February 2026</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2026/01/"><span class="level-start"><span class="level-item">January 2026</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/12/"><span class="level-start"><span class="level-item">December 2025</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/11/"><span class="level-start"><span class="level-item">November 2025</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/10/"><span class="level-start"><span class="level-item">October 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/09/"><span class="level-start"><span class="level-item">September 2025</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/08/"><span class="level-start"><span class="level-item">August 2025</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/07/"><span class="level-start"><span class="level-item">July 2025</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/06/"><span class="level-start"><span class="level-item">June 2025</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/05/"><span class="level-start"><span class="level-item">May 2025</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/04/"><span class="level-start"><span class="level-item">April 2025</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">March 2025</span></span><span class="level-end"><span class="level-item tag">45</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">February 2025</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item">January 2025</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">December 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/11/"><span class="level-start"><span class="level-item">November 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/07/"><span class="level-start"><span class="level-item">July 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">June 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/05/"><span class="level-start"><span class="level-item">May 2024</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/04/"><span class="level-start"><span class="level-item">April 2024</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">46</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/2026/02/14/%5BOBS%5Dexist_label/"><img src="/thumb/Research-paper.png" alt="exist_label"></a></figure><div class="media-content"><p class="date"><time dateTime="2026-02-14T12:01:54.000Z">2026-02-14</time></p><p class="title"><a href="/2026/02/14/%5BOBS%5Dexist_label/">exist_label</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2026/02/06/%5BOBS%5DDeep%20Learning-BAGEL-Unified-Multimodal-Pretraining/"><img src="/thumb/Research-paper.png" alt="BAGEL-Unified-Multimodal-Pretraining"></a></figure><div class="media-content"><p class="date"><time dateTime="2026-02-05T21:30:00.000Z">2026-02-06</time></p><p class="title"><a href="/2026/02/06/%5BOBS%5DDeep%20Learning-BAGEL-Unified-Multimodal-Pretraining/">BAGEL-Unified-Multimodal-Pretraining</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2026/02/05/%5BOBS%5DDeep%20Learning-LingBot-VLA/"><img src="/thumb/Research-paper.png" alt="LingBot-VLA"></a></figure><div class="media-content"><p class="date"><time dateTime="2026-02-05T15:30:00.000Z">2026-02-05</time></p><p class="title"><a href="/2026/02/05/%5BOBS%5DDeep%20Learning-LingBot-VLA/">LingBot-VLA</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2026/02/05/%5BOBS%5DDeep%20Learning-Transformer-Mixture-of-Experts-Survey/"><img src="/thumb/LLM.png" alt="Mixture-of-Experts-Survey"></a></figure><div class="media-content"><p class="date"><time dateTime="2026-02-05T15:30:00.000Z">2026-02-05</time></p><p class="title"><a href="/2026/02/05/%5BOBS%5DDeep%20Learning-Transformer-Mixture-of-Experts-Survey/">Mixture-of-Experts-Survey</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2026-02-05T00:00:00.000Z">2026-02-05</time></p><p class="title"><a href="/2026/02/05/%5BOBS%5DRobotics-Humanoid-Robot-Control-Methods/">人形机器人控制方法综述</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/3D-Scene/"><span class="tag">3D-Scene</span><span class="tag">17</span></a></div><div class="control"><a class="tags has-addons" href="/tags/6-D/"><span class="tag">6-D</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">16</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AIGC/"><span class="tag">AIGC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/API/"><span class="tag">API</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AR/"><span class="tag">AR</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Academic/"><span class="tag">Academic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Aliyun/"><span class="tag">Aliyun</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/App/"><span class="tag">App</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BS4/"><span class="tag">BS4</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bayesian-Inference/"><span class="tag">Bayesian-Inference</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Beautify/"><span class="tag">Beautify</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Behaviorism/"><span class="tag">Behaviorism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Business/"><span class="tag">Business</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CADC/"><span class="tag">CADC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CD/"><span class="tag">CD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLI/"><span class="tag">CLI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLIP/"><span class="tag">CLIP</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CV/"><span class="tag">CV</span><span class="tag">68</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Camera/"><span class="tag">Camera</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Capstone/"><span class="tag">Capstone</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Chemistry/"><span class="tag">Chemistry</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Claude/"><span class="tag">Claude</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Communication/"><span class="tag">Communication</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Contrastive-Learning/"><span class="tag">Contrastive-Learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Control/"><span class="tag">Control</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Csharp/"><span class="tag">Csharp</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Css/"><span class="tag">Css</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cuda/"><span class="tag">Cuda</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DD/"><span class="tag">DD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DINO/"><span class="tag">DINO</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DT/"><span class="tag">DT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dataframe/"><span class="tag">Dataframe</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debate/"><span class="tag">Debate</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debugger/"><span class="tag">Debugger</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Development-Tools/"><span class="tag">Development-Tools</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Diffusion/"><span class="tag">Diffusion</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Diffusion-Policy/"><span class="tag">Diffusion-Policy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DiffusionModel/"><span class="tag">DiffusionModel</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Discrete-Mathematics/"><span class="tag">Discrete-Mathematics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Disney/"><span class="tag">Disney</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docs/"><span class="tag">Docs</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dynamic-programming/"><span class="tag">Dynamic-programming</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ESP32/"><span class="tag">ESP32</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Education/"><span class="tag">Education</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embeded-System/"><span class="tag">Embeded-System</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embodied-AI/"><span class="tag">Embodied-AI</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emoation/"><span class="tag">Emoation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emotion/"><span class="tag">Emotion</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ethic/"><span class="tag">Ethic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Experiment/"><span class="tag">Experiment</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FL/"><span class="tag">FL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FPN/"><span class="tag">FPN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Family/"><span class="tag">Family</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Federated-Learning/"><span class="tag">Federated-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Foundation/"><span class="tag">Foundation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FoundationModel/"><span class="tag">FoundationModel</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Functional-programming/"><span class="tag">Functional programming</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Game/"><span class="tag">Game</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gated-NN/"><span class="tag">Gated-NN</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Github/"><span class="tag">Github</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Godot/"><span class="tag">Godot</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Graph/"><span class="tag">Graph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HPC/"><span class="tag">HPC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HRI/"><span class="tag">HRI</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Haskell/"><span class="tag">Haskell</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Health/"><span class="tag">Health</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hierarchical/"><span class="tag">Hierarchical</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Html/"><span class="tag">Html</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Humanism/"><span class="tag">Humanism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Humanoid/"><span class="tag">Humanoid</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HumanoidRobot/"><span class="tag">HumanoidRobot</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hybrid-Control/"><span class="tag">Hybrid-Control</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hyprland/"><span class="tag">Hyprland</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IK/"><span class="tag">IK</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Grounding/"><span class="tag">Image-Grounding</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Text/"><span class="tag">Image-Text</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-generation/"><span class="tag">Image-generation</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image2Text/"><span class="tag">Image2Text</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ImgGen/"><span class="tag">ImgGen</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ImitationLearning/"><span class="tag">ImitationLearning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Information-Theory/"><span class="tag">Information-Theory</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Jolt/"><span class="tag">Jolt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Json/"><span class="tag">Json</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">17</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LSP/"><span class="tag">LSP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LatentAction/"><span class="tag">LatentAction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latex/"><span class="tag">Latex</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lego/"><span class="tag">Lego</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life/"><span class="tag">Life</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinearAlgebra/"><span class="tag">LinearAlgebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Live2d/"><span class="tag">Live2d</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Love/"><span class="tag">Love</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lua/"><span class="tag">Lua</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MBTI/"><span class="tag">MBTI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MPC/"><span class="tag">MPC</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MR-AR/"><span class="tag">MR/AR</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine-Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mason/"><span class="tag">Mason</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Math/"><span class="tag">Math</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Meme/"><span class="tag">Meme</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Message-Passing/"><span class="tag">Message-Passing</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MindPlus/"><span class="tag">MindPlus</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MoE/"><span class="tag">MoE</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mod/"><span class="tag">Mod</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model-Predictive-Control/"><span class="tag">Model-Predictive-Control</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Motivation/"><span class="tag">Motivation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Moveit/"><span class="tag">Moveit</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Movie/"><span class="tag">Movie</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-Agent/"><span class="tag">Multi-Agent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-modal/"><span class="tag">Multi-modal</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-view/"><span class="tag">Multi-view</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MultiModal/"><span class="tag">MultiModal</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Music/"><span class="tag">Music</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NN/"><span class="tag">NN</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Network/"><span class="tag">Network</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nodejs/"><span class="tag">Nodejs</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Numpy/"><span class="tag">Numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nvim/"><span class="tag">Nvim</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Object-Detection/"><span class="tag">Object-Detection</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Open-Vocabulary/"><span class="tag">Open-Vocabulary</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenCV/"><span class="tag">OpenCV</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Oral/"><span class="tag">Oral</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PHD/"><span class="tag">PHD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PSY/"><span class="tag">PSY</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pandas/"><span class="tag">Pandas</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Panoptic/"><span class="tag">Panoptic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Path/"><span class="tag">Path</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Philosophy/"><span class="tag">Philosophy</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PhysX/"><span class="tag">PhysX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Physical-Scene/"><span class="tag">Physical-Scene</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Physics-engine/"><span class="tag">Physics-engine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pio/"><span class="tag">Pio</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Planning/"><span class="tag">Planning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Plugin/"><span class="tag">Plugin</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PoseEstimation/"><span class="tag">PoseEstimation</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Postgraduate/"><span class="tag">Postgraduate</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Prefab/"><span class="tag">Prefab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Probability/"><span class="tag">Probability</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">30</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/QML/"><span class="tag">QML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Quantum/"><span class="tag">Quantum</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RAG/"><span class="tag">RAG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RL/"><span class="tag">RL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROS/"><span class="tag">ROS</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reading/"><span class="tag">Reading</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Real2Sim/"><span class="tag">Real2Sim</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reconstruct/"><span class="tag">Reconstruct</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regex/"><span class="tag">Regex</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reinforcement-Learning/"><span class="tag">Reinforcement-Learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reinforcement-learning/"><span class="tag">Reinforcement-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Repository/"><span class="tag">Repository</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation-Learning/"><span class="tag">Representation-Learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Research-paper/"><span class="tag">Research-paper</span><span class="tag">97</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robot/"><span class="tag">Robot</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RobotLearning/"><span class="tag">RobotLearning</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robotics/"><span class="tag">Robotics</span><span class="tag">38</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SJTU-Lecture/"><span class="tag">SJTU-Lecture</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SSH/"><span class="tag">SSH</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scalability/"><span class="tag">Scalability</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scene-graph/"><span class="tag">Scene-graph</span><span class="tag">34</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scene-synthesis/"><span class="tag">Scene-synthesis</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Science-fiction/"><span class="tag">Science-fiction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scrap/"><span class="tag">Scrap</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Script/"><span class="tag">Script</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Segmentation/"><span class="tag">Segmentation</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Semantic/"><span class="tag">Semantic</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shader/"><span class="tag">Shader</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shell/"><span class="tag">Shell</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Signals-and-Systems/"><span class="tag">Signals and Systems</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sim2Real/"><span class="tag">Sim2Real</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sklearn/"><span class="tag">Sklearn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Snippets/"><span class="tag">Snippets</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Society/"><span class="tag">Society</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Star-rail/"><span class="tag">Star-rail</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Statistics/"><span class="tag">Statistics</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Subgraph/"><span class="tag">Subgraph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Submodule/"><span class="tag">Submodule</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Supervised-learning/"><span class="tag">Supervised-learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Survey/"><span class="tag">Survey</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TC/"><span class="tag">TC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TOEFL/"><span class="tag">TOEFL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Task-Planning/"><span class="tag">Task-Planning</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tasks/"><span class="tag">Tasks</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tech-Communication/"><span class="tag">Tech Communication</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Torch/"><span class="tag">Torch</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Translation-Embedding/"><span class="tag">Translation-Embedding</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Travel/"><span class="tag">Travel</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/UI/"><span class="tag">UI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unified-Multimodal/"><span class="tag">Unified-Multimodal</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unity/"><span class="tag">Unity</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unsupervised-learning/"><span class="tag">Unsupervised-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VAE/"><span class="tag">VAE</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLA/"><span class="tag">VLA</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLM/"><span class="tag">VLM</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLP/"><span class="tag">VLP</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VQ-VAE/"><span class="tag">VQ-VAE</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Variational-Inference/"><span class="tag">Variational-Inference</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Version-management/"><span class="tag">Version-management</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ViT/"><span class="tag">ViT</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VideoEditing/"><span class="tag">VideoEditing</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vim/"><span class="tag">Vim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Visual-Relation/"><span class="tag">Visual-Relation</span><span class="tag">23</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WSL/"><span class="tag">WSL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Waybar/"><span class="tag">Waybar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wayland/"><span class="tag">Wayland</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Web/"><span class="tag">Web</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Website/"><span class="tag">Website</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Well-being/"><span class="tag">Well-being</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Window-manager/"><span class="tag">Window-manager</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WorldModel/"><span class="tag">WorldModel</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/YKLL/"><span class="tag">YKLL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Zen/"><span class="tag">Zen</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E2%99%A5%EF%B8%8F/"><span class="tag">♥️</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%9E%E4%B9%A0/"><span class="tag">实习</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%F0%9F%8D%A2/"><span class="tag">🍢</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%F0%9F%8D%B0/"><span class="tag">🍰</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%F0%9F%90%B1/"><span class="tag">🐱</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%F0%9F%A7%80/"><span class="tag">🧀</span><span class="tag">1</span></a></div></div></div></div></div></div><style>.column.column-left,.column.column-right{display:block}</style></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img class="logo-img" src="/img/cyllogo.png" alt="Chen Yulin&#039;s Blog" height="28"><img class="logo-img-dark" src="/img/cyllogonight.png" alt="Chen Yulin&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2026 Chen Yulin</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/imaegoo/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><div class="searchbox-pinyin"><label class="checkbox"><input id="search-by-pinyin" type="checkbox" checked="checked"><span> 拼音检索</span></label></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/imaegoo/pinyin.js" defer></script><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script type="text/javascript" src="/js/imaegoo/imaegoo.js"></script><script type="text/javascript" src="/js/imaegoo/universe.js"></script><script type="text/javascript" src="/js/imaegoo/falling-petals.js"></script><!-- hexo injector body_end start -->
<link rel="stylesheet" crossorigin href="https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.css" />
<script type="module" crossorigin src="https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.js"></script>
<script>
  window.CHATBOT_CONFIG = {
    endpoint: "https://webchat-bot-iqu-knzhgrvznd.cn-hangzhou.fcapp.run/chat", // 可以替换为 https://{your-fc-http-trigger-domain}/chat
    displayByDefault: false, // 默认不展示 AI 助手聊天框
    aiChatOptions: { // aiChatOptions 中 options 会传递 aiChat 组件，自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat
      conversationOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#conversation-options
        conversationStarters: [
          {prompt: '你是谁？'},
          {prompt: '博主又是谁？'},
          {prompt: '怎么使用这个网站？'},
          {prompt: '想要博主联系方式！'},
        ]
      },
      displayOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#display-options
        height: 600,
        width: 350,
      },
      personaOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#chat-personas
        assistant: {          name: '博主的AI助手，十四行诗参上！',
          // AI 助手的图标
          avatar: 'https://chen-yulin.github.io/thumb/14.png',
          tagline: '要不要试试问下面的问题呢？',
        }
      }
    }
  };
</script>
<style>
  :root {
    /* webchat 工具栏的颜色 */
    --webchat-toolbar-background-color: #1464E4;
    /* webchat 工具栏文字和按钮的颜色 */
    --webchat-toolbar-text-color: #FFF;
  }
  /* webchat 对话框如果被遮挡，可以尝试通过 z-index、bottom、left 等设置来调整位置 */
  .webchat-container {
    z-index: 100;
    bottom: 10px;
    right: 10px;
  }
  /* webchat 的唤起按钮如果被遮挡，可以尝试通过 z-index、bottom、left 等设置来调整位置 */
  .webchat-bubble-tip {
    z-index: 99;
    bottom: 60px;
    right: 20px;
  }
  .webchat-bubble-tip {
    overflow: visible !important;
  }
  @keyframes float {
    0% {
      transform: translateY(0px) translateX(-50%);
    }
    50% {
      transform: translateY(-10px) translateX(-50%);
    }
    100% {
      transform: translateY(0px) translateX(-50%);
    }
  }

  .webchat-bubble-tip::before {
    content: '';
    position: absolute;
    top: -25px;
    left: 70%;
    width: 40px;
    height: 40px;
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='white'%3E%3Cpath d='M20 2H4c-1.1 0-2 .9-2 2v18l4-4h14c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm0 14H6l-2 2V4h16v12z'/%3E%3C/svg%3E");
    background-repeat: no-repeat;
    background-position: center;
    background-size: contain;
    filter: drop-shadow(0 4px 6px rgba(0, 0, 0, 0.5));
    animation: float 3s ease-in-out infinite;
  }
</style><script data-pjax src="https://registry.npmmirror.com/oh-my-live2d/latest/files"></script><script>const oml2d = OML2D.loadOml2d({libraryUrls:{"complete":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/complete.js","cubism2":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism2.js","cubism5":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism5.js"},dockedPosition:"left",mobileDisplay:true,models:[{"path":"https://model.hacxy.cn/mai/model.json","mobilePosition":[25,0],"mobileScale":0.1,"mobileStageStyle":{"width":125,"height":175},"motionPreloadStrategy":"ALL","position":[50,0],"scale":0.2,"stageStyle":{"width":250,"height":350}}],parentElement:document.body,primaryColor:"var(--btn-bg)",sayHello:false,tips:{style: {"width":230,"height":120,"left":"calc(50% - 20px)","top":"-100px"},mobileStyle: {"width":180,"height":80,"left":"calc(50% - 30px)","top":"-100px"},idleTips:{interval:15000,message:function(){
  return axios.get('https://v1.hitokoto.cn?c=i')
    .then(function (response) {
      return response.data.hitokoto ;
    })
    .catch(function (error) {
      console.error(error);
    });
}
}}});</script><!-- hexo injector body_end end --></body></html>