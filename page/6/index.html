<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="theme-color" content="#123456"><title>Chen Yulin&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#6495ed"><meta name="application-name" content="Icarus - Hexo Theme"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="msapplication-TileColor" content="#6495ed"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Icarus - Hexo Theme"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Chen Yulin&#039;s Blog"><meta property="og:url" content="http://chen-yulin.github.io/"><meta property="og:site_name" content="Chen Yulin&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://chen-yulin.github.io/img/og_image.png"><meta property="article:author" content="Chen Yulin"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://chen-yulin.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://chen-yulin.github.io"},"headline":"Chen Yulin's Blog","image":["http://chen-yulin.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Chen Yulin"},"publisher":{"@type":"Organization","name":"Chen Yulin's Blog","logo":{"@type":"ImageObject","url":{"light":"/img/cyllogo.png","dark":"/img/cyllogonight.png"}}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><script type="text/javascript" src="/js/imaegoo/night.js"></script><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img class="logo-img" src="/img/cyllogo.png" alt="Chen Yulin&#039;s Blog" height="28"><img class="logo-img-dark" src="/img/cyllogonight.png" alt="Chen Yulin&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-11-20T14:19:13.000Z" title="11/20/2024, 10:19:13 PM">2024-11-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-03-11T15:49:22.163Z" title="3/11/2025, 11:49:22 PM">2025-03-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/11/20/%5BOBS%5DDeep%20Learning-CV-ACDC-%20Automated%20Creation%20of%20Digital%20Cousins%20for%20Robust%20Policy%20Learning/">ACDC- Automated Creation of Digital Cousins for Robust Policy Learning</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2024/11/17/%5BOBS%5DPoseEstimation-Cosypose%20(multi-view)%20Adaption/"><img class="fill" src="/gallery/Python.png" alt="Cosypose modification" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-11-16T16:35:56.000Z" title="11/17/2024, 12:35:56 AM">2024-11-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-03-11T15:49:21.787Z" title="3/11/2025, 11:49:21 PM">2025-03-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">18 minutes read (About 2722 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/11/17/%5BOBS%5DPoseEstimation-Cosypose%20(multi-view)%20Adaption/">Cosypose modification</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><h2 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h2><p>仓库: <a target="_blank" rel="noopener" href="https://github.com/Simple-Robotics/cosypose">https://github.com/Simple-Robotics/cosypose</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --recurse-submodules https://github.com/Simple-Robotics/cosypose.git</span><br><span class="line"><span class="built_in">cd</span> cosypose</span><br><span class="line">conda <span class="built_in">env</span> create -n cosypose --file environment.yaml</span><br></pre></td></tr></table></figure>

<p>注意执行这一步的时候pip 会提示setuptools 和matplotlib-inline不符合3.7.6的python，到环境中手动安装适配的版本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda activate cosypose</span><br><span class="line">pip install setuptools==63.4.1</span><br><span class="line">pip install matplotlib-inline==0.1.6</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git lfs pull</span><br><span class="line">python setup.py install</span><br><span class="line">python setup.py develop</span><br></pre></td></tr></table></figure>

<p>根据README下载数据<br>注意第一块指令无法下载成功，由 <a target="_blank" rel="noopener" href="https://bop.felk.cvut.cz/datasets/">https://bop.felk.cvut.cz/datasets/</a> 得知下载链接迁移到了huggingface, <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/bop-benchmark/datasets/tree/main/ycbv">https://huggingface.co/datasets/bop-benchmark/datasets/tree/main/ycbv</a> 可以从这里手动下载测试集并放置到<code>local_data/bop_datasets/ycbv/test</code></p>
<p>设置测试使用的models</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> ./local_data/bop_datasets/ycbv/model_bop_compat_eval ./local_data/bop_datasets/ycbv/models</span><br></pre></td></tr></table></figure>

<h2 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h2><h3 id="np-where-mask-0-item"><a href="#np-where-mask-0-item" class="headerlink" title="np.where(mask)[0].item()"></a><code>np.where(mask)[0].item()</code></h3><p>运行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> CUDA_VISIBLE_DEVICES=0 </span><br><span class="line">python -m cosypose.scripts.run_cosypose_eval --config ycbv</span><br></pre></td></tr></table></figure>
<p>时出现报错</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;/home/cyl/.conda/envs/cosypose/lib/python3.7/runpy.py&quot;</span>, line 193, <span class="keyword">in</span> _run_module_as_main</span><br><span class="line">    <span class="string">&quot;__main__&quot;</span>, mod_spec)</span><br><span class="line">  File <span class="string">&quot;/home/cyl/.conda/envs/cosypose/lib/python3.7/runpy.py&quot;</span>, line 85, <span class="keyword">in</span> _run_code</span><br><span class="line">    <span class="built_in">exec</span>(code, run_globals)</span><br><span class="line">  File <span class="string">&quot;/home/cyl/cosypose/cosypose/scripts/run_cosypose_eval.py&quot;</span>, line 491, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    main()</span><br><span class="line">  File <span class="string">&quot;/home/cyl/cosypose/cosypose/scripts/run_cosypose_eval.py&quot;</span>, line 332, <span class="keyword">in</span> main</span><br><span class="line">    scene_ds = make_scene_dataset(ds_name)</span><br><span class="line">  File <span class="string">&quot;/home/cyl/cosypose/cosypose/datasets/datasets_cfg.py&quot;</span>, line 68, <span class="keyword">in</span> make_scene_dataset</span><br><span class="line">    ids.append(np.where(mask)[0].item())</span><br><span class="line">ValueError: can only convert an array of size 1 to a Python scalar</span><br></pre></td></tr></table></figure>
<p>添加debug输出，得到</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Debug - scene_id: 48, view_id: 1</span><br><span class="line">Debug - mask matches: 1</span><br><span class="line">Debug - <span class="built_in">where</span> result shape: (1,), values: [225]</span><br><span class="line">Debug - scene_id: 48, view_id: 36</span><br><span class="line">Debug - mask matches: 1</span><br><span class="line">Debug - <span class="built_in">where</span> result shape: (1,), values: [226]</span><br><span class="line">Debug - scene_id: 48, view_id: 47</span><br><span class="line">Debug - mask matches: 1</span><br><span class="line">Debug - <span class="built_in">where</span> result shape: (1,), values: [227]</span><br><span class="line">Debug - scene_id: 48, view_id: 83</span><br><span class="line">Debug - mask matches: 1</span><br><span class="line">Debug - <span class="built_in">where</span> result shape: (1,), values: [228]</span><br><span class="line">Debug - scene_id: 48, view_id: 112</span><br><span class="line">Debug - mask matches: 1</span><br><span class="line">Debug - <span class="built_in">where</span> result shape: (1,), values: [229]</span><br><span class="line">Debug - scene_id: 48, view_id: 135</span><br><span class="line">Debug - mask matches: 0</span><br><span class="line">Debug - <span class="built_in">where</span> result shape: (0,), values: []</span><br><span class="line">0:00:00.912023 - Expected exactly one match, got 0 matches <span class="keyword">for</span> scene_id=48, view_id=135</span><br></pre></td></tr></table></figure>
<p>发现是下载的测试数据集并不包含数据集keyframe.txt中所有的帧，导致一些关键帧识别不到</p>
<h3 id="运行到一半被终止的情况"><a href="#运行到一半被终止的情况" class="headerlink" title="运行到一半被终止的情况"></a>运行到一半被终止的情况</h3><p>如果想重新开始新的训练： 清空<code>local_data/joblib_cache</code></p>
<h2 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h2><h3 id="Prediction-Script-cosypose-scripts-run-cosypose-eval"><a href="#Prediction-Script-cosypose-scripts-run-cosypose-eval" class="headerlink" title="Prediction Script cosypose.scripts.run_cosypose_eval"></a>Prediction Script <code>cosypose.scripts.run_cosypose_eval</code></h3><h4 id="AI-explanation"><a href="#AI-explanation" class="headerlink" title="AI explanation"></a>AI explanation</h4><p>The script predicts object poses based on multi-view input by following these steps:</p>
<ol>
<li><p><strong>Dataset Loading</strong>: It first loads the dataset using the <code>make_scene_dataset</code> function, which prepares the scene data for evaluation. The dataset is wrapped in a <code>MultiViewWrapper</code> to handle multiple views.</p>
</li>
<li><p><strong>Model Loading</strong>: The script loads pre-trained models for pose prediction using the <code>load_models</code> function. It loads both coarse and refiner models based on the configuration specified in the command-line arguments.</p>
</li>
<li><p><strong>Prediction Setup</strong>: The script sets up the prediction parameters, including the number of iterations for coarse and refiner models, and whether to skip multi-view processing based on the number of views specified.</p>
</li>
<li><p><strong>Multi-view Prediction</strong>: The <code>MultiviewScenePredictor</code> is initialized with the mesh database, which is used to predict poses across multiple views. The <code>MultiviewPredictionRunner</code> is then used to run predictions on the dataset, leveraging the multi-view setup to improve pose estimation accuracy.</p>
</li>
<li><p><strong>Pose Estimation</strong>: The script uses the loaded models to predict object poses. It processes detections from either <code>pix2pose</code> or <code>posecnn</code> depending on the dataset, and refines these predictions using the refiner model.</p>
</li>
<li><p><strong>Evaluation</strong>: After predictions, the script evaluates the predicted poses using the <code>PoseEvaluation</code> class. It calculates various metrics like ADD-S and AUC to assess the accuracy of the pose predictions.</p>
</li>
<li><p><strong>Results Logging</strong>: Finally, the script logs the results, including evaluation metrics, and saves them to a specified directory.</p>
</li>
</ol>
<p>The multi-view approach allows the script to leverage information from different viewpoints, which can help resolve ambiguities and improve the robustness of the pose estimation.</p>
<h3 id="Prediction-Script-run-custom-scenario"><a href="#Prediction-Script-run-custom-scenario" class="headerlink" title="Prediction Script run_custom_scenario"></a>Prediction Script <code>run_custom_scenario</code></h3><h3 id="Terms"><a href="#Terms" class="headerlink" title="Terms"></a>Terms</h3><h4 id="TCO"><a href="#TCO" class="headerlink" title="TCO"></a>TCO</h4><p><strong>Transformation from Camera to Object.</strong><br>It represents the transformation matrix or parameters that describe the pose of an object relative to the camera’s coordinate system</p>
<h4 id="TWO"><a href="#TWO" class="headerlink" title="TWO"></a>TWO</h4><p><strong>Transformation from World to Object.</strong><br>It represents the transformation matrix or parameters that describe the pose of an object relative to the world’s coordinate system</p>
<h3 id="Model-dataset"><a href="#Model-dataset" class="headerlink" title="Model dataset"></a>Model dataset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MeshDataBase</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, obj_list</span>):</span><br><span class="line">        <span class="variable language_">self</span>.infos = &#123;obj[<span class="string">&#x27;label&#x27;</span>]: obj <span class="keyword">for</span> obj <span class="keyword">in</span> obj_list&#125;</span><br><span class="line">        <span class="variable language_">self</span>.meshes = &#123;l: trimesh.load(obj[<span class="string">&#x27;mesh_path&#x27;</span>]) <span class="keyword">for</span> l, obj <span class="keyword">in</span> <span class="variable language_">self</span>.infos.items()&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_object_ds</span>(<span class="params">object_ds</span>):</span><br><span class="line">        obj_list = [object_ds[n] <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(object_ds))]</span><br><span class="line">        <span class="keyword">return</span> MeshDataBase(obj_list)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>一般使用的初始化方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">object_ds = BOPObjectDataset(scenario_dir / <span class="string">&#x27;models&#x27;</span>)</span><br><span class="line">mesh_db = MeshDataBase.from_object_ds(object_ds)</span><br></pre></td></tr></table></figure>
<p>也可以通过load models一起加载：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictor, mesh_db = load_models(coarse_run_id, refiner_run_id, n_workers=n_plotters, object_set=object_set)</span><br></pre></td></tr></table></figure>




<h3 id="Important-Classes"><a href="#Important-Classes" class="headerlink" title="Important Classes"></a>Important Classes</h3><h4 id="Multiview-wrapper"><a href="#Multiview-wrapper" class="headerlink" title="Multiview_wrapper"></a><code>Multiview_wrapper</code></h4><p>作用：<br>读取 scene_dataset 并且通过视角数量<code>n_views</code>来分割这些数据为不同场景，然后方便遍历其中的场景元素（这里都是ground truth）<br>遍历时返回的值为</p>
<ul>
<li><code>n_views</code>张不同视角下的RGB图像</li>
<li><code>n_views</code>张对应的mask</li>
<li><code>n_views</code>份对应的observation<ul>
<li>识别到的物体位姿和类型</li>
<li>相机位姿和内参</li>
<li>frame_info，没太多用<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scene_ds_pred = MultiViewWrapper(scene_ds, n_views=n_views)</span><br><span class="line">scene_ds_pred[<span class="number">0</span>][<span class="number">2</span>] <span class="comment"># scene48 multiview_group1 &#x27;s observations in five views</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line"> &#123;<span class="string">&#x27;objects&#x27;</span>: </span><br><span class="line">  [</span><br><span class="line">   &#123;<span class="string">&#x27;label&#x27;</span>: <span class="string">&#x27;obj_000001&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;obj_000001&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;TWO&#x27;</span>: array([[-<span class="number">0.02062261</span>, -<span class="number">0.99870347</span>, -<span class="number">0.04654345</span>, -<span class="number">0.05380909</span>],</span><br><span class="line">           [ <span class="number">0.99854439</span>, -<span class="number">0.022895</span>  ,  <span class="number">0.04883047</span>,  <span class="number">0.00189095</span>],</span><br><span class="line">           [-<span class="number">0.04983272</span>, -<span class="number">0.04546878</span>,  <span class="number">0.9977229</span> ,  <span class="number">0.07060698</span>],</span><br><span class="line">           [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ]]),</span><br><span class="line">    <span class="string">&#x27;T0O&#x27;</span>: array([[-<span class="number">0.02062261</span>, -<span class="number">0.99870347</span>, -<span class="number">0.04654345</span>, -<span class="number">0.05380909</span>],</span><br><span class="line">           [ <span class="number">0.99854439</span>, -<span class="number">0.022895</span>  ,  <span class="number">0.04883047</span>,  <span class="number">0.00189095</span>],</span><br><span class="line">           [-<span class="number">0.04983272</span>, -<span class="number">0.04546878</span>,  <span class="number">0.9977229</span> ,  <span class="number">0.07060698</span>],</span><br><span class="line">           [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ]]),</span><br><span class="line">    <span class="string">&#x27;visib_fract&#x27;</span>: <span class="number">0.7769277845777234</span>,</span><br><span class="line">    <span class="string">&#x27;id_in_segm&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&#x27;bbox&#x27;</span>: [<span class="number">347</span>, <span class="number">210</span>, <span class="number">467</span>, <span class="number">374</span>]&#125;,</span><br><span class="line">   &#123;<span class="string">&#x27;label&#x27;</span>: <span class="string">&#x27;obj_000006&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;obj_000006&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;TWO&#x27;</span>: array([[-<span class="number">0.40056693</span>,  <span class="number">0.91475543</span>, -<span class="number">0.05262471</span>,  <span class="number">0.03103553</span>],</span><br><span class="line">           [-<span class="number">0.91622629</span>, -<span class="number">0.39934108</span>,  <span class="number">0.03248866</span>, -<span class="number">0.02365388</span>],</span><br><span class="line">           [ <span class="number">0.00870386</span>,  <span class="number">0.06123014</span>,  <span class="number">0.9980863</span> ,  <span class="number">0.01391488</span>],</span><br><span class="line">           [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ]]),</span><br><span class="line">    <span class="string">&#x27;T0O&#x27;</span>: array([[-<span class="number">0.40056693</span>,  <span class="number">0.91475543</span>, -<span class="number">0.05262471</span>,  <span class="number">0.03103553</span>],</span><br><span class="line">           [-<span class="number">0.91622629</span>, -<span class="number">0.39934108</span>,  <span class="number">0.03248866</span>, -<span class="number">0.02365388</span>],</span><br><span class="line">           [ <span class="number">0.00870386</span>,  <span class="number">0.06123014</span>,  <span class="number">0.9980863</span> ,  <span class="number">0.01391488</span>],</span><br><span class="line">           [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ]]),</span><br><span class="line">    <span class="string">&#x27;visib_fract&#x27;</span>: <span class="number">0.9990349353406678</span>,</span><br><span class="line">    <span class="string">&#x27;id_in_segm&#x27;</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="string">&#x27;bbox&#x27;</span>: [<span class="number">328</span>, <span class="number">343</span>, <span class="number">422</span>, <span class="number">405</span>]&#125;,</span><br><span class="line">   &#123;<span class="string">&#x27;label&#x27;</span>: <span class="string">&#x27;obj_000014&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;obj_000014&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;TWO&#x27;</span>: array([[ <span class="number">0.24178672</span>, -<span class="number">0.96941339</span>, -<span class="number">0.04215706</span>, -<span class="number">0.05206396</span>],</span><br><span class="line">           [ <span class="number">0.96977496</span>,  <span class="number">0.2399519</span> ,  <span class="number">0.0442575</span> ,  <span class="number">0.0179453</span> ],</span><br><span class="line">           [-<span class="number">0.03278805</span>, -<span class="number">0.05158388</span>,  <span class="number">0.99813144</span>,  <span class="number">0.16636215</span>],</span><br><span class="line">           [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ]]),</span><br><span class="line">    <span class="string">&#x27;T0O&#x27;</span>: array([[ <span class="number">0.24178672</span>, -<span class="number">0.96941339</span>, -<span class="number">0.04215706</span>, -<span class="number">0.05206396</span>],</span><br><span class="line">           [ <span class="number">0.96977496</span>,  <span class="number">0.2399519</span> ,  <span class="number">0.0442575</span> ,  <span class="number">0.0179453</span> ],</span><br><span class="line">           [-<span class="number">0.03278805</span>, -<span class="number">0.05158388</span>,  <span class="number">0.99813144</span>,  <span class="number">0.16636215</span>],</span><br><span class="line">           [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ]]),</span><br><span class="line">    <span class="string">&#x27;visib_fract&#x27;</span>: <span class="number">0.9938250428816466</span>,</span><br><span class="line">    <span class="string">&#x27;id_in_segm&#x27;</span>: <span class="number">3</span>,</span><br><span class="line">    <span class="string">&#x27;bbox&#x27;</span>: [<span class="number">372</span>, <span class="number">143</span>, <span class="number">490</span>, <span class="number">241</span>]&#125;,</span><br><span class="line">   &#123;<span class="string">&#x27;label&#x27;</span>: <span class="string">&#x27;obj_000019&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;obj_000019&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;TWO&#x27;</span>: array([[-<span class="number">0.69888905</span>,  <span class="number">0.1926738</span> , -<span class="number">0.68878937</span>,  <span class="number">0.01412755</span>],</span><br><span class="line">           [ <span class="number">0.711967</span>  ,  <span class="number">0.27928957</span>, -<span class="number">0.64428215</span>,  <span class="number">0.05127768</span>],</span><br><span class="line">           [ <span class="number">0.06823575</span>, -<span class="number">0.94067797</span>, -<span class="number">0.33237011</span>,  <span class="number">0.06472594</span>],</span><br><span class="line">           [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ]]),</span><br><span class="line">    <span class="string">&#x27;T0O&#x27;</span>: array([[-<span class="number">0.69888905</span>,  <span class="number">0.1926738</span> , -<span class="number">0.68878937</span>,  <span class="number">0.01412755</span>],</span><br><span class="line">           [ <span class="number">0.711967</span>  ,  <span class="number">0.27928957</span>, -<span class="number">0.64428215</span>,  <span class="number">0.05127768</span>],</span><br><span class="line">           [ <span class="number">0.06823575</span>, -<span class="number">0.94067797</span>, -<span class="number">0.33237011</span>,  <span class="number">0.06472594</span>],</span><br><span class="line">           [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ]]),</span><br><span class="line">    <span class="string">&#x27;visib_fract&#x27;</span>: <span class="number">0.9890470974808324</span>,</span><br><span class="line">    <span class="string">&#x27;id_in_segm&#x27;</span>: <span class="number">4</span>,</span><br><span class="line">    <span class="string">&#x27;bbox&#x27;</span>: [<span class="number">419</span>, <span class="number">222</span>, <span class="number">527</span>, <span class="number">410</span>]&#125;,</span><br><span class="line">   &#123;<span class="string">&#x27;label&#x27;</span>: <span class="string">&#x27;obj_000020&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;obj_000020&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;TWO&#x27;</span>: array([[-<span class="number">0.74512542</span>, -<span class="number">0.66691536</span>,  <span class="number">0.00352083</span>,  <span class="number">0.07854437</span>],</span><br><span class="line">           [-<span class="number">0.6669148</span> ,  <span class="number">0.74507458</span>, -<span class="number">0.00940455</span>, -<span class="number">0.15283599</span>],</span><br><span class="line">           [ <span class="number">0.00364864</span>, -<span class="number">0.00935569</span>, -<span class="number">0.99995023</span>,  <span class="number">0.01854317</span>],</span><br><span class="line">           [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ]]),</span><br><span class="line">    <span class="string">&#x27;T0O&#x27;</span>: array([[-<span class="number">0.74512542</span>, -<span class="number">0.66691536</span>,  <span class="number">0.00352083</span>,  <span class="number">0.07854437</span>],</span><br><span class="line">           [-<span class="number">0.6669148</span> ,  <span class="number">0.74507458</span>, -<span class="number">0.00940455</span>, -<span class="number">0.15283599</span>],</span><br><span class="line">           [ <span class="number">0.00364864</span>, -<span class="number">0.00935569</span>, -<span class="number">0.99995023</span>,  <span class="number">0.01854317</span>],</span><br><span class="line">           [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ]]),</span><br><span class="line">    <span class="string">&#x27;visib_fract&#x27;</span>: <span class="number">0.9953060637992145</span>,</span><br><span class="line">    <span class="string">&#x27;id_in_segm&#x27;</span>: <span class="number">5</span>,</span><br><span class="line">    <span class="string">&#x27;bbox&#x27;</span>: [<span class="number">92</span>, <span class="number">328</span>, <span class="number">288</span>, <span class="number">442</span>]&#125;],</span><br><span class="line">  <span class="string">&#x27;camera&#x27;</span>: </span><br><span class="line">  &#123;<span class="string">&#x27;T0C&#x27;</span>: array([[-<span class="number">0.0792652</span> ,  <span class="number">0.241296</span>  , -<span class="number">0.967209</span>  ,  <span class="number">0.946419</span>  ],</span><br><span class="line">          [ <span class="number">0.996102</span>  ,  <span class="number">0.0568396</span> , -<span class="number">0.0674529</span> , -<span class="number">0.02116569</span>],</span><br><span class="line">          [ <span class="number">0.0386997</span> , -<span class="number">0.968786</span>  , -<span class="number">0.244861</span>  ,  <span class="number">0.36645836</span>],</span><br><span class="line">          [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ]]),</span><br><span class="line">   <span class="string">&#x27;K&#x27;</span>: array([[<span class="number">1.066778e+03</span>, <span class="number">0.000000e+00</span>, <span class="number">3.129869e+02</span>],</span><br><span class="line">          [<span class="number">0.000000e+00</span>, <span class="number">1.067487e+03</span>, <span class="number">2.413109e+02</span>],</span><br><span class="line">          [<span class="number">0.000000e+00</span>, <span class="number">0.000000e+00</span>, <span class="number">1.000000e+00</span>]]),</span><br><span class="line">   <span class="string">&#x27;TWC&#x27;</span>: array([[-<span class="number">0.0792652</span> ,  <span class="number">0.241296</span>  , -<span class="number">0.967209</span>  ,  <span class="number">0.946419</span>  ],</span><br><span class="line">          [ <span class="number">0.996102</span>  ,  <span class="number">0.0568396</span> , -<span class="number">0.0674529</span> , -<span class="number">0.02116569</span>],</span><br><span class="line">          [ <span class="number">0.0386997</span> , -<span class="number">0.968786</span>  , -<span class="number">0.244861</span>  ,  <span class="number">0.36645836</span>],</span><br><span class="line">          [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.</span>        ]]),</span><br><span class="line">   <span class="string">&#x27;resolution&#x27;</span>: torch.Size([<span class="number">480</span>, <span class="number">640</span>])&#125;,</span><br><span class="line">  <span class="string">&#x27;frame_info&#x27;</span>: </span><br><span class="line">  &#123;</span><br><span class="line">   <span class="string">&#x27;scene_id&#x27;</span>: <span class="number">48</span>,</span><br><span class="line">   <span class="string">&#x27;cam_id&#x27;</span>: <span class="string">&#x27;cam&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;view_id&#x27;</span>: <span class="number">1626</span>,</span><br><span class="line">   <span class="string">&#x27;cam_name&#x27;</span>: <span class="string">&#x27;cam&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;group_id&#x27;</span>: <span class="number">0</span></span><br><span class="line">   &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  ... <span class="comment"># other views</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>


<h4 id="MultiviewPredictorRunner"><a href="#MultiviewPredictorRunner" class="headerlink" title="MultiviewPredictorRunner"></a><code>MultiviewPredictorRunner</code></h4><p>作用：<br>接收<code>Multiview_wrapper</code>作为输入，并做出预测</p>
<p>首先是数据集接收：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dataloader = DataLoader(scene_ds, batch_size=batch_size,</span><br><span class="line">						num_workers=n_workers,</span><br><span class="line">						sampler=sampler,</span><br><span class="line">						collate_fn=<span class="variable language_">self</span>.collate_fn)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>use <code>collate_fn</code> to process the row data （最后的注释里面有真正用到的数据）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">self, batch</span>):</span><br><span class="line">	batch_im_id = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">	cam_infos, K = [], []</span><br><span class="line">	det_infos, bboxes = [], []</span><br><span class="line">	<span class="keyword">for</span> n, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(batch): <span class="comment"># normally only one batch</span></span><br><span class="line">		<span class="keyword">assert</span> n == <span class="number">0</span></span><br><span class="line">		images, masks, obss = data</span><br><span class="line">		<span class="keyword">for</span> c, obs <span class="keyword">in</span> <span class="built_in">enumerate</span>(obss): <span class="comment"># iterate along different views</span></span><br><span class="line">			batch_im_id += <span class="number">1</span></span><br><span class="line">			frame_info = obs[<span class="string">&#x27;frame_info&#x27;</span>]</span><br><span class="line">			im_info = &#123;k: frame_info[k] <span class="keyword">for</span> k <span class="keyword">in</span> (<span class="string">&#x27;scene_id&#x27;</span>, <span class="string">&#x27;view_id&#x27;</span>, <span class="string">&#x27;group_id&#x27;</span>)&#125; <span class="comment"># info for the image</span></span><br><span class="line">			im_info.update(batch_im_id=batch_im_id)</span><br><span class="line">			cam_info = im_info.copy() <span class="comment"># info for camera</span></span><br><span class="line"></span><br><span class="line">			K.append(obs[<span class="string">&#x27;camera&#x27;</span>][<span class="string">&#x27;K&#x27;</span>]) <span class="comment"># info for 相机内参</span></span><br><span class="line">			cam_infos.append(cam_info)</span><br><span class="line"></span><br><span class="line">			<span class="keyword">for</span> o, obj <span class="keyword">in</span> <span class="built_in">enumerate</span>(obs[<span class="string">&#x27;objects&#x27;</span>]):</span><br><span class="line">				obj_info = <span class="built_in">dict</span>(</span><br><span class="line">					label=obj[<span class="string">&#x27;name&#x27;</span>],</span><br><span class="line">					score=<span class="number">1.0</span>,</span><br><span class="line">				)</span><br><span class="line">				obj_info.update(im_info) <span class="comment"># add key-value pair from im_info to obj_info</span></span><br><span class="line">				bboxes.append(obj[<span class="string">&#x27;bbox&#x27;</span>])</span><br><span class="line">				det_infos.append(obj_info)</span><br><span class="line"></span><br><span class="line">	gt_detections = tc.PandasTensorCollection(</span><br><span class="line">		infos=pd.DataFrame(det_infos),</span><br><span class="line">		bboxes=torch.as_tensor(np.stack(bboxes)),</span><br><span class="line">	) <span class="comment"># 包括每一个ground truthdetection的的基本info,和检测框 </span></span><br><span class="line">	cameras = tc.PandasTensorCollection(</span><br><span class="line">		infos=pd.DataFrame(cam_infos),</span><br><span class="line">		K=torch.as_tensor(np.stack(K)),</span><br><span class="line">	)<span class="comment"># 包括每一view 相机的基本info（和detection info相同）,和内参</span></span><br><span class="line">	data = <span class="built_in">dict</span>(</span><br><span class="line">		images=images,</span><br><span class="line">		cameras=cameras,</span><br><span class="line">		gt_detections=gt_detections,</span><br><span class="line">	)</span><br><span class="line">	<span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>

<p>最重要的function: <code>get_predictions</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_predictions</span>(<span class="params">self, pose_predictor, mv_predictor,</span></span><br><span class="line"><span class="params">					detections=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">					n_coarse_iterations=<span class="number">1</span>, n_refiner_iterations=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">					sv_score_th=<span class="number">0.0</span>, skip_mv=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">					use_detections_TCO=<span class="literal">False</span></span>):</span><br></pre></td></tr></table></figure>

<p>Responsible for generating predictions for object poses in a scene using both single-view and multi-view approaches.</p>
<ol>
<li><p><strong>Input Parameters:</strong></p>
<ul>
<li><code>pose_predictor</code>: single view predictor，比如ycbv数据集用的就是posecnn的检测模型</li>
<li><code>mv_predictor</code>: An object or function that predicts scene states using multi-view information.</li>
<li><code>detections</code>: A collection of detected objects with associated information, pre-generated and saved in a .pkl file</li>
<li><code>n_coarse_iterations</code>, <code>n_refiner_iterations</code>: Number of iterations for coarse and refinement pose estimation.</li>
<li><code>sv_score_th</code>: Score threshold for single-view detections.</li>
<li><code>skip_mv</code>: A flag to skip multi-view predictions.</li>
<li><code>use_detections_TCO</code>: A flag to use detections for initial pose estimation.</li>
</ul>
</li>
<li><p><strong>Filtering Detections:</strong><br> 需要注意的是这里使用的detection是直接来自预存好的检测数据（非ground truth）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">posecnn_detections = load_posecnn_results()</span><br></pre></td></tr></table></figure>

<ul>
<li>The function filters the input <code>detections</code> based on the <code>sv_score_th</code> threshold.</li>
<li>It assigns a unique detection ID to each detection and creates an index based on <code>scene_id</code> and <code>view_id</code>.</li>
</ul>
</li>
<li><p><strong>Iterating Over Data:</strong></p>
<ul>
<li>The function iterates over batches of data from the <code>dataloader</code>.</li>
<li>For each batch, it extracts images, camera information, and ground truth detections.</li>
</ul>
</li>
<li><p><strong>Matching Detections:</strong></p>
<ul>
<li>It matches the detections with the current batch of data using the index created earlier.</li>
<li>It filters and prepares the detections for processing.</li>
</ul>
</li>
<li><p><strong>Pose Prediction:</strong></p>
<ul>
<li>If there are detections, it uses the <code>pose_predictor</code> to get single-view predictions.</li>
<li>It registers the initial bounding boxes with the candidates.</li>
</ul>
</li>
<li><p><strong>Multi-View Prediction:</strong></p>
<ul>
<li>If <code>skip_mv</code> is <code>False</code>, it uses the <code>mv_predictor</code> to predict the scene state using multi-view information.</li>
</ul>
</li>
<li><p><strong>Collecting Predictions:</strong></p>
<ul>
<li>It collects the single-view and multi-view predictions into a dictionary.</li>
</ul>
</li>
<li><p><strong>Concatenating Results:</strong></p>
<ul>
<li>It concatenates the predictions across all batches and returns the final predictions.</li>
</ul>
</li>
</ol>
<h4 id="MultiviewScenePredictor"><a href="#MultiviewScenePredictor" class="headerlink" title="MultiviewScenePredictor"></a><code>MultiviewScenePredictor</code></h4><p>作用：<br>used by <code>Myltiview_PredictionRunner.get_predictions</code><br>In <code>run_cosypose_eval</code> we initialize <code>MultiviewScenePredictor</code>  in this way:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv_predictor = MultiviewScenePredictor(mesh_db)</span><br></pre></td></tr></table></figure>

<p>In the <code>MultiviewScenePredictor</code> we use the mesh_db to initialize <code>MultiviewRefinement</code> and solve:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">problem = MultiviewRefinement(candidates=candidates_n,</span><br><span class="line">                    cameras=cameras,</span><br><span class="line">	                pairs_TC1C2=pairs_TC1C2,</span><br><span class="line">	                mesh_db=<span class="variable language_">self</span>.mesh_db_ba)</span><br><span class="line">ba_outputs = problem.solve(</span><br><span class="line">	n_iterations=ba_n_iter,</span><br><span class="line">	optimize_cameras=<span class="keyword">not</span> use_known_camera_poses,</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>The <code>solve</code> function of <code>MultiviewRefinement</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">solve</span>(<span class="params">self, sample_n_init=<span class="number">1</span>, **lm_kwargs</span>):</span><br><span class="line">	timer_init = Timer()</span><br><span class="line">	timer_opt = Timer()</span><br><span class="line">	timer_misc = Timer()</span><br><span class="line"></span><br><span class="line">	timer_init.start()</span><br><span class="line">	TWO_9d_init, TCW_9d_init = <span class="variable language_">self</span>.robust_initialization_TWO_TCW(n_init=sample_n_init)</span><br><span class="line">	timer_init.pause()</span><br><span class="line"></span><br><span class="line">	timer_opt.start()</span><br><span class="line">	TWO_9d_opt, TCW_9d_opt, history = <span class="variable language_">self</span>.optimize_lm(</span><br><span class="line">		TWO_9d_init, TCW_9d_init, **lm_kwargs)</span><br><span class="line">	timer_opt.pause()</span><br><span class="line"></span><br><span class="line">	timer_misc.start()</span><br><span class="line">	objects, cameras = <span class="variable language_">self</span>.make_scene_infos(TWO_9d_opt, TCW_9d_opt)</span><br><span class="line">	objects_init, cameras_init = <span class="variable language_">self</span>.make_scene_infos(TWO_9d_init, TCW_9d_init)</span><br><span class="line">	history = <span class="variable language_">self</span>.convert_history(history)</span><br><span class="line">	timer_misc.pause()</span><br><span class="line"></span><br><span class="line">	outputs = <span class="built_in">dict</span>(</span><br><span class="line">		objects_init=objects_init,</span><br><span class="line">		cameras_init=cameras_init,</span><br><span class="line">		objects=objects,</span><br><span class="line">		cameras=cameras,</span><br><span class="line">		history=history,</span><br><span class="line">		time_init=timer_init.stop(),</span><br><span class="line">		time_opt=timer_opt.stop(),</span><br><span class="line">		time_misc=timer_misc.stop(),</span><br><span class="line">	)</span><br><span class="line">	<span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>


<h2 id="Adaption"><a href="#Adaption" class="headerlink" title="Adaption"></a>Adaption</h2><p>准备基于<code>run_custom_scenario</code>进行修改<br><code>run_custom_scenario</code>的使用方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m cosypose.scripts.run_custom_scenario --scenario=example</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">Setting OMP and MKL num threads to 1.</span><br><span class="line">pybullet build time: Jan 28 2022 20:13:03</span><br><span class="line">0:00:00.000859 - -----------------------------------------------</span><br><span class="line">---------------------------------</span><br><span class="line">0:00:00.000921 - scenario: example</span><br><span class="line">0:00:00.000942 - sv_score_th: 0.3</span><br><span class="line">0:00:00.000956 - n_symmetries_rot: 64</span><br><span class="line">0:00:00.000956 - n_symmetries_rot: 64</span><br><span class="line">0:00:00.000968 - ransac_n_iter: 2000</span><br><span class="line">0:00:00.000980 - ransac_dist_threshold: 0.02</span><br><span class="line">0:00:00.001002 - nms_th: 0.04</span><br><span class="line">0:00:00.001015 - no_visualization: False</span><br><span class="line">0:00:00.001026 - -----------------------------------------------</span><br><span class="line">---------------------------------</span><br><span class="line">0:00:00.569089 - Loaded 796 candidates <span class="keyword">in</span> 8 views.</span><br><span class="line">0:00:00.570278 - Loaded cameras intrinsics.</span><br><span class="line">0:00:00.690990 - Loaded 30 3D object models.</span><br><span class="line">0:00:00.691047 - Running stage 2 and 3 of CosyPose...</span><br><span class="line">0:00:01.145408 - Num candidates: 107</span><br><span class="line">0:00:01.145468 - Num views: 8</span><br><span class="line">0:00:01.145728 - Estimating camera poses using RANSAC.</span><br><span class="line">0:00:04.588304 - Matched candidates: 49</span><br><span class="line">0:00:04.588375 - RANSAC time_models: 0:00:02.390068</span><br><span class="line">0:00:04.588398 - RANSAC time_score: 0:00:00.990740</span><br><span class="line">0:00:04.588415 - RANSAC time_misc: 0:00:00.061626</span><br><span class="line">0:00:04.902268 - BA time_init: 0:00:00.005349</span><br><span class="line">0:00:04.902333 - BA time_opt: 0:00:00.091822</span><br><span class="line">0:00:04.902351 - BA time_misc: 0:00:00.004793</span><br><span class="line">0:00:04.491746 - Subscene 0 has 8 objects and 7 cameras.</span><br><span class="line">0:00:04.512850 - Wrote predicted scene (objects+cameras): /home/cyl/cosypose/local_data/custom_scenarios/example/</span><br><span class="line">results/subscene=0/predicted_scene.json</span><br><span class="line">0:00:04.512906 - Wrote predicted objects with pose expressed <span class="keyword">in</span> camera frame: /home/cyl/cosypose/local_data/custo</span><br><span class="line">m_scenarios/example/results/subscene=0/scene_reprojected.csv</span><br></pre></td></tr></table></figure>
<p>该脚本只接收了candidates, mesh_db和camera_k信息，直接运行mv_predictor</p>
<p>写一个通过list输入构建candidates的function:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">read_list_candidates_cameras</span>(<span class="params">self, data_list, cameras_K_list</span>):</span><br><span class="line">	<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	Creates a PandasTensorCollection from a list of candidates information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	Args:</span></span><br><span class="line"><span class="string">		data_list (list): Each element is a dictionary with keys:</span></span><br><span class="line"><span class="string">			- &quot;candidates&quot; (list of dict): Each candidate dictionary includes:</span></span><br><span class="line"><span class="string">				- &quot;label&quot; (str): The label of the object.</span></span><br><span class="line"><span class="string">				- &quot;score&quot; (float): The confidence score of the object.</span></span><br><span class="line"><span class="string">				- &quot;pose&quot; (torch.Tensor): A [4, 4] torch.Tensor representing the pose matrix.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	Returns:</span></span><br><span class="line"><span class="string">		PandasTensorCollection: Contains poses and infos.</span></span><br><span class="line"><span class="string">	&quot;&quot;&quot;</span></span><br><span class="line">	all_poses = []</span><br><span class="line">	all_infos = []</span><br><span class="line">	all_K = []</span><br><span class="line"></span><br><span class="line">	<span class="comment"># Initialize view_id to be assigned automatically</span></span><br><span class="line">	view_id = <span class="number">0</span></span><br><span class="line">	scene_id = <span class="number">0</span>  <span class="comment"># Fixed value for scene_id</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> view, K <span class="keyword">in</span> <span class="built_in">zip</span>(data_list, cameras_K_list):</span><br><span class="line">		all_K.append(K)</span><br><span class="line">		<span class="keyword">for</span> candidate <span class="keyword">in</span> view[<span class="string">&quot;candidates&quot;</span>]:</span><br><span class="line">			label = candidate[<span class="string">&quot;label&quot;</span>]</span><br><span class="line">			score = candidate[<span class="string">&quot;score&quot;</span>]</span><br><span class="line">			pose = candidate[<span class="string">&quot;pose&quot;</span>]</span><br><span class="line"></span><br><span class="line">			<span class="comment"># Append the pose tensor</span></span><br><span class="line">			all_poses.append(pose)</span><br><span class="line"></span><br><span class="line">			<span class="comment"># Append the metadata</span></span><br><span class="line">			all_infos.append(&#123;</span><br><span class="line">				<span class="string">&quot;view_id&quot;</span>: view_id,</span><br><span class="line">				<span class="string">&quot;scene_id&quot;</span>: scene_id,</span><br><span class="line">				<span class="string">&quot;score&quot;</span>: score,</span><br><span class="line">				<span class="string">&quot;label&quot;</span>: label</span><br><span class="line">			&#125;)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Increment view_id for the next set of candidates</span></span><br><span class="line">		view_id += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">	K_tensor = torch.stack(all_K).to(dtype=torch.float32, device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># Stack poses into a single tensor</span></span><br><span class="line">	poses_tensor = torch.stack(all_poses).to(dtype=torch.float32, device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># Create a Pandas DataFrame for infos</span></span><br><span class="line">	infos_df = pd.DataFrame(all_infos)</span><br><span class="line">	<span class="comment"># Return the PandasTensorCollection-like structure</span></span><br><span class="line">	ptc_candidate = tc.PandasTensorCollection(poses=poses_tensor, infos=infos_df)</span><br><span class="line">	cam_info = infos_df.loc[:,[<span class="string">&quot;view_id&quot;</span>]]</span><br><span class="line">	cam_info = cam_info.drop_duplicates()</span><br><span class="line">	ptc_cam = tc.PandasTensorCollection(K=K_tensor, infos=cam_info)</span><br><span class="line">	<span class="keyword">return</span> ptc_candidate, ptc_cam</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example usage:</span></span><br><span class="line">example_data = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;candidates&quot;</span>: [</span><br><span class="line">            &#123;<span class="string">&quot;label&quot;</span>: <span class="string">&quot;obj_000017&quot;</span>, <span class="string">&quot;score&quot;</span>: <span class="number">0.829675</span>, <span class="string">&quot;pose&quot;</span>: torch.eye(<span class="number">4</span>)&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;label&quot;</span>: <span class="string">&quot;obj_000010&quot;</span>, <span class="string">&quot;score&quot;</span>: <span class="number">0.820436</span>, <span class="string">&quot;pose&quot;</span>: torch.eye(<span class="number">4</span>) * <span class="number">2</span>&#125;,</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;candidates&quot;</span>: [</span><br><span class="line">            &#123;<span class="string">&quot;label&quot;</span>: <span class="string">&quot;obj_000005&quot;</span>, <span class="string">&quot;score&quot;</span>: <span class="number">0.104478</span>, <span class="string">&quot;pose&quot;</span>: torch.eye(<span class="number">4</span>) * <span class="number">3</span>&#125;,</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">example_cameras_K = [</span><br><span class="line">    torch.eye(<span class="number">3</span>),</span><br><span class="line">    torch.eye(<span class="number">3</span>) * <span class="number">2</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">cd, cam= read_list_candidates(example_data, example_cameras_K)</span><br><span class="line">cd, cam</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">(PandasTensorCollection(</span><br><span class="line">     poses: torch.Size([3, 4, 4]) torch.float32 cuda:0,</span><br><span class="line"> ----------------------------------------</span><br><span class="line">     infos:</span><br><span class="line">    view_id  scene_id     score       label</span><br><span class="line"> 0        0         0  0.829675  obj_000017</span><br><span class="line"> 1        0         0  0.820436  obj_000010</span><br><span class="line"> 2        1         0  0.104478  obj_000005</span><br><span class="line"> ),</span><br><span class="line"> PandasTensorCollection(</span><br><span class="line">     K: torch.Size([2, 3, 3]) torch.float32 cuda:0,</span><br><span class="line"> ----------------------------------------</span><br><span class="line">     infos:</span><br><span class="line">    view_id</span><br><span class="line"> 0        0</span><br><span class="line"> 1        1</span><br><span class="line"> ))</span><br></pre></td></tr></table></figure>
<p>之后就正常调用<code>MultiviewScenePredictor.predict_scene_state()</code> to estimate the scene:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">predictions = <span class="variable language_">self</span>.mv_predictor.predict_scene_state(candidates, cameras,</span><br><span class="line">									   score_th=<span class="variable language_">self</span>.sv_score_th,</span><br><span class="line">									   use_known_camera_poses=<span class="literal">False</span>,</span><br><span class="line">									   ransac_n_iter= <span class="variable language_">self</span>.ransac_n_iter,</span><br><span class="line">									   ransac_dist_threshold= <span class="variable language_">self</span>.ransac_dist_threshold,</span><br><span class="line">									   ba_n_iter= <span class="variable language_">self</span>.ba_n_iter)</span><br></pre></td></tr></table></figure>
<p>之后再使用Non-Maximum Suppression来聚合重复检出的物体</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">objects = predictions[<span class="string">&#x27;scene/objects&#x27;</span>]</span><br><span class="line">cameras = predictions[<span class="string">&#x27;scene/cameras&#x27;</span>]</span><br><span class="line">reproj = predictions[<span class="string">&#x27;ba_output&#x27;</span>]</span><br><span class="line"><span class="comment">#print(predictions)</span></span><br><span class="line"><span class="keyword">for</span> view_group <span class="keyword">in</span> np.unique(objects.infos[<span class="string">&#x27;view_group&#x27;</span>]):</span><br><span class="line">	objects_ = objects[np.where(objects.infos[<span class="string">&#x27;view_group&#x27;</span>] == view_group)[<span class="number">0</span>]]</span><br><span class="line">	cameras_ = cameras[np.where(cameras.infos[<span class="string">&#x27;view_group&#x27;</span>] == view_group)[<span class="number">0</span>]]</span><br><span class="line">	reproj_ = reproj[np.where(reproj.infos[<span class="string">&#x27;view_group&#x27;</span>] == view_group)[<span class="number">0</span>]]</span><br><span class="line">	objects_ = nms3d(objects_, th= <span class="variable language_">self</span>.nms_th, poses_attr=<span class="string">&#x27;TWO&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>最终输出<code>objects_</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">PandasTensorCollection(</span><br><span class="line">    TWO: torch.Size([10, 4, 4]) torch.float32 cuda:0,</span><br><span class="line">----------------------------------------</span><br><span class="line">    infos:</span><br><span class="line">   obj_id     score       label  n_cand  view_group  group_id  scene_id</span><br><span class="line">0       2  5.469747  obj_000016       7           0         0        16</span><br><span class="line">1       0  5.450335  obj_000017       8           0         0        16</span><br><span class="line">2       4  4.098602  obj_000012       8           0         0        16</span><br><span class="line">3       1  3.380887  obj_000010       6           0         0        16</span><br><span class="line">4       5  2.771779  obj_000015       6           0         0        16</span><br><span class="line">5       3  1.453180  obj_000011       4           0         0        16</span><br><span class="line">6       9  1.183983  obj_000014       3           0         0        16</span><br><span class="line">7       8  1.106775  obj_000013       2           0         0        16</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>Please refer to the notebook <code>custom_scene.ipynb</code>.</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-11-07T09:28:05.000Z" title="11/7/2024, 5:28:05 PM">2024-11-07</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-03-11T15:49:22.164Z" title="3/11/2025, 11:49:22 PM">2025-03-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">a minute read (About 135 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/11/07/%5BOBS%5DDeep%20Learning-CV-CosyPose--%20Consistent%20multi-view%20multi-object%20%206D%20pose%20estimation/">CosyPose-- Consistent multi-view multi-object  6D pose estimation</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>Estimate accurate 6D poses of multiple <strong>known</strong> objects in a 3D scene captured by <strong>multiple cameras with unknown positions</strong></p>
<div class="post-content"><a href="/2024/11/07/[OBS]Deep Learning-CV-CosyPose-- Consistent multi-view multi-object  6D pose estimation/Pasted_image_20241112222444.png" title="" title=" class="gallery-item"><img src="/2024/11/07/[OBS]Deep Learning-CV-CosyPose-- Consistent multi-view multi-object  6D pose estimation/Pasted_image_20241112222444.png" alt="" title=""></a></div>

<h3 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h3><ul>
<li>object pose hypotheses made in individual images cannot easily be expressed in a common reference frame when the relative transformations between the cameras are unknown(相机相对位置未知)</li>
<li>the single-view 6D object pose hypotheses have gross errors in the form of false positive and missed detections（由于视角遮蔽，会存在误报和错漏的情况）</li>
<li>the candidate 6D object poses estimated from input images are noisy as they suffer from depth ambiguities inherent to single view methods.（深度信息通常没那么精准）</li>
</ul>
<h2 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h2><div class="post-content"><a href="/2024/11/07/[OBS]Deep Learning-CV-CosyPose-- Consistent multi-view multi-object  6D pose estimation/Pasted_image_20241112224221.png" title="" title=" class="gallery-item"><img src="/2024/11/07/[OBS]Deep Learning-CV-CosyPose-- Consistent multi-view multi-object  6D pose estimation/Pasted_image_20241112224221.png" alt="" title=""></a></div>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-11-05T10:06:46.000Z" title="11/5/2024, 6:06:46 PM">2024-11-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-03-11T15:49:22.170Z" title="3/11/2025, 11:49:22 PM">2025-03-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">4 minutes read (About 649 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/11/05/%5BOBS%5DDeep%20Learning-Imitation%20Learnning-AR2-D2%20--%20Training%20a%20Robot%20Without%20a%20Robot/">AR2-D2 -- Training a Robot Without a Robot</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p><a target="_blank" rel="noopener" href="https://ar2d2.site/">https://ar2d2.site/</a></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>机器人执行任务的视频数据集非常重要，特别是对于Visual Imitation Learning来说。<br>想要获得这些训练集视频，传统的方法是人工引导机器人做相关动作，然后再录制，耗费大量人力和时间成本，最关键的是机器人是固定在实验室内的，能接触到的物品和任务比较有限，因此这些训练数据中不包含更日常的场景。</p>
<div class="post-content"><a href="/2024/11/05/[OBS]Deep Learning-Imitation Learnning-AR2-D2 -- Training a Robot Without a Robot/Pasted_image_20241106095202.png" title="" title=" class="gallery-item"><img src="/2024/11/05/[OBS]Deep Learning-Imitation Learnning-AR2-D2 -- Training a Robot Without a Robot/Pasted_image_20241106095202.png" alt="" title=""></a></div>


<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>提出了一个IOS APP，可以通过追踪用户手部的动作在视频中生成一个执行动作的AR机器人。</p>
<div class="post-content"><a href="/2024/11/05/[OBS]Deep Learning-Imitation Learnning-AR2-D2 -- Training a Robot Without a Robot/Pasted_image_20241106114807.png" title="" title=" class="gallery-item"><img src="/2024/11/05/[OBS]Deep Learning-Imitation Learnning-AR2-D2 -- Training a Robot Without a Robot/Pasted_image_20241106114807.png" alt="" title=""></a></div>

<h3 id="AR2-D2-系统细节"><a href="#AR2-D2-系统细节" class="headerlink" title="AR2-D2 系统细节"></a>AR2-D2 系统细节</h3><div class="post-content"><a href="/2024/11/05/[OBS]Deep Learning-Imitation Learnning-AR2-D2 -- Training a Robot Without a Robot/Pasted_image_20241106095410.png" title="" title=" class="gallery-item"><img src="/2024/11/05/[OBS]Deep Learning-Imitation Learnning-AR2-D2 -- Training a Robot Without a Robot/Pasted_image_20241106095410.png" alt="" title=""></a></div>

<p>如上图，AR2-D2 的设计和实现由两个主要组件组成。第一个组件是一个手机应用程序，它将 AR 机器人投射到现实世界中，允许用户与物理对象和 AR 机器人进行交互。第二个组件将收集的视频转换为可用于训练不同行为克隆代理的格式，这些克隆代理随后可以部署在真实的机器人上。</p>
<h3 id="IOS-Application"><a href="#IOS-Application" class="headerlink" title="IOS Application"></a>IOS Application</h3><p>Unity + AR Foundation kit（用于生成一个虚拟机械臂并布置在场景中）<br>传感器：苹果设备摄像头和自带的LiDAR<br>通过ios自己的人手姿态算法和深度信息获取手部动作，由此获取机械臂需要运动到的关键点，并且可以让AR界面中的机械臂移动到指定位置。</p>
<h3 id="Training-Data-Generation"><a href="#Training-Data-Generation" class="headerlink" title="Training Data Generation"></a>Training Data Generation</h3><p>得到APP生成的视频后消除人手并填补消除的区域（E2FGVI），就可以得到机械臂操作物体的视频，它可以用作基于视觉的模仿学习的训练数据。</p>
<h2 id="APP-Evaluation"><a href="#APP-Evaluation" class="headerlink" title="APP Evaluation"></a>APP Evaluation</h2><div class="post-content"><a href="/2024/11/05/[OBS]Deep Learning-Imitation Learnning-AR2-D2 -- Training a Robot Without a Robot/Pasted_image_20241106121849.png" title="" title=" class="gallery-item"><img src="/2024/11/05/[OBS]Deep Learning-Imitation Learnning-AR2-D2 -- Training a Robot Without a Robot/Pasted_image_20241106121849.png" alt="" title=""></a></div>

<h2 id="Real-Deployment-Evaluation"><a href="#Real-Deployment-Evaluation" class="headerlink" title="Real Deployment Evaluation"></a>Real Deployment Evaluation</h2><p>围绕三个常见的机器人任务收集演示：{press, push, pick up}</p>
<p>使用 Perciver-Actor (PERACT)训练基于 Transformer 的语言引导行为cloning policy</p>
<blockquote>
<p>PERACT takes a 3D voxel observation and a language goal (v, l) as input and produces <strong>discretized outputs</strong> for translation, rotation, and gripper state of the end-effector. These outputs, coupled with a motion planner, enable the execution of the task specified by the language goal.</p>
</blockquote>
<p>每一个agent执行一种任务（{press, push, pick up}），先训练3k次，然后再微调训练（3k iteration），用于缩小iphone摄像机和agent使用的kinect v2相机之间的偏差。</p>
<p>微调结果</p>
<div class="post-content"><a href="/2024/11/05/[OBS]Deep Learning-Imitation Learnning-AR2-D2 -- Training a Robot Without a Robot/Pasted_image_20241106133117.png" title="" title=" class="gallery-item"><img src="/2024/11/05/[OBS]Deep Learning-Imitation Learnning-AR2-D2 -- Training a Robot Without a Robot/Pasted_image_20241106133117.png" alt="" title=""></a></div>

<p>测试结果</p>
<div class="post-content"><a href="/2024/11/05/[OBS]Deep Learning-Imitation Learnning-AR2-D2 -- Training a Robot Without a Robot/Pasted_image_20241106133421.png" title="" title=" class="gallery-item"><img src="/2024/11/05/[OBS]Deep Learning-Imitation Learnning-AR2-D2 -- Training a Robot Without a Robot/Pasted_image_20241106133421.png" alt="" title=""></a></div>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-29T06:42:19.000Z" title="10/29/2024, 2:42:19 PM">2024-10-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-03-11T15:49:22.271Z" title="3/11/2025, 11:49:22 PM">2025-03-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">a few seconds read (About 18 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/10/29/%5BOBS%5DHRI-Human-robot%20interaction%20for%20robotic%20manipulator%20programming%20in%20%20Mixed%20Reality/">Human-robot interaction for robotic manipulator programming in  Mixed Reality</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><blockquote>
<p>和我毕设很像的工作，居然已经发ICRA了？</p>
</blockquote>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-28T07:48:36.000Z" title="10/28/2024, 3:48:36 PM">2024-10-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-03-11T15:49:22.270Z" title="3/11/2025, 11:49:22 PM">2025-03-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">7 minutes read (About 1119 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/10/28/%5BOBS%5DHRI-Augmented%20Reality%20and%20Robotics%20-%20A%20Survey%20and%20Taxonomy%20for%20AR-enhanced%20Human-Robot%20Interaction%20and%20Robotic%20Interfaces/">Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p>虽然近些年有关AR在人机交互方面应用的研究有很多，但是这些研究大都缺少<strong>系统性的分析</strong></p>
<blockquote>
<p>Recently, an increasing number of studies in HCI, HRI, and robotics have demonstrated how AR enables better interactions between people and robots. However, often research remains focused on individual explorations and key design strategies, and research questions are rarely analyzed systematically.</p>
</blockquote>
<p>本文主要给目前AR人机交互领域做一下分类（基于460篇文章）<br>AR人机交互主要分为这几种研究维度</p>
<ul>
<li>approaches to augmenting reality</li>
<li>characteristics of robots</li>
<li>purposes and benefits</li>
<li>classification of presented information</li>
<li>design components and strategies for visual augmentation</li>
<li>interaction techniques and modalities</li>
<li>application domains</li>
<li>evaluation strategies</li>
</ul>
<div class="post-content"><a href="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241029135747.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241029135747.png" alt="" title=""></a></div>


<p>AR最大的优势就是能够提供超出物理限制的丰富视觉反馈，减少工人的认知负荷<br>这个研究最终的目标是提供一个对于该领域的共同基础和理解。</p>
<h2 id="Definition-Scope-Contribution-Methodology"><a href="#Definition-Scope-Contribution-Methodology" class="headerlink" title="Definition, Scope, Contribution, Methodology"></a>Definition, Scope, Contribution, Methodology</h2><h3 id="HRI-amp-Robotic-Interfaces"><a href="#HRI-amp-Robotic-Interfaces" class="headerlink" title="HRI &amp; Robotic Interfaces"></a>HRI &amp; Robotic Interfaces</h3><p>机器人系统不单指传统工业机器人，在本研究中，我们不局限于任一种机器人。<br>Robotic interfaces 主要指”Interfaces that use robots or other actuated systems as medium for HCI”.</p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><p>该研究通过design space dimensions来呈现该领域的分类<br>拓宽了HCI和HRI的文献研究<br>讨论了促进该领域进一步研究的开放性研究问题和机会<br>有一个交互式网站 <a target="_blank" rel="noopener" href="https://ilab.ucalgary.ca/ar-and-robotics/">https://ilab.ucalgary.ca/ar-and-robotics/</a></p>
<div class="post-content"><a href="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241029142609.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241029142609.png" alt="" title=""></a></div>

<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><h3 id="Approaches-to-augmenting-reality"><a href="#Approaches-to-augmenting-reality" class="headerlink" title="Approaches to augmenting reality"></a>Approaches to augmenting reality</h3><p>根据增强现实硬件的布置位置（dimension 1），可以分为</p>
<ul>
<li>on-body</li>
<li>on-environment</li>
<li>on-robot<br>根据视觉增强的目标位置（dimension 2），可以分为</li>
<li>augmenting robots</li>
<li>augmenting surroundings</li>
</ul>
<div class="post-content"><a href="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241103132127.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241103132127.png" alt="" title=""></a></div>


<h3 id="Characteristics-of-robots"><a href="#Characteristics-of-robots" class="headerlink" title="Characteristics of robots"></a>Characteristics of robots</h3><ol>
<li>the form factor of robots （机器人类型）</li>
<li>the relationship between the users and robots （n:m）</li>
<li>size and scale of the robots</li>
<li>proximity for interactions (交互距离)</li>
</ol>
<div class="post-content"><a href="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241103135953.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241103135953.png" alt="" title=""></a></div>

<h3 id="Purposes-and-benefits"><a href="#Purposes-and-benefits" class="headerlink" title="Purposes and benefits"></a>Purposes and benefits</h3><ol>
<li>Facilitate Programming （类似毕设）<ul>
<li>在虚拟3D空间中编辑，可视化路径</li>
<li>通过物体识别把现实物体映射到虚拟空间用于抓取</li>
</ul>
</li>
<li>Support Real-time Control and Navigation</li>
<li>Improve Safety （类似毕设中的碰撞检测急停）</li>
<li>Communicate Intent （绘制机器人的意向轨迹）</li>
<li>Increase the Expressiveness （机器人的虚拟义体）</li>
</ol>
<div class="post-content"><a href="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241103141336.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241103141336.png" alt="" title=""></a></div>


<h3 id="Classification-of-presented-information"><a href="#Classification-of-presented-information" class="headerlink" title="Classification of presented information"></a>Classification of presented information</h3><ol>
<li>robot’s internal information<ol>
<li>robot’s internal status</li>
<li>robot’s software and hardware condition</li>
<li>robot’s internal functionality and capability</li>
</ol>
</li>
<li>external information about the environment<ol>
<li>sensor data from the internal or external sensors</li>
<li>camera or video feed</li>
<li>information about external objects</li>
<li>depth map or 3D reconstructed scene of the environment (就是hololens的环境感知网格)</li>
</ol>
</li>
<li>plan and activity<ol>
<li>a plan of the robot’s motion and behavior</li>
<li>simulation results of the programmed behavior</li>
<li>visualization of a target and goal</li>
<li>progress of the current task</li>
</ol>
</li>
<li>supplemental content</li>
</ol>
<div class="post-content"><a href="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241104113403.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241104113403.png" alt="" title=""></a></div>

<h3 id="Design-components-and-strategies-for-visual-augmentation"><a href="#Design-components-and-strategies-for-visual-augmentation" class="headerlink" title="Design components and strategies for visual augmentation"></a>Design components and strategies for visual augmentation</h3><p>这篇主要讨论呈现AR内容的方式</p>
<ol>
<li>UIs and Widgets<ol>
<li>Menus</li>
<li>Information Panels</li>
<li>Labels and Annotations</li>
<li>Controls and Handles</li>
<li>Monitors and Displays</li>
</ol>
</li>
<li>Spatial References and Visualizations (将空间3D图像叠加显示到现实空间中)<ol>
<li>Points and Locations</li>
<li>Paths and Trajectories</li>
<li>Areas and Boundaries</li>
<li>Other Visualizations（比如空间颜色&#x2F;热图可视化）</li>
</ol>
</li>
<li>Embedded Visual Effects （相较于Spatial References and Visualizations，不需要包含数据信息）<ol>
<li>anthropomorphic effects</li>
<li>virtual replica</li>
<li>texture mapping of physical objects</li>
</ol>
</li>
<li>Anthropomorphic Effects (机器人的社交拟人内容（谁来给增强一下社交拟人功能）)</li>
<li>Virtual Replica and Ghost Effects （虚拟物品）</li>
<li>Texture Mapping Effects based on Shape (例如给衣服换个图案)</li>
</ol>
<div class="post-content"><a href="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241104114741.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241104114741.png" alt="" title=""></a></div>

<h3 id="Interactions"><a href="#Interactions" class="headerlink" title="Interactions"></a>Interactions</h3><ol>
<li>Dimension-1. Level of Interactivity<div class="post-content"><a href="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241104161433.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241104161433.png" alt="" title=""></a></div></li>
<li>Dimension-2. Interaction Modalities<div class="post-content"><a href="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241104161449.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241104161449.png" alt="" title=""></a></div></li>
</ol>
<h3 id="Application-Domains"><a href="#Application-Domains" class="headerlink" title="Application Domains"></a>Application Domains</h3><div class="post-content"><a href="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241104163809.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]HRI-Augmented Reality and Robotics - A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces/Pasted_image_20241104163809.png" alt="" title=""></a></div>

<h3 id="Evaluation-strategies"><a href="#Evaluation-strategies" class="headerlink" title="Evaluation strategies"></a>Evaluation strategies</h3><ol>
<li>Evaluation through Demonstration (诸如在Seminar,workshop展示功能，示例程序)</li>
<li>Technical Evaluation<ol>
<li>延迟测量</li>
<li>物体跟踪误差</li>
<li>成功率</li>
<li>与其他系统的对比（tracking system for example）</li>
</ol>
</li>
<li>User Evaluation（通过访谈，问卷，通常和前两者结合）</li>
</ol>
<h2 id="Future"><a href="#Future" class="headerlink" title="Future"></a>Future</h2><ol>
<li>使AR-HR更具实用性<ol>
<li>头戴式AR设备的追踪误差（陀螺仪），可靠性仍需加强</li>
<li>在户外使用的局限性</li>
</ol>
</li>
<li>对AR HRI的新的设计探索<ol>
<li>可以依靠AR设计不局限于物理限制的机器人</li>
<li>更好的开发环境（因为目前的AR开发仍然主要使用平面显示器，可以思考有没有基于AR显示做程序设计的应用）</li>
</ol>
</li>
<li>AR for better decision making(针对用户)<ol>
<li>可视化场景数据</li>
<li>可解释性的机器人操作</li>
</ol>
</li>
<li>新颖交互设计<ol>
<li>更自然的交互方式（例如更自然地指定任务对象）</li>
<li>进一步融合虚拟和物理世界（让虚拟的交互能影响现实物理（经典最扯的放最后））</li>
</ol>
</li>
</ol>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2024/10/28/%5BOBS%5Dhexo-Blog%20Template%20For%20New%20Hexo%20User%20(%E7%B3%95)/"><img class="fill" src="/gallery/Hexo.png" alt="Blog Template For New Hexo User" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-27T19:14:22.000Z" title="10/28/2024, 3:14:22 AM">2024-10-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-03-11T15:49:21.829Z" title="3/11/2025, 11:49:21 PM">2025-03-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">4 minutes read (About 566 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/10/28/%5BOBS%5Dhexo-Blog%20Template%20For%20New%20Hexo%20User%20(%E7%B3%95)/">Blog Template For New Hexo User</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><h1 id="前摇部分"><a href="#前摇部分" class="headerlink" title="前摇部分"></a>前摇部分</h1><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>本地增添博客内容(markdown文件)-&gt;hexo根据文件内容生成网页源码-&gt;上通过指令上传(push)到github-&gt;github自行部署静态页面</p>
<h2 id="基本准备"><a href="#基本准备" class="headerlink" title="基本准备"></a>基本准备</h2><h3 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h3><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/xueweisuoyong/p/11914045.html">https://www.cnblogs.com/xueweisuoyong/p/11914045.html</a></p>
<h3 id="Github-shh-key"><a href="#Github-shh-key" class="headerlink" title="Github shh key"></a>Github shh key</h3><p>因为把本地写的内容传到github，需要绑定一个ssh密钥<br>参见：<a target="_blank" rel="noopener" href="https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent">https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t ed25519 -C <span class="string">&quot;guanshengyuanlu@163.com&quot;</span></span><br></pre></td></tr></table></figure>

<div class="post-content"><a href="/2024/10/28/[OBS]hexo-Blog Template For New Hexo User (糕)/Pasted_image_20241027192407.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]hexo-Blog Template For New Hexo User (糕)/Pasted_image_20241027192407.png" alt="" title=""></a></div>

<p>把这串公钥添加到github ssh settings里面</p>
<h3 id="安装npm"><a href="#安装npm" class="headerlink" title="安装npm"></a>安装npm</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/lizhong2008/article/details/133844070">https://blog.csdn.net/lizhong2008/article/details/133844070</a><br>最新版本即可</p>
<h2 id="本地部署"><a href="#本地部署" class="headerlink" title="本地部署"></a>本地部署</h2><p>设定本地的git config</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.email <span class="string">&quot;guanshengyuanlu@163.com&quot;</span></span><br><span class="line">git config --global user.name <span class="string">&quot;Draumurvakna&quot;</span></span><br></pre></td></tr></table></figure>

<p>克隆仓库</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git@github.com:Draumurvakna/MIGAO-Blog-Src.git</span><br><span class="line"><span class="built_in">cd</span> MIGAO-Blog-Src</span><br></pre></td></tr></table></figure>

<p>安装环境</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git submodule update --recursive --init   </span><br><span class="line">npm update</span><br><span class="line"><span class="built_in">cd</span> themes/icarus</span><br><span class="line">npm update</span><br></pre></td></tr></table></figure>

<h2 id="更新网站"><a href="#更新网站" class="headerlink" title="更新网站"></a>更新网站</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./show.sh <span class="comment">#预览</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./deploy.sh <span class="comment">#可以直接通过网页访https://draumurvakna.github.io/</span></span><br></pre></td></tr></table></figure>

<h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>网站上的每一篇文章在本地都是一份<a target="_blank" rel="noopener" href="https://markdown.com.cn/intro.html">markdown</a>文本文件，存在<code>source/_posts</code>中</p>
<div class="post-content"><a href="/2024/10/28/[OBS]hexo-Blog Template For New Hexo User (糕)/Pasted_image_20241027220857.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]hexo-Blog Template For New Hexo User (糕)/Pasted_image_20241027220857.png" alt="" title=""></a></div>
例如这里就有两篇示例文章

<p>通过指令<code>hexo new &quot;article title&quot;</code> 来创建一篇新博客</p>
<div class="post-content"><a href="/2024/10/28/[OBS]hexo-Blog Template For New Hexo User (糕)/Pasted_image_20241027221104.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]hexo-Blog Template For New Hexo User (糕)/Pasted_image_20241027221104.png" alt="" title=""></a></div>


<p>然后到对应文件里面编辑就行了<br>markdown的编辑器推荐用typora，当然如果足够硬核的话用txt文本编辑器也毫无问题！</p>
<p>如果想添加图片的话，就往同文件夹下的资源文件夹（和这篇博客名字相同的文件夹）中添加照片然后在文中输入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><div class="post-content"><a href="/2024/10/28/[OBS]hexo-Blog Template For New Hexo User (糕)/picture_name" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]hexo-Blog Template For New Hexo User (糕)/picture_name" alt="" title=""></a></div></span><br></pre></td></tr></table></figure>
<p>可以参考<code>Sample Blog</code></p>
<p>添加完自己想要的内容之后用<code>./deploy.sh</code>部署一下网站，稍等片刻，进到网站里就可以看到最新的变化了。</p>
<h1 id="后"><a href="#后" class="headerlink" title="后"></a>后</h1><h3 id="我想给博客换个背景"><a href="#我想给博客换个背景" class="headerlink" title="我想给博客换个背景"></a>我想给博客换个背景</h3><p>进到<code>themes/icarus/source/img</code>文件夹📁</p>
<div class="post-content"><a href="/2024/10/28/[OBS]hexo-Blog Template For New Hexo User (糕)/Pasted_image_20241027222139.png" title="" title=" class="gallery-item"><img src="/2024/10/28/[OBS]hexo-Blog Template For New Hexo User (糕)/Pasted_image_20241027222139.png" alt="" title=""></a></div>
把`lightBG.png`, `darkBG.jpg`换成别的图片，名字一致

<p>如果重新部署后发现没有更改，那就网页里按一下<code>&lt;Ctrl&gt;+F5</code></p>
<h3 id="我想换个头像👤"><a href="#我想换个头像👤" class="headerlink" title="我想换个头像👤"></a>我想换个头像👤</h3><p>如上图，改avatar.png</p>
<h3 id="关于评论系统的话需要自己搞定o"><a href="#关于评论系统的话需要自己搞定o" class="headerlink" title="关于评论系统的话需要自己搞定o"></a>关于评论系统的话需要自己搞定o</h3><p>参考 <a href="https://chen-yulin.github.io/2024/09/03/%5BOBS%5Dhexo-Hexo%20Comment%20System%20--%20Twikoo/">https://chen-yulin.github.io/2024/09/03/%5BOBS%5Dhexo-Hexo%20Comment%20System%20--%20Twikoo/</a></p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-24T10:43:05.000Z" title="10/24/2024, 6:43:05 PM">2024-10-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-03-11T15:49:22.158Z" title="3/11/2025, 11:49:22 PM">2025-03-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Review/">Review</a></span><span class="level-item">10 minutes read (About 1451 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/10/24/%5BOBS%5DDeep%20Learning-Federated%20Learning-Federated%20Learning%20Atlas/">Federated Learning Atlas</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p>联邦学习（Federated Learning, FL）作为一种新兴的分布式机器学习方法，已经引起了大量研究的关注。要系统地理解联邦学习的相关研究，建议遵循以下结构化的阅读图谱，以便逐步加深对其原理、应用和挑战的理解。</p>
<h3 id="1-基础与概念性论文"><a href="#1-基础与概念性论文" class="headerlink" title="1. 基础与概念性论文"></a>1. <strong>基础与概念性论文</strong></h3><p>   这些论文介绍了联邦学习的基本概念、目标、以及经典算法，是了解联邦学习的起点。</p>
<ul>
<li><p><strong>Konečnỳ, J., et al. (2016).</strong> “Federated Learning: Strategies for Improving Communication Efficiency” <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1610.05492">arXiv</a></p>
<ul>
<li>介绍了联邦学习的概念，提出了最早期的算法（如FedAvg），并讨论了如何优化通信效率。</li>
</ul>
</li>
<li><p><strong>McMahan, H. B., et al. (2017).</strong> “Communication-Efficient Learning of Deep Networks from Decentralized Data” <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1602.05629">arXiv</a></p>
<ul>
<li>这篇论文提出了经典的Federated Averaging (FedAvg) 算法，系统阐述了在分布式环境下训练深度学习模型时的通信效率问题。</li>
</ul>
</li>
<li><p><strong>Yang, Q., Liu, Y., Cheng, Y., Kang, Y., Chen, T., &amp; Yu, H. (2019).</strong> “Federated Learning” <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1902.04885">ACM Transactions on Intelligent Systems and Technology (TIST)</a></p>
<ul>
<li>详细综述了联邦学习的基本框架、挑战、技术和应用，适合作为综述性的阅读材料。</li>
</ul>
</li>
</ul>
<h3 id="2-隐私保护与安全性"><a href="#2-隐私保护与安全性" class="headerlink" title="2. 隐私保护与安全性"></a>2. <strong>隐私保护与安全性</strong></h3><p>   联邦学习的一个重要目标是确保数据的隐私和安全，这一领域的研究为其提供了理论基础和技术手段。</p>
<ul>
<li><p><strong>Bonawitz, K., et al. (2017).</strong> “Practical Secure Aggregation for Federated Learning on User-Held Data” <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.04482">arXiv</a></p>
<ul>
<li>讨论了如何在联邦学习中实现安全聚合（Secure Aggregation），即确保服务器无法知道单个客户端的模型更新内容，以保护用户隐私。</li>
</ul>
</li>
<li><p><strong>Geyer, R. C., Klein, T., &amp; Nabi, M. (2017).</strong> “Differentially Private Federated Learning: A Client Level Perspective” <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1712.07557">arXiv</a></p>
<ul>
<li>探讨了如何将差分隐私（Differential Privacy）应用于联邦学习中，以确保用户模型更新时的隐私。</li>
</ul>
</li>
<li><p><strong>Zhao, Y., et al. (2018).</strong> “Federated Learning with Non-IID Data” <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1806.00582">arXiv</a></p>
<ul>
<li>讨论了在非独立同分布（non-IID）数据的情况下，如何在联邦学习中实现模型训练，这是实际应用中的重要挑战之一。</li>
</ul>
</li>
</ul>
<h3 id="3-优化与效率"><a href="#3-优化与效率" class="headerlink" title="3. 优化与效率"></a>3. <strong>优化与效率</strong></h3><p>   联邦学习中的通信和计算效率问题是该领域的关键研究方向，许多研究尝试通过各种方法优化模型训练过程中的资源消耗。</p>
<ul>
<li><p><strong>Li, X., et al. (2020).</strong> “Federated Optimization in Heterogeneous Networks” <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1812.06127">arXiv</a></p>
<ul>
<li>讨论了在客户端计算能力和网络资源异质性情况下如何进行联邦优化。</li>
</ul>
</li>
<li><p><strong>Kairouz, P., et al. (2021).</strong> “Advances and Open Problems in Federated Learning” <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1912.04977">arXiv</a></p>
<ul>
<li>这篇论文对联邦学习的现状、挑战以及未来的研究方向进行了系统性综述，覆盖了通信效率、模型性能、隐私保护等多个方面。</li>
</ul>
</li>
<li><p><strong>Chen, M., et al. (2020).</strong> “Joint Learning and Communication Optimization for Federated Learning over Wireless Networks” <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1909.07972">arXiv</a></p>
<ul>
<li>探讨了如何在无线网络环境下优化联邦学习中的学习效率和通信效率。</li>
</ul>
</li>
</ul>
<h3 id="4-系统实现与工具"><a href="#4-系统实现与工具" class="headerlink" title="4. 系统实现与工具"></a>4. <strong>系统实现与工具</strong></h3><p>   要更好地理解联邦学习在实际中的应用和系统架构，可以参考一些开源框架和实际实现案例。</p>
<ul>
<li><p><strong>Google AI.</strong> “Federated Learning for Mobile Keyboard Prediction” <a target="_blank" rel="noopener" href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html">Blog Post</a></p>
<ul>
<li>这是联邦学习最早的实际应用之一，讲述了Google如何使用联邦学习提升手机键盘的预测能力。</li>
</ul>
</li>
<li><p><strong>TensorFlow Federated (TFF)</strong>: <a target="_blank" rel="noopener" href="https://github.com/tensorflow/federated">GitHub</a></p>
<ul>
<li>TensorFlow Federated是Google推出的一个开源框架，用于实现联邦学习的系统实验。通过阅读其文档，可以深入理解联邦学习的具体实现细节。</li>
</ul>
</li>
</ul>
<h3 id="5-联邦学习在各领域的应用"><a href="#5-联邦学习在各领域的应用" class="headerlink" title="5. 联邦学习在各领域的应用"></a>5. <strong>联邦学习在各领域的应用</strong></h3><p>   联邦学习在诸多行业中都具有广泛的应用，了解这些应用有助于扩展对联邦学习实际意义的认识。</p>
<ul>
<li><p><strong>Rieke, N., et al. (2020).</strong> “The Future of Digital Health with Federated Learning” <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2003.08119">arXiv</a></p>
<ul>
<li>探讨了联邦学习在医疗健康领域的应用，特别是在跨医院数据无法集中共享的情况下如何训练模型。</li>
</ul>
</li>
<li><p><strong>Hard, A., et al. (2019).</strong> “Federated Learning for Mobile Keyboard Prediction” <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1811.03604">arXiv</a></p>
<ul>
<li>描述了联邦学习在智能手机上如何用于改善键盘输入的预测性能。</li>
</ul>
</li>
</ul>
<h3 id="6-联邦学习的挑战与未来研究方向"><a href="#6-联邦学习的挑战与未来研究方向" class="headerlink" title="6. 联邦学习的挑战与未来研究方向"></a>6. <strong>联邦学习的挑战与未来研究方向</strong></h3><p>   对于未来的研究，联邦学习还面临许多挑战，比如系统异质性、模型性能与隐私保护的平衡等。</p>
<ul>
<li><strong>Wang, J., et al. (2021).</strong> “Federated Learning: Challenges, Methods, and Future Directions” <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1906.04978">arXiv</a><ul>
<li>这篇论文对联邦学习面临的主要挑战进行了分析，如数据不均衡、通信成本、模型性能等，并提出了一些未来的研究方向。</li>
</ul>
</li>
</ul>
<h3 id="联邦学习论文阅读图谱总结："><a href="#联邦学习论文阅读图谱总结：" class="headerlink" title="联邦学习论文阅读图谱总结："></a>联邦学习论文阅读图谱总结：</h3><ol>
<li><strong>基础理论</strong>：先了解联邦学习的基本框架和经典算法。</li>
<li><strong>隐私与安全</strong>：深入研究数据隐私保护和安全机制。</li>
<li><strong>优化与效率</strong>：关注如何优化联邦学习中的通信与计算。</li>
<li><strong>系统实现</strong>：通过工具和实际案例理解系统实现细节。</li>
<li><strong>应用领域</strong>：了解联邦学习在不同领域的实际应用。</li>
<li><strong>挑战与未来方向</strong>：展望联邦学习的未来挑战和潜在研究方向。</li>
</ol>
<p>通过这个图谱，你可以系统地了解联邦学习的关键领域，并逐步深入到各个具体问题的解决方法与研究前沿。</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2024/10/23/%5BOBS%5DGame-dev-Godot%20Learning%20Plan/"><img class="fill" src="/gallery/Godot.png" alt="Godot Learning Plan" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-22T17:04:38.000Z" title="10/23/2024, 1:04:38 AM">2024-10-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-03-11T15:49:21.797Z" title="3/11/2025, 11:49:21 PM">2025-03-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Schedule/">Schedule</a></span><span class="level-item">a minute read (About 190 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/10/23/%5BOBS%5DGame-dev-Godot%20Learning%20Plan/">Godot Learning Plan</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><h2 id="Godot-Editor"><a href="#Godot-Editor" class="headerlink" title="Godot Editor"></a>Godot Editor</h2><ul>
<li><input checked="" disabled="" type="checkbox"> Basic <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=q7wlSvt0JIc&list=PL4cUxeGkcC9iHCXBpxbdsOByZ55Ez4bgF">https://www.youtube.com/watch?v=q7wlSvt0JIc&amp;list=PL4cUxeGkcC9iHCXBpxbdsOByZ55Ez4bgF</a></li>
<li><input checked="" disabled="" type="checkbox"> UI <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RHcHMRUGDHU">https://www.youtube.com/watch?v=RHcHMRUGDHU</a></li>
<li><input disabled="" type="checkbox"> UI doc <a target="_blank" rel="noopener" href="https://docs.godotengine.org/en/stable/tutorials/ui/index.html">https://docs.godotengine.org/en/stable/tutorials/ui/index.html</a></li>
<li><input checked="" disabled="" type="checkbox"> UI theme <ul>
<li><input checked="" disabled="" type="checkbox"> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=jIk-OG5hG3k">https://www.youtube.com/watch?v=jIk-OG5hG3k</a></li>
<li><input checked="" disabled="" type="checkbox"> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=AxFKPXko35I">https://www.youtube.com/watch?v=AxFKPXko35I</a></li>
</ul>
</li>
<li><input disabled="" type="checkbox"> performance <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=q1nwCJpjURQ">https://www.youtube.com/watch?v=q1nwCJpjURQ</a></li>
</ul>
<h2 id="GDscript"><a href="#GDscript" class="headerlink" title="GDscript"></a>GDscript</h2><ul>
<li><input disabled="" type="checkbox"> Basic <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=e1zJS31tr88">https://www.youtube.com/watch?v=e1zJS31tr88</a></li>
<li><input disabled="" type="checkbox"> Simplify <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=74y6zWZfQKk">https://www.youtube.com/watch?v=74y6zWZfQKk</a></li>
<li><input disabled="" type="checkbox"> doc <a target="_blank" rel="noopener" href="https://docs.godotengine.org/en/stable/tutorials/scripting/gdscript/index.html">https://docs.godotengine.org/en/stable/tutorials/scripting/gdscript/index.html</a></li>
</ul>
<h2 id="GD-Shader"><a href="#GD-Shader" class="headerlink" title="GD-Shader"></a>GD-Shader</h2><ul>
<li><input disabled="" type="checkbox"> Intro <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=BRPy8n2Ayc8">https://www.youtube.com/watch?v=BRPy8n2Ayc8</a></li>
<li><input disabled="" type="checkbox"> doc <a target="_blank" rel="noopener" href="https://docs.godotengine.org/en/stable/tutorials/shaders/introduction_to_shaders.html">https://docs.godotengine.org/en/stable/tutorials/shaders/introduction_to_shaders.html</a></li>
<li><input disabled="" type="checkbox"> hand draw <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=4dfADUfyKTA&t=10s">https://www.youtube.com/watch?v=4dfADUfyKTA&amp;t=10s</a></li>
<li><input disabled="" type="checkbox"> water wave <ul>
<li><input disabled="" type="checkbox"> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=VSwVwIYEypY">https://www.youtube.com/watch?v=VSwVwIYEypY</a></li>
<li><input disabled="" type="checkbox"> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=tnCUzDhBGB0">https://www.youtube.com/watch?v=tnCUzDhBGB0</a></li>
</ul>
</li>
<li><input disabled="" type="checkbox"> toon shader <ul>
<li><input disabled="" type="checkbox"> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=io2y8RgF39A">https://www.youtube.com/watch?v=io2y8RgF39A</a> </li>
<li><input disabled="" type="checkbox"> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=1duRtTEc2SU">https://www.youtube.com/watch?v=1duRtTEc2SU</a></li>
</ul>
</li>
<li><input disabled="" type="checkbox"> Course <a target="_blank" rel="noopener" href="https://github.com/gdquest-demos/godot-shaders?tab=readme-ov-file">https://github.com/gdquest-demos/godot-shaders?tab=readme-ov-file</a></li>
</ul>
<h2 id="VFX"><a href="#VFX" class="headerlink" title="VFX"></a>VFX</h2><h2 id="Jolt"><a href="#Jolt" class="headerlink" title="Jolt"></a>Jolt</h2></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-22T14:32:24.000Z" title="10/22/2024, 10:32:24 PM">2024-10-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-03-11T15:49:21.637Z" title="3/11/2025, 11:49:21 PM">2025-03-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">2 minutes read (About 232 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/10/22/%5BOBS%5D%E4%BF%A1%E6%81%AF%E5%B7%AE-%E5%AF%86%E9%99%A2%E7%BD%97%E6%96%AF%E5%95%86%E5%AD%A6%E9%99%A2%E5%8F%8C%E5%AD%A6%E4%BD%8D%E9%A1%B9%E7%9B%AE/">密院罗斯商学院双学位项目</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p>研究生层面的罗斯商学院双学位项目<br>密大方面提供的硕士学位（授课型）：</p>
<ul>
<li>管理 <strong>30 credits</strong></li>
<li>供应链（管理）<strong>30 credits</strong></li>
<li>商务分析 (BA) <strong>36.5 credits</strong> 挺适合转商科，量化分析（programming required）</li>
</ul>
<p>密大的一年放在三年学制的<strong>最后一学年的6月~来年5月</strong>，我们认对方6学分，对方认我们Gateway<br>准入条件：</p>
<ul>
<li>密院研究生</li>
<li>对方的线上面试方式</li>
</ul>
<p>学费，<strong>5w$~6w$</strong> （如果承认学分学费可以打折），生活安娜堡预计1000$&#x2F;m，饮食1000$&#x2F;m， 杂项500$&#x2F;m</p>
<p>可以提供找工作的签证机会（利好留美发展者）<br>但是时间会和秋招冲突，会给国内找工作面试带来困难</p>
<p>发学位证书的时间在两边并不统一</p>
<p>26级包括<strong>专硕</strong>招生（和双学位挂钩）</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/5/">Previous</a></div><div class="pagination-next"><a href="/page/7/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/4/">4</a></li><li><a class="pagination-link" href="/page/5/">5</a></li><li><a class="pagination-link is-current" href="/page/6/">6</a></li><li><a class="pagination-link" href="/page/7/">7</a></li><li><a class="pagination-link" href="/page/8/">8</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/21/">21</a></li></ul></nav></div><style>.column.column-left,.column.column-right{display:none}</style><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Chen Yulin"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Chen Yulin</p><p class="is-size-6 is-block">SJTU student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Manchester by the Sea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">205</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">173</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Chen-Yulin" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">March 2025</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">February 2025</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item">January 2025</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">December 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/11/"><span class="level-start"><span class="level-item">November 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/07/"><span class="level-start"><span class="level-item">July 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">June 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/05/"><span class="level-start"><span class="level-item">May 2024</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/04/"><span class="level-start"><span class="level-item">April 2024</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">46</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-11T15:00:59.000Z">2025-03-11</time></p><p class="title"><a href="/2025/03/11/%5BOBS%5DReconstruct%20Anything-OMG-LLaVA/">OMG-LLaVA</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-11T11:46:24.000Z">2025-03-11</time></p><p class="title"><a href="/2025/03/11/%5BOBS%5DReconstruct%20Anything-PHYSCENE-%20Physically%20Interactable%203D%20Scene%20Synthesis%20for%20Embodied%20AI/">PHYSCENE- Physically Interactable 3D Scene Synthesis for Embodied AI</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-11T09:25:44.000Z">2025-03-11</time></p><p class="title"><a href="/2025/03/11/%5BOBS%5DReconstruct%20Anything-%E7%9B%B8%E8%BF%91%E5%B7%A5%E4%BD%9C-Scene%20Reconstruction%20with%20Functional%20Objects%20for%20Robot%20Autonomy/">Scene Reconstruction with Functional Objects for Robot Autonomy</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-11T09:01:07.000Z">2025-03-11</time></p><p class="title"><a href="/2025/03/11/%5BOBS%5DReconstruct%20Anything-%E7%9B%B8%E8%BF%91%E5%B7%A5%E4%BD%9C-Part-level%20Scene%20Reconstruction%20Affords%20Robot%20Interaction/">Part-level Scene Reconstruction Affords Robot Interaction</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-11T08:15:11.000Z">2025-03-11</time></p><p class="title"><a href="/2025/03/11/%5BOBS%5DReconstruct%20Anything-Semantic-DETR/">DETR</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/3D-Scene/"><span class="tag">3D-Scene</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/6-D/"><span class="tag">6-D</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AIGC/"><span class="tag">AIGC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AR/"><span class="tag">AR</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Academic/"><span class="tag">Academic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Aliyun/"><span class="tag">Aliyun</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/App/"><span class="tag">App</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BS4/"><span class="tag">BS4</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Beautify/"><span class="tag">Beautify</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Behaviorism/"><span class="tag">Behaviorism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Business/"><span class="tag">Business</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CADC/"><span class="tag">CADC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CD/"><span class="tag">CD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLIP/"><span class="tag">CLIP</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CV/"><span class="tag">CV</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Capstone/"><span class="tag">Capstone</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Communication/"><span class="tag">Communication</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Contrastive-Learning/"><span class="tag">Contrastive-Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Control/"><span class="tag">Control</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Csharp/"><span class="tag">Csharp</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Css/"><span class="tag">Css</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cuda/"><span class="tag">Cuda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DD/"><span class="tag">DD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DINO/"><span class="tag">DINO</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DT/"><span class="tag">DT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dataframe/"><span class="tag">Dataframe</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debate/"><span class="tag">Debate</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debugger/"><span class="tag">Debugger</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Diffusion/"><span class="tag">Diffusion</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Discrete-Mathematics/"><span class="tag">Discrete-Mathematics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docs/"><span class="tag">Docs</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dynamic-programming/"><span class="tag">Dynamic-programming</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ESP32/"><span class="tag">ESP32</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Education/"><span class="tag">Education</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embeded-System/"><span class="tag">Embeded-System</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embodied-AI/"><span class="tag">Embodied-AI</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emoation/"><span class="tag">Emoation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emotion/"><span class="tag">Emotion</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ethic/"><span class="tag">Ethic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FL/"><span class="tag">FL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Family/"><span class="tag">Family</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Federated-Learning/"><span class="tag">Federated-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Foundation/"><span class="tag">Foundation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Functional-programming/"><span class="tag">Functional programming</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Game/"><span class="tag">Game</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gated-NN/"><span class="tag">Gated-NN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Github/"><span class="tag">Github</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Godot/"><span class="tag">Godot</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HRI/"><span class="tag">HRI</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Haskell/"><span class="tag">Haskell</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Health/"><span class="tag">Health</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Html/"><span class="tag">Html</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Humanism/"><span class="tag">Humanism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hyprland/"><span class="tag">Hyprland</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IK/"><span class="tag">IK</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Grounding/"><span class="tag">Image-Grounding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Text/"><span class="tag">Image-Text</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ImitationLearning/"><span class="tag">ImitationLearning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Jolt/"><span class="tag">Jolt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Json/"><span class="tag">Json</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LSP/"><span class="tag">LSP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latex/"><span class="tag">Latex</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life/"><span class="tag">Life</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinearAlgebra/"><span class="tag">LinearAlgebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Live2d/"><span class="tag">Live2d</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Love/"><span class="tag">Love</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lua/"><span class="tag">Lua</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MBTI/"><span class="tag">MBTI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MR-AR/"><span class="tag">MR/AR</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mason/"><span class="tag">Mason</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Math/"><span class="tag">Math</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Meme/"><span class="tag">Meme</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mod/"><span class="tag">Mod</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Motivation/"><span class="tag">Motivation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Movie/"><span class="tag">Movie</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-modal/"><span class="tag">Multi-modal</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-view/"><span class="tag">Multi-view</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Music/"><span class="tag">Music</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NN/"><span class="tag">NN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Network/"><span class="tag">Network</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nodejs/"><span class="tag">Nodejs</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Numpy/"><span class="tag">Numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nvim/"><span class="tag">Nvim</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Object-Detection/"><span class="tag">Object-Detection</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Open-Vocabulary/"><span class="tag">Open-Vocabulary</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenCV/"><span class="tag">OpenCV</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Oral/"><span class="tag">Oral</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PHD/"><span class="tag">PHD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PSY/"><span class="tag">PSY</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pandas/"><span class="tag">Pandas</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Path/"><span class="tag">Path</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Philosophy/"><span class="tag">Philosophy</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PhysX/"><span class="tag">PhysX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Physical-Scene/"><span class="tag">Physical-Scene</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Physics-engine/"><span class="tag">Physics-engine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pio/"><span class="tag">Pio</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Planning/"><span class="tag">Planning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Plugin/"><span class="tag">Plugin</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PoseEstimation/"><span class="tag">PoseEstimation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Postgraduate/"><span class="tag">Postgraduate</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Prefab/"><span class="tag">Prefab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Probability/"><span class="tag">Probability</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/QML/"><span class="tag">QML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Quantum/"><span class="tag">Quantum</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROS/"><span class="tag">ROS</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reading/"><span class="tag">Reading</span><span class="tag">17</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Real2Sim/"><span class="tag">Real2Sim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reconstruct/"><span class="tag">Reconstruct</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regex/"><span class="tag">Regex</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reinforcement-learning/"><span class="tag">Reinforcement-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Repository/"><span class="tag">Repository</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robot/"><span class="tag">Robot</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robotics/"><span class="tag">Robotics</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SJTU-Lecture/"><span class="tag">SJTU-Lecture</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SSH/"><span class="tag">SSH</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scene-synthesis/"><span class="tag">Scene-synthesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Science-fiction/"><span class="tag">Science-fiction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scrap/"><span class="tag">Scrap</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Script/"><span class="tag">Script</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Segmentation/"><span class="tag">Segmentation</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Semantic/"><span class="tag">Semantic</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shader/"><span class="tag">Shader</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shell/"><span class="tag">Shell</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Signals-and-Systems/"><span class="tag">Signals and Systems</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sim2Real/"><span class="tag">Sim2Real</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sklearn/"><span class="tag">Sklearn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Snippets/"><span class="tag">Snippets</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Society/"><span class="tag">Society</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Star-rail/"><span class="tag">Star-rail</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Submodule/"><span class="tag">Submodule</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Supervised-learning/"><span class="tag">Supervised-learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Survey/"><span class="tag">Survey</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TC/"><span class="tag">TC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TOEFL/"><span class="tag">TOEFL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tasks/"><span class="tag">Tasks</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tech-Communication/"><span class="tag">Tech Communication</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Torch/"><span class="tag">Torch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Travel/"><span class="tag">Travel</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unity/"><span class="tag">Unity</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unsupervised-learning/"><span class="tag">Unsupervised-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLP/"><span class="tag">VLP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Version-management/"><span class="tag">Version-management</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ViT/"><span class="tag">ViT</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VideoEditing/"><span class="tag">VideoEditing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vim/"><span class="tag">Vim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WSL/"><span class="tag">WSL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Waybar/"><span class="tag">Waybar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wayland/"><span class="tag">Wayland</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Web/"><span class="tag">Web</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Website/"><span class="tag">Website</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Well-being/"><span class="tag">Well-being</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Window-manager/"><span class="tag">Window-manager</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/YKLL/"><span class="tag">YKLL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Zen/"><span class="tag">Zen</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%F0%9F%90%B1/"><span class="tag">🐱</span><span class="tag">1</span></a></div></div></div></div></div></div><style>.column.column-left,.column.column-right{display:block}</style></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img class="logo-img" src="/img/cyllogo.png" alt="Chen Yulin&#039;s Blog" height="28"><img class="logo-img-dark" src="/img/cyllogonight.png" alt="Chen Yulin&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 Chen Yulin</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/imaegoo/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><div class="searchbox-pinyin"><label class="checkbox"><input id="search-by-pinyin" type="checkbox" checked="checked"><span> 拼音检索</span></label></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/imaegoo/pinyin.js" defer></script><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script type="text/javascript" src="/js/imaegoo/imaegoo.js"></script><script type="text/javascript" src="/js/imaegoo/universe.js"></script><!-- hexo injector body_end start -->
<link rel="stylesheet" crossorigin href="https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.css" />
<script type="module" crossorigin src="https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.js"></script>
<script>
  window.CHATBOT_CONFIG = {
    endpoint: "https://webchat-bot-iqu-knzhgrvznd.cn-hangzhou.fcapp.run/chat", // 可以替换为 https://{your-fc-http-trigger-domain}/chat
    displayByDefault: false, // 默认不展示 AI 助手聊天框
    aiChatOptions: { // aiChatOptions 中 options 会传递 aiChat 组件，自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat
      conversationOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#conversation-options
        conversationStarters: [
          {prompt: '你是谁？'},
          {prompt: '博主又是谁？'},
          {prompt: '怎么使用这个网站？'},
          {prompt: '想要博主联系方式！'},
        ]
      },
      displayOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#display-options
        height: 600,
        width: 350,
      },
      personaOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#chat-personas
        assistant: {          name: '博主的AI助手，十四行诗参上！',
          // AI 助手的图标
          avatar: 'https://chen-yulin.github.io/thumb/14.png',
          tagline: '要不要试试问下面的问题呢？',
        }
      }
    }
  };
</script>
<style>
  :root {
    /* webchat 工具栏的颜色 */
    --webchat-toolbar-background-color: #1464E4;
    /* webchat 工具栏文字和按钮的颜色 */
    --webchat-toolbar-text-color: #FFF;
  }
  /* webchat 对话框如果被遮挡，可以尝试通过 z-index、bottom、left 等设置来调整位置 */
  .webchat-container {
    z-index: 100;
    bottom: 10px;
    right: 10px;
  }
  /* webchat 的唤起按钮如果被遮挡，可以尝试通过 z-index、bottom、left 等设置来调整位置 */
  .webchat-bubble-tip {
    z-index: 99;
    bottom: 60px;
    right: 20px;
  }
  .webchat-bubble-tip {
    overflow: visible !important;
  }
  @keyframes float {
    0% {
      transform: translateY(0px) translateX(-50%);
    }
    50% {
      transform: translateY(-10px) translateX(-50%);
    }
    100% {
      transform: translateY(0px) translateX(-50%);
    }
  }

  .webchat-bubble-tip::before {
    content: '';
    position: absolute;
    top: -25px;
    left: 70%;
    width: 40px;
    height: 40px;
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='white'%3E%3Cpath d='M20 2H4c-1.1 0-2 .9-2 2v18l4-4h14c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm0 14H6l-2 2V4h16v12z'/%3E%3C/svg%3E");
    background-repeat: no-repeat;
    background-position: center;
    background-size: contain;
    filter: drop-shadow(0 4px 6px rgba(0, 0, 0, 0.5));
    animation: float 3s ease-in-out infinite;
  }
</style><script data-pjax src="https://registry.npmmirror.com/oh-my-live2d/latest/files"></script><script>const oml2d = OML2D.loadOml2d({libraryUrls:{"complete":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/complete.js","cubism2":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism2.js","cubism5":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism5.js"},dockedPosition:"left",mobileDisplay:true,models:[{"path":"https://model.oml2d.com/mai/model.json","mobilePosition":[25,0],"mobileScale":0.1,"mobileStageStyle":{"width":125,"height":175},"motionPreloadStrategy":"ALL","position":[50,0],"scale":0.2,"stageStyle":{"width":250,"height":350}}],parentElement:document.body,primaryColor:"var(--btn-bg)",sayHello:false,tips:{style: {"width":230,"height":120,"left":"calc(50% - 20px)","top":"-100px"},mobileStyle: {"width":180,"height":80,"left":"calc(50% - 30px)","top":"-100px"},idleTips:{interval:15000,message:function(){
  return axios.get('https://v1.hitokoto.cn?c=i')
    .then(function (response) {
      return response.data.hitokoto ;
    })
    .catch(function (error) {
      console.error(error);
    });
}
}}});</script><!-- hexo injector body_end end --></body></html>