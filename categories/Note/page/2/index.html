<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta name="theme-color" content="#123456"><title>Category: Note - Chen Yulin&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#6495ed"><meta name="application-name" content="Icarus - Hexo Theme"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="msapplication-TileColor" content="#6495ed"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Icarus - Hexo Theme"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Chen Yulin&#039;s Blog"><meta property="og:url" content="http://chen-yulin.github.io/"><meta property="og:site_name" content="Chen Yulin&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://chen-yulin.github.io/img/og_image.png"><meta property="article:author" content="Chen Yulin"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://chen-yulin.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://chen-yulin.github.io"},"headline":"Chen Yulin's Blog","image":["http://chen-yulin.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Chen Yulin"},"publisher":{"@type":"Organization","name":"Chen Yulin's Blog","logo":{"@type":"ImageObject","url":{"light":"/img/cyllogo.png","dark":"/img/cyllogonight.png"}}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><script type="text/javascript" src="/js/imaegoo/night.js"></script><canvas id="universe"></canvas><canvas id="flower"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img class="logo-img" src="/img/cyllogo.png" alt="Chen Yulin&#039;s Blog" height="28"><img class="logo-img-dark" src="/img/cyllogonight.png" alt="Chen Yulin&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories/">Categories</a></li><li class="is-active"><a href="#" aria-current="page">Note</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-03-25T10:55:53.000Z" title="3/25/2025, 6:55:53 PM">2025-03-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-05-01T03:48:45.178Z" title="5/1/2025, 11:48:45 AM">2025-05-01</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">5 minutes read (About 724 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/03/25/%5BOBS%5D%E7%A7%91%E7%A0%94-(Roadmap)%20Deeper%20Scene%20Graph%20For%20Robots/">(Roadmap) Deeper Scene Graph For Robots</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><h2 id="针对的问题（任务场景）"><a href="#针对的问题（任务场景）" class="headerlink" title="针对的问题（任务场景）"></a>针对的问题（任务场景）</h2><p>Robotic planning and execution in open-world environments is a complex problem due to the <strong>vast state spaces</strong> and <strong>high variability of task embodiment</strong>.<br>例如针对家用场景：</p>
<ul>
<li>OVMM Challenge: <a target="_blank" rel="noopener" href="https://aihabitat.org/challenge/2023_homerobot_ovmm/">https://aihabitat.org/challenge/2023_homerobot_ovmm/</a><br>想要在这样复杂场景中执行 general, long-horizon, embodied tasks 需要生成一系列离散的动作，这些动作在都拥有累计和传播错误的可能。因此需要创建一个可行的计划并在该计划出现问题时恢复，需要对物理环境进行有效的抽象以及能够完全利用该抽象的planner。应对这些挑战需要整合自然语言理解，多粒度的场景抽象和理解以及有弹性的推理。</li>
</ul>
<p>目前粗粒度（object-level）的场景抽象（场景图构建）已经有许多工作了，详见Reconstruct-Anything Literature Review，在这些工作中，重点都在于object detection和 object-level visual relationship detection</p>
<p><strong>需要聚焦的部分是多粒度的场景抽象</strong><br>需要多粒度的原因：</p>
<ul>
<li>Scalability: 如果只有一个粒度，那么输入LLM的场景图token不可控，影响扩展性</li>
<li>想要和物体进行更复杂的交互（相较于抓取），需要明确物体各个part的位置，语义性质，和父物体的<strong>parent-child relationship</strong>。这就要求场景图的生成需要考虑更细粒度。</li>
<li>针对不同复杂度的物体，需要的物体粒度层级不同</li>
<li>对于不同任务，需要的物体粒度也不同。<br>具体案例（任务需要的颗粒度层次）：</li>
<li>&lt;Task&gt;给水壶加水：<ul>
<li>&lt;object-level&gt;水壶<ul>
<li>&lt;part-level&gt;壶盖</li>
<li>&lt;part-level&gt;把手</li>
</ul>
</li>
<li>&lt;object-level&gt;饮水机<ul>
<li>&lt;part-level&gt;操作面板<ul>
<li>&lt;part-level&gt;绿色按钮（常温水）</li>
<li>&lt;part-level&gt;红色按钮（开水）</li>
<li>&lt;part-level&gt;童锁</li>
</ul>
</li>
<li>&lt;part-level&gt;水槽</li>
</ul>
</li>
<li>&lt;object-level&gt;桌子<ul>
<li>&lt;part-level&gt;桌面</li>
</ul>
</li>
</ul>
</li>
<li>&lt;Task&gt;离开房间<ul>
<li>&lt;object-level&gt;门<ul>
<li>&lt;part-level&gt;把手</li>
<li>&lt;part-level&gt;纸条：“离开房间前把玩偶放回红筐”</li>
</ul>
</li>
<li>&lt;object-level&gt;黄鸭玩偶</li>
<li>&lt;object-level&gt;红框  <div class="post-content"><a href="/2025/03/25/[OBS]科研-(Roadmap) Deeper Scene Graph For Robots/Pasted_image_20250328103811.png" title="" title=" class="gallery-item"><img src="/2025/03/25/[OBS]科研-(Roadmap) Deeper Scene Graph For Robots/Pasted_image_20250328103811.png" alt="" title=""></a></div></li>
</ul>
</li>
</ul>
<p>在更细粒度（part-level）的场景抽象中，重点在于<strong>子物体和父物体关系的识别</strong></p>
<blockquote>
<p>除此，和object-level scene graph中的object detection相对的，是part-level scene graph的子物体语义的多粒度分割和语义信息提取，可以由现有的Semantic-SAM和类似CLIP或者其他多模态模型的语义特征提取器实现。</p>
</blockquote>
<h2 id="主要的研究流程"><a href="#主要的研究流程" class="headerlink" title="主要的研究流程"></a>主要的研究流程</h2><h3 id="明确研究对象Parent-child-Relationship"><a href="#明确研究对象Parent-child-Relationship" class="headerlink" title="明确研究对象Parent-child Relationship"></a>明确研究对象<strong>Parent-child Relationship</strong></h3><p>What aspects does parent-child relationship include?</p>
<ul>
<li>语义构成关系，即这个子物体的<strong>存在与否</strong>给父物体的语义带来了什么改变 Translation in embedding space.</li>
<li>kinematic relations，也就是需要把一个物体以一个运动学树的形式构建出来  <div class="post-content"><a href="/2025/03/25/[OBS]科研-(Roadmap) Deeper Scene Graph For Robots/Pasted_image_20250328143957.png" title="" title=" class="gallery-item"><img src="/2025/03/25/[OBS]科研-(Roadmap) Deeper Scene Graph For Robots/Pasted_image_20250328143957.png" alt="" title=""></a></div>
  <div class="post-content"><a href="/2025/03/25/[OBS]科研-(Roadmap) Deeper Scene Graph For Robots/Pasted_image_20250328150005.png" title="" title=" class="gallery-item"><img src="/2025/03/25/[OBS]科研-(Roadmap) Deeper Scene Graph For Robots/Pasted_image_20250328150005.png" alt="" title=""></a></div></li>
</ul>
<h3 id="项目流程的流程"><a href="#项目流程的流程" class="headerlink" title="项目流程的流程"></a>项目流程的流程</h3><h3 id="自监督的特征提取方法"><a href="#自监督的特征提取方法" class="headerlink" title="自监督的特征提取方法"></a>自监督的特征提取方法</h3><div class="post-content"><a href="/2025/03/25/[OBS]科研-(Roadmap) Deeper Scene Graph For Robots/Pasted_image_20250328145911.png" title="" title=" class="gallery-item"><img src="/2025/03/25/[OBS]科研-(Roadmap) Deeper Scene Graph For Robots/Pasted_image_20250328145911.png" alt="" title=""></a></div>


<div class="post-content"><a href="/2025/03/25/[OBS]科研-(Roadmap) Deeper Scene Graph For Robots/Pasted_image_20250417185849.png" title="" title=" class="gallery-item"><img src="/2025/03/25/[OBS]科研-(Roadmap) Deeper Scene Graph For Robots/Pasted_image_20250417185849.png" alt="" title=""></a></div></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/03/25/%5BOBS%5DReconstruct%20Anything-%E7%9B%B8%E8%BF%91%E5%B7%A5%E4%BD%9C-ConceptAgent=%20LLM-Driven%20Precondition%20Grounding%20and%20Tree%20Search%20for%20Robust%20Task%20Planning%20and%20Execution/"><img class="fill" src="/gallery/LLM.png" alt="ConceptAgent= LLM-Driven Precondition Grounding and Tree Search for Robust Task Planning and Execution" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-03-25T03:01:50.000Z" title="3/25/2025, 11:01:50 AM">2025-03-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-05-01T03:48:45.805Z" title="5/1/2025, 11:48:45 AM">2025-05-01</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/03/25/%5BOBS%5DReconstruct%20Anything-%E7%9B%B8%E8%BF%91%E5%B7%A5%E4%BD%9C-ConceptAgent=%20LLM-Driven%20Precondition%20Grounding%20and%20Tree%20Search%20for%20Robust%20Task%20Planning%20and%20Execution/">ConceptAgent= LLM-Driven Precondition Grounding and Tree Search for Robust Task Planning and Execution</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/03/24/%5BOBS%5D%E7%A7%91%E7%A0%94-Semantic-SAM%20Repository%20Application/"><img class="fill" src="/gallery/Linux.png" alt="Semantic-SAM Repository Application" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-03-24T15:40:23.000Z" title="3/24/2025, 11:40:23 PM">2025-03-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-05-01T03:48:45.179Z" title="5/1/2025, 11:48:45 AM">2025-05-01</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">3 minutes read (About 444 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/03/24/%5BOBS%5D%E7%A7%91%E7%A0%94-Semantic-SAM%20Repository%20Application/">Semantic-SAM Repository Application</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p>My repository: <a target="_blank" rel="noopener" href="https://github.com/Chen-Yulin/Semantic-SAM">https://github.com/Chen-Yulin/Semantic-SAM</a></p>
<h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><p>官方步骤：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch==1.13.1 torchvision==0.14.1 --extra-index-url https://download.pytorch.org/whl/cu113</span><br><span class="line">python -m pip install <span class="string">&#x27;git+https://github.com/MaureenZOU/detectron2-xyz.git&#x27;</span></span><br><span class="line">pip install git+https://github.com/cocodataset/panopticapi.git</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/UX-Decoder/Semantic-SAM</span><br><span class="line"><span class="built_in">cd</span> Semantic-SAM</span><br><span class="line">python -m pip install -r requirements.txt</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> DATASET=/pth/to/dataset  <span class="comment"># path to your coco data</span></span><br></pre></td></tr></table></figure>

<h3 id="一些绊脚石"><a href="#一些绊脚石" class="headerlink" title="一些绊脚石 ^ ^"></a>一些绊脚石 ^ ^</h3><h4 id="1"><a href="#1" class="headerlink" title="1"></a>1</h4><p>根据[[Cuda+Torch]]，<strong>需要先安装<code>cudatoolkit</code>和<code>cuda-toolkit</code></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda install nvidia/label/cuda-11.7.0::cuda-toolkit -c nvidia/label/cuda-11.7.0 </span><br><span class="line">conda install cudatoolkit <span class="comment"># no need to specify version</span></span><br><span class="line">conda <span class="built_in">env</span> config vars <span class="built_in">set</span> LD_LIBRARY_PATH=<span class="string">&quot;/home/cyl/miniconda3/envs/&lt;name&gt;/lib/&quot;</span></span><br><span class="line">conda <span class="built_in">env</span> config vars <span class="built_in">set</span> CPATH=<span class="string">&quot;/home/cyl/miniconda3/envs/&lt;name&gt;/include/&quot;</span></span><br><span class="line">conda <span class="built_in">env</span> config vars <span class="built_in">set</span> CUDA_HOME=<span class="string">&quot;/home/cyl/miniconda3/envs/&lt;name&gt;/&quot;</span></span><br></pre></td></tr></table></figure>
<p>然后按照<a target="_blank" rel="noopener" href="https://pytorch.org/get-started/previous-versions/">torch官网</a>的安装指令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.7 -c pytorch -c nvidia</span><br></pre></td></tr></table></figure>

<h4 id="2"><a href="#2" class="headerlink" title="2"></a>2</h4><p>第二行直接运行可能会报错，提示系统gcc版本过高，安装<code>gcc=11.2.0</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge gcc=11.2.0</span><br><span class="line">conda install -c conda-forge gxx=11.2.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定编译器路径</span></span><br><span class="line"><span class="built_in">export</span> CC=<span class="variable">$CONDA_PREFIX</span>/bin/gcc</span><br><span class="line"><span class="built_in">export</span> CXX=<span class="variable">$CONDA_PREFIX</span>/bin/g++</span><br></pre></td></tr></table></figure>
<p>如果编译时出现<code>ld: cannot find -lcudart: No such file or directory collect2: error: ld returned 1 exit status</code> 报错，只是因为没有安装<code>cudatoolkit</code> ^ ^</p>
<h4 id="3"><a href="#3" class="headerlink" title="3"></a>3</h4><p>安装完成后直接<code>import semantic_sam</code>会报错<code>ModuleNotFoundError: No module named &#39;MultiScaleDeformableAttention&#39;</code> ^ ^<br>提示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Please compile MultiScaleDeformableAttention CUDA op with the following commands:</span><br><span class="line">	`<span class="built_in">cd</span> mask2former[/modeling/pixel_decoder/ops](http://127.0.0.1:8888/modeling/pixel_decoder/ops)`</span><br><span class="line">	`sh make.sh`</span><br></pre></td></tr></table></figure>
<p>需要手动make一下 <code>Mask2Former</code>:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> Mask2Former/mask2former/modeling/pixel_decoder/ops/</span><br><span class="line">sh make.sh</span><br></pre></td></tr></table></figure>

<h4 id="4"><a href="#4" class="headerlink" title="4"></a>4</h4><p>一些版本问题</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install gradio==3.37.0</span><br></pre></td></tr></table></figure>

<h2 id="Demo-🐱"><a href="#Demo-🐱" class="headerlink" title="Demo 🐱"></a>Demo 🐱</h2><h3 id="Generate-multi-granularity-Mask-on-CLICK"><a href="#Generate-multi-granularity-Mask-on-CLICK" class="headerlink" title="Generate multi-granularity Mask on CLICK"></a>Generate multi-granularity Mask on <strong>CLICK</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python demo.py --ckpt ./weights/swinl_only_sam_many2many.pth</span><br></pre></td></tr></table></figure>

<div class="post-content"><a href="/2025/03/24/[OBS]科研-Semantic-SAM Repository Application/Pasted_image_20250324170601.png" title="" title=" class="gallery-item"><img src="/2025/03/24/[OBS]科研-Semantic-SAM Repository Application/Pasted_image_20250324170601.png" alt="" title=""></a></div>
<div class="post-content"><a href="/2025/03/24/[OBS]科研-Semantic-SAM Repository Application/Pasted_image_20250324171359.png" title="" title=" class="gallery-item"><img src="/2025/03/24/[OBS]科研-Semantic-SAM Repository Application/Pasted_image_20250324171359.png" alt="" title=""></a></div>
<div class="post-content"><a href="/2025/03/24/[OBS]科研-Semantic-SAM Repository Application/Pasted_image_20250324171419.png" title="" title=" class="gallery-item"><img src="/2025/03/24/[OBS]科研-Semantic-SAM Repository Application/Pasted_image_20250324171419.png" alt="" title=""></a></div>
<div class="post-content"><a href="/2025/03/24/[OBS]科研-Semantic-SAM Repository Application/Pasted_image_20250324172143.png" title="" title=" class="gallery-item"><img src="/2025/03/24/[OBS]科研-Semantic-SAM Repository Application/Pasted_image_20250324172143.png" alt="" title=""></a></div>

<p><strong>Comment:</strong> 效果相较于SAM更多体现了语义的一致性，而不是基于texture进行分割。</p>
<h3 id="Automatically-Generate-Mask-on-Different-Granularity"><a href="#Automatically-Generate-Mask-on-Different-Granularity" class="headerlink" title="Automatically Generate Mask on Different Granularity"></a>Automatically Generate Mask on <strong>Different Granularity</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python demo_auto_generation.py --ckpt ./weights/swinl_only_sam_many2many.pth</span><br></pre></td></tr></table></figure>

<div class="post-content"><a href="/2025/03/24/[OBS]科研-Semantic-SAM Repository Application/Pasted_image_20250324173226.png" title="" title=" class="gallery-item"><img src="/2025/03/24/[OBS]科研-Semantic-SAM Repository Application/Pasted_image_20250324173226.png" alt="" title=""></a></div>
<div class="post-content"><a href="/2025/03/24/[OBS]科研-Semantic-SAM Repository Application/Pasted_image_20250324173324.png" title="" title=" class="gallery-item"><img src="/2025/03/24/[OBS]科研-Semantic-SAM Repository Application/Pasted_image_20250324173324.png" alt="" title=""></a></div>

</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/03/18/%5BOBS%5DReconstruct%20Anything-Relation-(UVtransE)%20Contextual%20Translation%20Embedding%20for%20Visual%20Relationship%20Detection%20and%20Scene%20Graph%20Generation/"><img class="fill" src="/gallery/Research-paper.png" alt="(UVtransE) Contextual Translation Embedding for Visual Relationship Detection and Scene Graph Generation" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-03-18T08:04:44.000Z" title="3/18/2025, 4:04:44 PM">2025-03-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-05-01T03:48:45.765Z" title="5/1/2025, 11:48:45 AM">2025-05-01</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 83 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/03/18/%5BOBS%5DReconstruct%20Anything-Relation-(UVtransE)%20Contextual%20Translation%20Embedding%20for%20Visual%20Relationship%20Detection%20and%20Scene%20Graph%20Generation/">(UVtransE) Contextual Translation Embedding for Visual Relationship Detection and Scene Graph Generation</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/03/18/[OBS]Reconstruct Anything-Relation-(UVtransE) Contextual Translation Embedding for Visual Relationship Detection and Scene Graph Generation/Pasted_image_20250318160643.png" title="" title=" class="gallery-item"><img src="/2025/03/18/[OBS]Reconstruct Anything-Relation-(UVtransE) Contextual Translation Embedding for Visual Relationship Detection and Scene Graph Generation/Pasted_image_20250318160643.png" alt="" title=""></a></div>
The **Union Visual Translation Embedding network (UVTransE)**, which learns three projection matrices $W_{s}$, $W_{o}$, $W_{u}$ which map the respective feature vectors of the bounding boxes enclosing the subject, object, and union of subject and object into a common embedding space, as well as translation vectors $t_{p}$ (to be consistent with [[(VtransE) Visual Translation Embedding Network for Visual Relation Detection]]) in the same space corresponding to each of the predicate labels that are present in the dataset.</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/03/08/%5BOBS%5DPython-PyTorch%20Einsum/"><img class="fill" src="/gallery/Python.png" alt="PyTorch Einsum" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-03-07T17:35:26.000Z" title="3/8/2025, 1:35:26 AM">2025-03-08</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-05-01T03:48:45.275Z" title="5/1/2025, 11:48:45 AM">2025-05-01</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/03/08/%5BOBS%5DPython-PyTorch%20Einsum/">PyTorch Einsum</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-18T14:40:07.000Z" title="2/18/2025, 10:40:07 PM">2025-02-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-05-01T03:48:45.294Z" title="5/1/2025, 11:48:45 AM">2025-05-01</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">25 minutes read (About 3683 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/18/%5BOBS%5DNSFC%20-%20SceneLLM+KnowledgeGraph/">NSFC</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/b0e12986bd2f9cb38846cd84de198c2b.jpg" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/b0e12986bd2f9cb38846cd84de198c2b.jpg" alt="" title=""></a></div>
## Related Works
### Scene-LLM
一系列（数量没有限制）深度图片整合为一整个可以输入大语言模型的token,
可以实现动态更新场景
可以基于场景进行推理，输出物体之间的关系
### ConceptFusion
用于从图像生成像素级clip embeding，由Scene-LLM使用
### CLIP
通过对齐text encoder 和image encoder, 用于图像分类。单独使用image encoder可以生成图像整体的feature(clip embeding)

<h3 id="一、研究背景与意义"><a href="#一、研究背景与意义" class="headerlink" title="一、研究背景与意义"></a>一、研究背景与意义</h3><p>在人机协作的工作环境中，准确地理解与推理工作场景至关重要。传统方法往往依赖静态感知技术，难以处理动态变化的场景信息。随着深度学习和大语言模型的进步，结合<strong>场景大模型</strong>与<strong>知识图谱</strong>的多模态推理技术，将为环境理解提供更强的动态感知和智能推理能力。</p>
<ul>
<li><strong>场景大模型（Scene-LLM）</strong>：通过输入深度图像或点云数据，将场景信息转化为可用于推理的tokens，从而动态更新并理解场景中物体的关系。</li>
<li><strong>ConceptFusion</strong>：从图像中生成像素级特征，通过与Scene-LLM结合，帮助生成精确的物体描述和物体关系。</li>
<li><strong>CLIP</strong>：通过文本和图像的对齐，生成图像的语义特征，可用来进行图像分类、物体比对及外形描述验证。</li>
<li><strong>知识图谱</strong>：用图形表示的知识结构，其中的节点表示实体（如物体、事件、任务等），边表示实体之间的关系。它通过对现实世界的知识进行结构化、语义化的表示，能够支持推理、查询、推荐等应用。在本研究中，知识图谱用于表示人机协作环境中的工件、工具、任务和环境之间的关系</li>
</ul>
<h3 id="二、研究目标"><a href="#二、研究目标" class="headerlink" title="二、研究目标"></a>二、研究目标</h3><p>本研究的目标是提出一种结合场景大模型（Scene-LLM）与知识图谱的动态工作环境理解方法，利用深度学习的图像处理、物体检测和推理能力，优化人机协作的效率和安全性。具体目标包括：</p>
<ol>
<li>动态环境感知与更新：通过Scene-LLM和ConceptFusion，对多视角的工人装配场景进行实时处理，准确识别物体和工具的位置信息。</li>
<li>任务与物体关系理解：构建基于知识图谱的任务理解模型，结合图文比对技术，优化任务分配与物体关系推理。</li>
<li>智能协作与优化：通过知识图谱和场景推理，实现任务分配与协作策略的自动调整，提升人机协作的灵活性与效率。</li>
</ol>
<h3 id="三、研究Pipeline"><a href="#三、研究Pipeline" class="headerlink" title="三、研究Pipeline"></a>三、研究Pipeline</h3><h4 id="0-知识图谱的构建"><a href="#0-知识图谱的构建" class="headerlink" title="0. 知识图谱的构建"></a>0. 知识图谱的构建</h4><p>知识图谱是机器人了解工人与工件之间关系的重要凭依，所以第一步需要构建工人任务的知识图谱。（<strong>融合持续学习和推理的思想</strong>）</p>
<p><strong>知识图谱的结构<strong><strong>（</strong></strong>表格的形式表示关系和实体的类型****）</strong>通常是由实体（Nodes）和关系（Edges）组成的图。在人机协作工作环境，本方案构建的知识图谱的结构包括以下几个主要组件：</p>
<ul>
<li><p><strong>Nodes</strong></p>
</li>
<li><p>工件：每个工件都作为一个节点，节点包含工件的属性（如形状、尺寸、材质等，也可以包括多角度的图片），注：工件不一定是单独的零件，可以是装配体，也因此，整个装配任务可以被组织为一个树状的装配流程</p>
</li>
<li><p>工具：每种工具作为一个节点，节点包含工件的属性（如形状、尺寸、材质等，也可以包括多角度的图片）。</p>
</li>
<li><p>人员：描述工人或操作人员的节点，包含技能、工作任务等信息。</p>
</li>
<li><p><strong>Edges</strong></p>
</li>
<li><p>包含（Part-of）：表示某个工件是另一个工件的组成部分。</p>
</li>
<li><p>依赖（Depends-on）：描述任务或工具之间的依赖关系。例如，某个装配任务依赖于特定工具或工件。</p>
</li>
<li><p>执行（Performs）：表示人员与任务之间的执行关系，指示某个人员执行特定的任务。</p>
</li>
</ul>
<h4 id="1-动态语义空间重构（通用场景大模型适配专业化的工作领域，不需要微调fine-tuning-free）"><a href="#1-动态语义空间重构（通用场景大模型适配专业化的工作领域，不需要微调fine-tuning-free）" class="headerlink" title="1. 动态语义空间重构（通用场景大模型适配专业化的工作领域，不需要微调fine-tuning free）"></a>1. 动态语义空间重构（通用场景大模型适配专业化的工作领域，不需要微调fine-tuning free）</h4><p><strong>有选择地更新（亮点）</strong></p>
<p>场景语义化的核心目标是从原始场景数据中提取出有意义的实体（如工件、工具等）和它们之间的关系，并为这些实体和关系赋予语义标签，并输出给下游的推理模块生成任务。</p>
<p>主要分为以下几个步骤：</p>
<ol>
<li><p>场景数据采集</p>
</li>
<li><ol>
<li>深度图像与点云数据：使用多视角深度相机采集工作环境中的深度图像和点云数据</li>
</ol>
</li>
<li><ol start="2">
<li>使用<strong>ConceptFusion</strong>生成每个视角的像素级特征点云，以获取精确的场景语义点云信息。</li>
</ol>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=YjAxMmY1NWQyOWEzMDlkZTM1ZGYxNTdlZjUyYzg5ZDZfbHA5ZUVFZXhzaDZ1NFA5N3hnd1ZIQUlmTFpabklpbEJfVG9rZW46TWhKbWJNWERSbzZrdTV4YkI1ZGNVVk0zbk1kXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=YjAxMmY1NWQyOWEzMDlkZTM1ZGYxNTdlZjUyYzg5ZDZfbHA5ZUVFZXhzaDZ1NFA5N3hnd1ZIQUlmTFpabklpbEJfVG9rZW46TWhKbWJNWERSbzZrdTV4YkI1ZGNVVk0zbk1kXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   全局的像素级特帧点云 <code>M</code> 由一系列点构成，每个点都由顶点位置，法向向量，置信度数量，颜色和概念向量（concept vector）组成</p>
<p>   想要生成这样的像素级特征点云<code>M</code>，首先需要进行帧（单张输入图片）预处理：通过一系列输入的深度图片获取顶点法相maps和相机方位，再通过计算获得每张图片中每个像素的语义上下文嵌入。其中，语义上下文的嵌入是通过结合局部和全局的CLIP features获得的。</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NGEzNWQ2NDUyZmE3NTgyZmJhZjBjYTUyNDdhMTc3MDVfTzZyMFpFM3oxbFN0M3FyR2xuNHhGR2Qxc1lwdTcwN3RfVG9rZW46QXF0UmJVR2pkb3RvQkV4b0FoT2NZRTZublZ6XzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NGEzNWQ2NDUyZmE3NTgyZmJhZjBjYTUyNDdhMTc3MDVfTzZyMFpFM3oxbFN0M3FyR2xuNHhGR2Qxc1lwdTcwN3RfVG9rZW46QXF0UmJVR2pkb3RvQkV4b0FoT2NZRTZublZ6XzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   然后再进行特征融合：通过相机的方位将每个帧的顶点和法相图映射到全局坐标系。对于帧$X_{t}$中的每个像素$(u，v)_t$，都在全局的点云图中具有相应的点$P_k$</p>
<p>   以下是将不同帧$X_t$中的特征集合在<code>M</code>中特征点的公式：</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NjE1NWU4ZTRiMzlkMTE5ZDI4OTliYzE4MjEzMjhiODlfZHZjTzQzQjJiZzdGTVEwWXUybW5HdHdYQ3Q5TXRZbHJfVG9rZW46QUtVd2JnYlBhb21waHN4Mm1YUWNTN3J4bmZnXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NjE1NWU4ZTRiMzlkMTE5ZDI4OTliYzE4MjEzMjhiODlfZHZjTzQzQjJiZzdGTVEwWXUybW5HdHdYQ3Q5TXRZbHJfVG9rZW46QUtVd2JnYlBhb21waHN4Mm1YUWNTN3J4bmZnXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   通过ConceptFusion的预处理和语义上下文嵌入，就获得了精确的场景语义点云信息。</p>
</li>
<li><p>场景Token化：由于场景语义点云的信息过于密集，导致信息长度不可控，不利于输入大模型，所以使用Scene-LLM中的体素<strong>均匀下采样方法</strong>，将图像数据转化为统一的tokens格式，确保数据可以与prompt一起输入Scene-LLM模型进行推理，同时也便于将场景进行动态更新。</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NWQ0ZDVmZTJkMzhlZGVlMzY0M2YwYWFiNGUyNjg4N2JfY0JvREx5dVpjWU9Fc2VjQXhoRXh5cnZ2Mks3S1V0QmdfVG9rZW46SW9yZmJ2dndqb0hLWnR4bnJZOWNFa0c4bnFnXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NWQ0ZDVmZTJkMzhlZGVlMzY0M2YwYWFiNGUyNjg4N2JfY0JvREx5dVpjWU9Fc2VjQXhoRXh5cnZ2Mks3S1V0QmdfVG9rZW46SW9yZmJ2dndqb0hLWnR4bnJZOWNFa0c4bnFnXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   具体来说，这里首先将空间分为具有尺寸x×y×z的固定分辨率体素网格，其中x，y，z代表沿着各个轴的素数。由于这种固定的分辨率，在不同场景中的体素数量有所不同。其次，对于每个体素，使用K近邻（KNN）方法将所有包含的点聚类。每个点的特征包括语义属性和空间坐标。由此可以获得特征的体素网格：</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=OTYxNjUzNDExMzE1NWVmNzJlZDczM2I1ZWU0OGJkMTBfWEExclJlTTEweTFLSW9ya2J5cDBMa1pValpqR29PbTBfVG9rZW46UUpTRWJCYzZ0b3lYVmp4R0lwRmNMZFpQbjJiXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=OTYxNjUzNDExMzE1NWVmNzJlZDczM2I1ZWU0OGJkMTBfWEExclJlTTEweTFLSW9ya2J5cDBMa1pValpqR29PbTBfVG9rZW46UUpTRWJCYzZ0b3lYVmp4R0lwRmNMZFpQbjJiXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   其中D是语义特征的维度，而3是空间坐标的维度。</p>
<p>   最后，计算可见性映射V∈{0，1} x×y×z，表明每个体素中的点存在（1）或不存在（0）。仅使用可见体素的特征用作视觉tokens。这种 hybrid-representation 通过均匀地采样点云信息设置来保留密集的空间信息，同时促进了语义特征空间的动态更新。</p>
<p>   语义体素网络的动态更新可以通过如下方式实现：为了更新场景以状态t的 $f^{vox}_t$ 到状态t + 1，我们首先从当前的摄像头视图渲染3D 帧。该帧的语义特征F被投影到3D点的特征映射Fˆ，并将其体素化为F^^{Vox}并且生成 visibility map Vˆ。然后使用以下方式更新语义体素网络</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=Zjg1ZGYyM2U3ZTgzZjM4MGI3OWFiNGU1YjZjZDM5MGJfaUJWYlJaOFZVY3BiQjZhVHFpNGZrS2pkTnN1ckdQUXhfVG9rZW46THFqNmJJdnJIb2QzTjB4OG56OWMzTlBvbnRlXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=Zjg1ZGYyM2U3ZTgzZjM4MGI3OWFiNGU1YjZjZDM5MGJfaUJWYlJaOFZVY3BiQjZhVHFpNGZrS2pkTnN1ckdQUXhfVG9rZW46THFqNmJJdnJIb2QzTjB4OG56OWMzTlBvbnRlXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   如此便可以确保3D场景的语义表示与任何场景状态变化保持同步。</p>
</li>
<li><p>Scene-LLM生成语义空间信息</p>
</li>
<li><ol>
<li>通过将场景Tokens和prompt结合输入Scene-LLM，得到工件，工具或其他工人所需物品的信息(<strong>粗标签</strong>+坐标)</li>
</ol>
</li>
<li><ol start="2">
<li>依据物品在场景中的坐标，获得相机视角下该物体的（多视角）裁剪图片</li>
</ol>
</li>
<li><ol start="3">
<li>如果是工件&#x2F;工具，则通过CLIP，将裁剪图与知识图谱中该物品的文字描述进行<strong>比对</strong>，得到工件或工具的具体ID和<strong>专业名称</strong>。</li>
</ol>
</li>
</ol>
<div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=MTUzYzYwYWYyMDYyYWE0ZThhNWI0ZmMyZTU5ODhjNmRfaXRGajVuN0dZRGgySXBVRTZDRDUwT3dXR2dXQk5LR0NfVG9rZW46Q05haWJOZzg1bzhxNzR4cWtCa2NieENablNjXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=MTUzYzYwYWYyMDYyYWE0ZThhNWI0ZmMyZTU5ODhjNmRfaXRGajVuN0dZRGgySXBVRTZDRDUwT3dXR2dXQk5LR0NfVG9rZW46Q05haWJOZzg1bzhxNzR4cWtCa2NieENablNjXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>

<p>CLIP（Contrastive Language-Image Pre-training）是一种基于对比学习的模型，旨在同时处理图像和文本数据，并将它们映射到一个共享的特征嵌入空间中。其训练过程包括对图像和文本对的学习，其中每一对图像和文本（如图像的描述）都会被处理成特征向量，图像由视觉编码器（通常是卷积神经网络或视觉Transformer）处理，文本则通过一个Transformer模型编码。模型的核心思想是通过对比学习的方式优化图像和文本之间的关系，使得正确配对的图像和文本在共享的嵌入空间中距离较近，而不相关的图像和文本则距离较远。这一过程通过对比损失函数（如InfoNCE）进行优化，模型逐渐学习到图像和文本之间的语义对应关系。CLIP在大规模图像-文本数据集上进行训练，通常涉及数百万对图像-文本配对，从而使其能够进行跨模态推理。训练完成后的CLIP能够在零-shot的情况下执行任务，即在没有专门训练的情况下处理新的计算机视觉和自然语言处理任务，如通过文本描述检索相关图像，或者根据图像检索相关文本。</p>
<p>想要比对裁剪图和物品的文字描述，可以通过使用预先使用CLIP预训练好的ViT图编码器和Transformer 文字编码器，分别用于编码物体的裁剪图和知识图谱中对于每一个工件的描述（并不需要每次识别都进行编码，可以预编码之后保存用于后续每次对比）。再使用裁剪图和文字的特征向量进行似然性评估，找到最贴合裁剪图的文字特征向量并由此获得裁剪图对应的具体工件或者工具序号。</p>
<p><strong>语义空间最终输出</strong>：场景中所有关键的工具、零件的标签（ID和<strong>专业名称</strong>）+精确位置坐标（场景中有啥，在哪）</p>
<h4 id="2-基于知识图谱的推理与任务生成"><a href="#2-基于知识图谱的推理与任务生成" class="headerlink" title="2. 基于知识图谱的推理与任务生成"></a>2. 基于知识图谱的推理与任务生成</h4><p>基于知识图谱的推理和任务生成方法在智能系统中扮演着关键角色，特别是在需要理解复杂场景和动态调整任务的应用中。</p>
<p>在获取了语义空间的信息后，知识图谱的应用主要分为以下几个步骤：</p>
<ol>
<li><p>通过工人的手部位置+语义空间的信息-&gt;判断当前正在装配的工件（检索&#x2F;搜索过程）+工人在用的工具</p>
</li>
<li><p>正在装配的工件+工人在用的工具+<strong>知识图谱</strong><strong>-&gt;<strong>判断下一步需要装配的零件以及需要的工具，并据此生成机器人需要执行的</strong>具体任务</strong>（比如抓取某区域的关键物体并放置到特定位置，更具体一些？）</p>
</li>
</ol>
<p>具体任务可能包括以下几种：</p>
<ul>
<li><p>GRASP <Pos>：</p>
<ul>
<li><p>任务描述：机器人需要抓取某一特定区域(<Pos>)的关键物体。</p>
</li>
<li><p>生成任务：结合语义空间的信息，系统会确定物体的精确位置（例如，某个工件的位置），并且会根据工件的形状、尺寸、重量等属性选择适当的抓取策略和工具。系统会向机器人发送抓取任务，指示其准确抓取目标物体。</p>
</li>
</ul>
</li>
<li><p>PLACE <Pos>：</p>
<ul>
<li><p>任务描述：机器人将物体放置到指定位置(<Pos>)。</p>
</li>
<li><p>生成任务：根据知识图谱和工人正在装配物体的位置，推理出工件的目标位置，例如，物体需要放置在某个工作台上的特定位置。</p>
</li>
<li><p>示例：将抓取的零件放置到工人需要的位置上，确保其放置的位置正确。</p>
</li>
</ul>
</li>
<li><p>GOTO <Pos>：</p>
<ul>
<li><p>任务描述：机器人末端移动到指定位置(<Pos>)。</p>
</li>
<li><p>生成任务：一般用于机器人执行完PLACE <Pos>后，归位以免阻碍工人操作工件</p>
</li>
</ul>
</li>
</ul>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-17T13:56:40.000Z" title="2/17/2025, 9:56:40 PM">2025-02-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-05-01T03:48:45.309Z" title="5/1/2025, 11:48:45 AM">2025-05-01</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 14 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/17/%5BOBS%5Dlinux-Docker/">Docker</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>proxy网络: <a target="_blank" rel="noopener" href="https://docs.docker.com/engine/daemon/proxy/#httphttps-proxy">https://docs.docker.com/engine/daemon/proxy/#httphttps-proxy</a></p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Moco-%20Momentum%20Contrast%20for%20Unsupervised%20Visual%20Representation%20Learning/"><img class="fill" src="/gallery/Research-paper.png" alt="Momentum Contrast for Unsupervised Visual Representation Learning" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-09T11:48:43.000Z" title="1/9/2025, 7:48:43 PM">2025-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-05-01T03:48:45.696Z" title="5/1/2025, 11:48:45 AM">2025-05-01</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">5 minutes read (About 722 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Moco-%20Momentum%20Contrast%20for%20Unsupervised%20Visual%20Representation%20Learning/">Momentum Contrast for Unsupervised Visual Representation Learning</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304154105.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304154105.png" alt="" title=""></a></div>
左侧是query encoder，右侧为key encoder
## 是什么
通过无监督对比学习的方法(loss:InfoNCE)来学习图像的特征。
<div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304154327.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304154327.png" alt="" title=""></a></div>
使用的pretext task是个体判别任务

<p>伪代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># f_q, f_k: encoder networks for query and key </span></span><br><span class="line"><span class="comment"># queue: dictionary as a queue of K keys (CxK) </span></span><br><span class="line"><span class="comment"># m: momentum </span></span><br><span class="line"><span class="comment"># t: temperature  </span></span><br><span class="line"></span><br><span class="line">f_k.params = f_q.params <span class="comment"># initialize </span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> loader: <span class="comment"># load a minibatch x with N samples </span></span><br><span class="line">	x_q = aug(x) <span class="comment"># a randomly augmented version </span></span><br><span class="line">	x_k = aug(x) <span class="comment"># another randomly augmented version  </span></span><br><span class="line">	q = f_q.forward(x_q) <span class="comment"># queries: NxC </span></span><br><span class="line">	k = f_k.forward(x_k) <span class="comment"># keys: NxC </span></span><br><span class="line">	k = k.detach() <span class="comment"># no gradient to keys  </span></span><br><span class="line">	</span><br><span class="line">	<span class="comment"># positive logits: Nx1 </span></span><br><span class="line">	l_pos = bmm(q.view(N,<span class="number">1</span>,C), k.view(N,C,<span class="number">1</span>))  <span class="comment"># 相当于把batch中每个正样本对之间求了cosine临近</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment"># negative logits: NxK </span></span><br><span class="line">	l_neg = mm(q.view(N,C), queue.view(C,K))  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># logits: Nx(1+K) </span></span><br><span class="line">	logits = cat([l_pos, l_neg], dim=<span class="number">1</span>)  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># contrastive loss, Eqn.(1) </span></span><br><span class="line">		labels = zeros(N) <span class="comment"># positives are the 0-th，将识别的类别视为0,可以直接使用CrossEntropyLoss</span></span><br><span class="line">	loss = CrossEntropyLoss(logits/t, labels)  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># SGD update: query network </span></span><br><span class="line">	loss.backward() </span><br><span class="line">	update(f_q.params)  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># momentum update: key network </span></span><br><span class="line">	f_k.params = m*f_k.params+(<span class="number">1</span>-m)*f_q.params  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># update dictionary </span></span><br><span class="line">	enqueue(queue, k) <span class="comment"># enqueue the current minibatch </span></span><br><span class="line">	dequeue(queue) <span class="comment"># dequeue the earliest minibatch</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="亮点"><a href="#亮点" class="headerlink" title="亮点"></a>亮点</h2><h3 id="Dictionary-as-a-queue"><a href="#Dictionary-as-a-queue" class="headerlink" title="Dictionary as a queue"></a>Dictionary as a queue</h3><p>在使用key encoder(momentum encoder)创建负样本，并把encode过的负样本存在一个queue（FIFO）中方便后续对比时直接使用，每次训练都会使用一个新的mini batch，此时会将此mini batch中的样本encode之后加入queue并删除存在最久的那个mini batch的样本（因为考虑到最老的mini batch使用的encoder是最过时的，所以FIFO是非常合理的），这样可以有效控制负样本的数量，也就是公式中的K。</p>
<ul>
<li>节省字典的计算开销</li>
<li>而且mini batch大小可以直接和负样本脱钩</li>
</ul>
<h3 id="Momentum-update"><a href="#Momentum-update" class="headerlink" title="Momentum update"></a>Momentum update</h3><p>因为负样本数量（字典&#x2F;队列）很大，所以没办法给key encoder回传梯度，所以可以考虑把query encoder的参数直接复制给key encoder，<strong>但过快改变的key encoder会导致样本字典的特征不一致</strong>，所以使用动量更新的方式。</p>
<div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304160138.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304160138.png" alt="" title=""></a></div>
> queue这个字典越大，那么理论上这个m就需要越大，保证字典中key的一致性

<h2 id="过往工作对比"><a href="#过往工作对比" class="headerlink" title="过往工作对比"></a>过往工作对比</h2><div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304160703.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304160703.png" alt="" title=""></a></div>
a)
所有的样本都在一个 mini batch 里，两个encoder完全一致，也因此都可以回传梯度，keys也高度一致，但限制了字典的大小

<p>b)<br>只有一个编码器进行学习。Memory bank存下了所有样本的key。每当梯度回传后，会把memory bank被本次训练中被采样过的key使用新的encoder进行更新。</p>
<ul>
<li>缺乏特帧一致性</li>
<li>需要训练一阵个epoch才能更新一遍memory bank</li>
</ul>
<p>MoCo和memory bank 更接近，但是使用了queue dictionary和momentum update</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-Vision%20Transformers%20Need%20Registers/"><img class="fill" src="/gallery/Research-paper.png" alt="Vision Transformers Need Registers" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-09T08:29:47.000Z" title="1/9/2025, 4:29:47 PM">2025-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-05-01T03:48:45.738Z" title="5/1/2025, 11:48:45 AM">2025-05-01</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-Vision%20Transformers%20Need%20Registers/">Vision Transformers Need Registers</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-DINOv2-%20Learning%20Robust%20Visual%20Features%20without%20Supervision/"><img class="fill" src="/gallery/Research-paper.png" alt="DINOv2- Learning Robust Visual Features without Supervision" referrerpolicy="no-referrer"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-09T08:28:49.000Z" title="1/9/2025, 4:28:49 PM">2025-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-05-01T03:48:45.707Z" title="5/1/2025, 11:48:45 AM">2025-05-01</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-DINOv2-%20Learning%20Robust%20Visual%20Features%20without%20Supervision/">DINOv2- Learning Robust Visual Features without Supervision</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/Note/">Previous</a></div><div class="pagination-next"><a href="/categories/Note/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/Note/">1</a></li><li><a class="pagination-link is-current" href="/categories/Note/page/2/">2</a></li><li><a class="pagination-link" href="/categories/Note/page/3/">3</a></li><li><a class="pagination-link" href="/categories/Note/page/4/">4</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/categories/Note/page/10/">10</a></li></ul></nav></div><style>.column.column-left,.column.column-right{display:none}</style><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Chen Yulin"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Chen Yulin</p><p class="is-size-6 is-block">SJTU student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Manchester by the Sea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">255</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">186</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Chen-Yulin" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/04/"><span class="level-start"><span class="level-item">April 2025</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">March 2025</span></span><span class="level-end"><span class="level-item tag">45</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">February 2025</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item">January 2025</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">December 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/11/"><span class="level-start"><span class="level-item">November 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/07/"><span class="level-start"><span class="level-item">July 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">June 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/05/"><span class="level-start"><span class="level-item">May 2024</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/04/"><span class="level-start"><span class="level-item">April 2024</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">46</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/2025/04/24/%5BOBS%5DDeep%20Learning-CV-Associative%20Embedding=%20End-to-End%20Learning%20for%20Joint%20Detection%20and%20Grouping/"><img src="/thumb/Research-paper.png" alt="Associative Embedding= End-to-End Learning for Joint Detection and Grouping"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-24T03:00:20.000Z">2025-04-24</time></p><p class="title"><a href="/2025/04/24/%5BOBS%5DDeep%20Learning-CV-Associative%20Embedding=%20End-to-End%20Learning%20for%20Joint%20Detection%20and%20Grouping/">Associative Embedding= End-to-End Learning for Joint Detection and Grouping</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/24/%5BOBS%5DDeep%20Learning-CV-CenterNet/"><img src="/thumb/Research-paper.png" alt="CenterNet"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-24T02:29:51.000Z">2025-04-24</time></p><p class="title"><a href="/2025/04/24/%5BOBS%5DDeep%20Learning-CV-CenterNet/">CenterNet</a></p><p class="categories"><a href="/categories/Review/">Review</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/23/%5BOBS%5D%E7%A7%91%E7%A0%94-FCSGG%20Repo%20Explanation/"><img src="/thumb/Python.png" alt="FCSGG Repo Explanation"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-23T14:34:47.000Z">2025-04-23</time></p><p class="title"><a href="/2025/04/23/%5BOBS%5D%E7%A7%91%E7%A0%94-FCSGG%20Repo%20Explanation/">FCSGG Repo Explanation</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/22/%5BOBS%5D%E7%A7%91%E7%A0%94-Detectron/"><img src="/thumb/Python.png" alt="Detectron"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-22T14:13:52.000Z">2025-04-22</time></p><p class="title"><a href="/2025/04/22/%5BOBS%5D%E7%A7%91%E7%A0%94-Detectron/">Detectron</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/22/%5BOBS%5D%E7%A7%91%E7%A0%94-FCSGG%20Repository%20Application/"><img src="/thumb/Python.png" alt="FCSGG Repository Application"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-22T10:08:07.000Z">2025-04-22</time></p><p class="title"><a href="/2025/04/22/%5BOBS%5D%E7%A7%91%E7%A0%94-FCSGG%20Repository%20Application/">FCSGG Repository Application</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/3D-Scene/"><span class="tag">3D-Scene</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/6-D/"><span class="tag">6-D</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AIGC/"><span class="tag">AIGC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AR/"><span class="tag">AR</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Academic/"><span class="tag">Academic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Aliyun/"><span class="tag">Aliyun</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/App/"><span class="tag">App</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BS4/"><span class="tag">BS4</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Beautify/"><span class="tag">Beautify</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Behaviorism/"><span class="tag">Behaviorism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Business/"><span class="tag">Business</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CADC/"><span class="tag">CADC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CD/"><span class="tag">CD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLIP/"><span class="tag">CLIP</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CV/"><span class="tag">CV</span><span class="tag">23</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Capstone/"><span class="tag">Capstone</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Communication/"><span class="tag">Communication</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Contrastive-Learning/"><span class="tag">Contrastive-Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Control/"><span class="tag">Control</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Csharp/"><span class="tag">Csharp</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Css/"><span class="tag">Css</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cuda/"><span class="tag">Cuda</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DD/"><span class="tag">DD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DINO/"><span class="tag">DINO</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DT/"><span class="tag">DT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dataframe/"><span class="tag">Dataframe</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debate/"><span class="tag">Debate</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debugger/"><span class="tag">Debugger</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Diffusion/"><span class="tag">Diffusion</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Discrete-Mathematics/"><span class="tag">Discrete-Mathematics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docs/"><span class="tag">Docs</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dynamic-programming/"><span class="tag">Dynamic-programming</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ESP32/"><span class="tag">ESP32</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Education/"><span class="tag">Education</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embeded-System/"><span class="tag">Embeded-System</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embodied-AI/"><span class="tag">Embodied-AI</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emoation/"><span class="tag">Emoation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emotion/"><span class="tag">Emotion</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ethic/"><span class="tag">Ethic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FL/"><span class="tag">FL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Family/"><span class="tag">Family</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Federated-Learning/"><span class="tag">Federated-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Foundation/"><span class="tag">Foundation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Functional-programming/"><span class="tag">Functional programming</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Game/"><span class="tag">Game</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gated-NN/"><span class="tag">Gated-NN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Github/"><span class="tag">Github</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Godot/"><span class="tag">Godot</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HPC/"><span class="tag">HPC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HRI/"><span class="tag">HRI</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Haskell/"><span class="tag">Haskell</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Health/"><span class="tag">Health</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hierarchical/"><span class="tag">Hierarchical</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Html/"><span class="tag">Html</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Humanism/"><span class="tag">Humanism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hyprland/"><span class="tag">Hyprland</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IK/"><span class="tag">IK</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Grounding/"><span class="tag">Image-Grounding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Text/"><span class="tag">Image-Text</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-generation/"><span class="tag">Image-generation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ImitationLearning/"><span class="tag">ImitationLearning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Jolt/"><span class="tag">Jolt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Json/"><span class="tag">Json</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LSP/"><span class="tag">LSP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latex/"><span class="tag">Latex</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life/"><span class="tag">Life</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinearAlgebra/"><span class="tag">LinearAlgebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Live2d/"><span class="tag">Live2d</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Love/"><span class="tag">Love</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lua/"><span class="tag">Lua</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MBTI/"><span class="tag">MBTI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MR-AR/"><span class="tag">MR/AR</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mason/"><span class="tag">Mason</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Math/"><span class="tag">Math</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Meme/"><span class="tag">Meme</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Message-Passing/"><span class="tag">Message-Passing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mod/"><span class="tag">Mod</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Motivation/"><span class="tag">Motivation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Movie/"><span class="tag">Movie</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-modal/"><span class="tag">Multi-modal</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-view/"><span class="tag">Multi-view</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Music/"><span class="tag">Music</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NN/"><span class="tag">NN</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Network/"><span class="tag">Network</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nodejs/"><span class="tag">Nodejs</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Numpy/"><span class="tag">Numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nvim/"><span class="tag">Nvim</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Object-Detection/"><span class="tag">Object-Detection</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Open-Vocabulary/"><span class="tag">Open-Vocabulary</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenCV/"><span class="tag">OpenCV</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Oral/"><span class="tag">Oral</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PHD/"><span class="tag">PHD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PSY/"><span class="tag">PSY</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pandas/"><span class="tag">Pandas</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Panoptic/"><span class="tag">Panoptic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Path/"><span class="tag">Path</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Philosophy/"><span class="tag">Philosophy</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PhysX/"><span class="tag">PhysX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Physical-Scene/"><span class="tag">Physical-Scene</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Physics-engine/"><span class="tag">Physics-engine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pio/"><span class="tag">Pio</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Planning/"><span class="tag">Planning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Plugin/"><span class="tag">Plugin</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PoseEstimation/"><span class="tag">PoseEstimation</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Postgraduate/"><span class="tag">Postgraduate</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Prefab/"><span class="tag">Prefab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Probability/"><span class="tag">Probability</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">26</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/QML/"><span class="tag">QML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Quantum/"><span class="tag">Quantum</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROS/"><span class="tag">ROS</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reading/"><span class="tag">Reading</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Real2Sim/"><span class="tag">Real2Sim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reconstruct/"><span class="tag">Reconstruct</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regex/"><span class="tag">Regex</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reinforcement-learning/"><span class="tag">Reinforcement-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Repository/"><span class="tag">Repository</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation-Learning/"><span class="tag">Representation-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Research-paper/"><span class="tag">Research-paper</span><span class="tag">84</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robot/"><span class="tag">Robot</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robotics/"><span class="tag">Robotics</span><span class="tag">16</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SJTU-Lecture/"><span class="tag">SJTU-Lecture</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SSH/"><span class="tag">SSH</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scene-graph/"><span class="tag">Scene-graph</span><span class="tag">29</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scene-synthesis/"><span class="tag">Scene-synthesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Science-fiction/"><span class="tag">Science-fiction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scrap/"><span class="tag">Scrap</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Script/"><span class="tag">Script</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Segmentation/"><span class="tag">Segmentation</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Semantic/"><span class="tag">Semantic</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shader/"><span class="tag">Shader</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shell/"><span class="tag">Shell</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Signals-and-Systems/"><span class="tag">Signals and Systems</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sim2Real/"><span class="tag">Sim2Real</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sklearn/"><span class="tag">Sklearn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Snippets/"><span class="tag">Snippets</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Society/"><span class="tag">Society</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Star-rail/"><span class="tag">Star-rail</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Subgraph/"><span class="tag">Subgraph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Submodule/"><span class="tag">Submodule</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Supervised-learning/"><span class="tag">Supervised-learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Survey/"><span class="tag">Survey</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TC/"><span class="tag">TC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TOEFL/"><span class="tag">TOEFL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Task-Planning/"><span class="tag">Task-Planning</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tasks/"><span class="tag">Tasks</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tech-Communication/"><span class="tag">Tech Communication</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Torch/"><span class="tag">Torch</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Translation-Embedding/"><span class="tag">Translation-Embedding</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Travel/"><span class="tag">Travel</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unity/"><span class="tag">Unity</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unsupervised-learning/"><span class="tag">Unsupervised-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLM/"><span class="tag">VLM</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLP/"><span class="tag">VLP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Version-management/"><span class="tag">Version-management</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ViT/"><span class="tag">ViT</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VideoEditing/"><span class="tag">VideoEditing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vim/"><span class="tag">Vim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Visual-Relation/"><span class="tag">Visual-Relation</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WSL/"><span class="tag">WSL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Waybar/"><span class="tag">Waybar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wayland/"><span class="tag">Wayland</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Web/"><span class="tag">Web</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Website/"><span class="tag">Website</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Well-being/"><span class="tag">Well-being</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Window-manager/"><span class="tag">Window-manager</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/YKLL/"><span class="tag">YKLL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Zen/"><span class="tag">Zen</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%F0%9F%90%B1/"><span class="tag">🐱</span><span class="tag">1</span></a></div></div></div></div></div></div><style>.column.column-left,.column.column-right{display:block}</style></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img class="logo-img" src="/img/cyllogo.png" alt="Chen Yulin&#039;s Blog" height="28"><img class="logo-img-dark" src="/img/cyllogonight.png" alt="Chen Yulin&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 Chen Yulin</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/imaegoo/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><div class="searchbox-pinyin"><label class="checkbox"><input id="search-by-pinyin" type="checkbox" checked="checked"><span> 拼音检索</span></label></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/imaegoo/pinyin.js" defer></script><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script type="text/javascript" src="/js/imaegoo/imaegoo.js"></script><script type="text/javascript" src="/js/imaegoo/universe.js"></script><script type="text/javascript" src="/js/imaegoo/falling-petals.js"></script><!-- hexo injector body_end start -->
<link rel="stylesheet" crossorigin href="https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.css" />
<script type="module" crossorigin src="https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.js"></script>
<script>
  window.CHATBOT_CONFIG = {
    endpoint: "https://webchat-bot-iqu-knzhgrvznd.cn-hangzhou.fcapp.run/chat", // 可以替换为 https://{your-fc-http-trigger-domain}/chat
    displayByDefault: false, // 默认不展示 AI 助手聊天框
    aiChatOptions: { // aiChatOptions 中 options 会传递 aiChat 组件，自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat
      conversationOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#conversation-options
        conversationStarters: [
          {prompt: '你是谁？'},
          {prompt: '博主又是谁？'},
          {prompt: '怎么使用这个网站？'},
          {prompt: '想要博主联系方式！'},
        ]
      },
      displayOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#display-options
        height: 600,
        width: 350,
      },
      personaOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#chat-personas
        assistant: {          name: '博主的AI助手，十四行诗参上！',
          // AI 助手的图标
          avatar: 'https://chen-yulin.github.io/thumb/14.png',
          tagline: '要不要试试问下面的问题呢？',
        }
      }
    }
  };
</script>
<style>
  :root {
    /* webchat 工具栏的颜色 */
    --webchat-toolbar-background-color: #1464E4;
    /* webchat 工具栏文字和按钮的颜色 */
    --webchat-toolbar-text-color: #FFF;
  }
  /* webchat 对话框如果被遮挡，可以尝试通过 z-index、bottom、left 等设置来调整位置 */
  .webchat-container {
    z-index: 100;
    bottom: 10px;
    right: 10px;
  }
  /* webchat 的唤起按钮如果被遮挡，可以尝试通过 z-index、bottom、left 等设置来调整位置 */
  .webchat-bubble-tip {
    z-index: 99;
    bottom: 60px;
    right: 20px;
  }
  .webchat-bubble-tip {
    overflow: visible !important;
  }
  @keyframes float {
    0% {
      transform: translateY(0px) translateX(-50%);
    }
    50% {
      transform: translateY(-10px) translateX(-50%);
    }
    100% {
      transform: translateY(0px) translateX(-50%);
    }
  }

  .webchat-bubble-tip::before {
    content: '';
    position: absolute;
    top: -25px;
    left: 70%;
    width: 40px;
    height: 40px;
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='white'%3E%3Cpath d='M20 2H4c-1.1 0-2 .9-2 2v18l4-4h14c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm0 14H6l-2 2V4h16v12z'/%3E%3C/svg%3E");
    background-repeat: no-repeat;
    background-position: center;
    background-size: contain;
    filter: drop-shadow(0 4px 6px rgba(0, 0, 0, 0.5));
    animation: float 3s ease-in-out infinite;
  }
</style><script data-pjax src="https://registry.npmmirror.com/oh-my-live2d/latest/files"></script><script>const oml2d = OML2D.loadOml2d({libraryUrls:{"complete":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/complete.js","cubism2":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism2.js","cubism5":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism5.js"},dockedPosition:"left",mobileDisplay:true,models:[{"path":"https://model.hacxy.cn/mai/model.json","mobilePosition":[25,0],"mobileScale":0.1,"mobileStageStyle":{"width":125,"height":175},"motionPreloadStrategy":"ALL","position":[50,0],"scale":0.2,"stageStyle":{"width":250,"height":350}}],parentElement:document.body,primaryColor:"var(--btn-bg)",sayHello:false,tips:{style: {"width":230,"height":120,"left":"calc(50% - 20px)","top":"-100px"},mobileStyle: {"width":180,"height":80,"left":"calc(50% - 30px)","top":"-100px"},idleTips:{interval:15000,message:function(){
  return axios.get('https://v1.hitokoto.cn?c=i')
    .then(function (response) {
      return response.data.hitokoto ;
    })
    .catch(function (error) {
      console.error(error);
    });
}
}}});</script><!-- hexo injector body_end end --></body></html>