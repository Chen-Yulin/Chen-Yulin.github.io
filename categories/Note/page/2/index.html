<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta name="theme-color" content="#123456"><title>Category: Note - Chen Yulin&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#6495ed"><meta name="application-name" content="Icarus - Hexo Theme"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="msapplication-TileColor" content="#6495ed"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Icarus - Hexo Theme"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Chen Yulin&#039;s Blog"><meta property="og:url" content="http://chen-yulin.github.io/"><meta property="og:site_name" content="Chen Yulin&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://chen-yulin.github.io/img/og_image.png"><meta property="article:author" content="Chen Yulin"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://chen-yulin.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://chen-yulin.github.io"},"headline":"Chen Yulin's Blog","image":["http://chen-yulin.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Chen Yulin"},"publisher":{"@type":"Organization","name":"Chen Yulin's Blog","logo":{"@type":"ImageObject","url":{"light":"/img/cyllogo.png","dark":"/img/cyllogonight.png"}}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><script type="text/javascript" src="/js/imaegoo/night.js"></script><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img class="logo-img" src="/img/cyllogo.png" alt="Chen Yulin&#039;s Blog" height="28"><img class="logo-img-dark" src="/img/cyllogonight.png" alt="Chen Yulin&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories/">Categories</a></li><li class="is-active"><a href="#" aria-current="page">Note</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-18T14:40:07.000Z" title="2/18/2025, 10:40:07 PM">2025-02-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-11T09:02:45.254Z" title="4/11/2025, 5:02:45 PM">2025-04-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">25 minutes read (About 3683 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/18/%5BOBS%5DNSFC%20-%20SceneLLM+KnowledgeGraph/">NSFC</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/b0e12986bd2f9cb38846cd84de198c2b.jpg" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/b0e12986bd2f9cb38846cd84de198c2b.jpg" alt="" title=""></a></div>
## Related Works
### Scene-LLM
一系列（数量没有限制）深度图片整合为一整个可以输入大语言模型的token,
可以实现动态更新场景
可以基于场景进行推理，输出物体之间的关系
### ConceptFusion
用于从图像生成像素级clip embeding，由Scene-LLM使用
### CLIP
通过对齐text encoder 和image encoder, 用于图像分类。单独使用image encoder可以生成图像整体的feature(clip embeding)

<h3 id="一、研究背景与意义"><a href="#一、研究背景与意义" class="headerlink" title="一、研究背景与意义"></a>一、研究背景与意义</h3><p>在人机协作的工作环境中，准确地理解与推理工作场景至关重要。传统方法往往依赖静态感知技术，难以处理动态变化的场景信息。随着深度学习和大语言模型的进步，结合<strong>场景大模型</strong>与<strong>知识图谱</strong>的多模态推理技术，将为环境理解提供更强的动态感知和智能推理能力。</p>
<ul>
<li><strong>场景大模型（Scene-LLM）</strong>：通过输入深度图像或点云数据，将场景信息转化为可用于推理的tokens，从而动态更新并理解场景中物体的关系。</li>
<li><strong>ConceptFusion</strong>：从图像中生成像素级特征，通过与Scene-LLM结合，帮助生成精确的物体描述和物体关系。</li>
<li><strong>CLIP</strong>：通过文本和图像的对齐，生成图像的语义特征，可用来进行图像分类、物体比对及外形描述验证。</li>
<li><strong>知识图谱</strong>：用图形表示的知识结构，其中的节点表示实体（如物体、事件、任务等），边表示实体之间的关系。它通过对现实世界的知识进行结构化、语义化的表示，能够支持推理、查询、推荐等应用。在本研究中，知识图谱用于表示人机协作环境中的工件、工具、任务和环境之间的关系</li>
</ul>
<h3 id="二、研究目标"><a href="#二、研究目标" class="headerlink" title="二、研究目标"></a>二、研究目标</h3><p>本研究的目标是提出一种结合场景大模型（Scene-LLM）与知识图谱的动态工作环境理解方法，利用深度学习的图像处理、物体检测和推理能力，优化人机协作的效率和安全性。具体目标包括：</p>
<ol>
<li>动态环境感知与更新：通过Scene-LLM和ConceptFusion，对多视角的工人装配场景进行实时处理，准确识别物体和工具的位置信息。</li>
<li>任务与物体关系理解：构建基于知识图谱的任务理解模型，结合图文比对技术，优化任务分配与物体关系推理。</li>
<li>智能协作与优化：通过知识图谱和场景推理，实现任务分配与协作策略的自动调整，提升人机协作的灵活性与效率。</li>
</ol>
<h3 id="三、研究Pipeline"><a href="#三、研究Pipeline" class="headerlink" title="三、研究Pipeline"></a>三、研究Pipeline</h3><h4 id="0-知识图谱的构建"><a href="#0-知识图谱的构建" class="headerlink" title="0. 知识图谱的构建"></a>0. 知识图谱的构建</h4><p>知识图谱是机器人了解工人与工件之间关系的重要凭依，所以第一步需要构建工人任务的知识图谱。（<strong>融合持续学习和推理的思想</strong>）</p>
<p><strong>知识图谱的结构<strong><strong>（</strong></strong>表格的形式表示关系和实体的类型****）</strong>通常是由实体（Nodes）和关系（Edges）组成的图。在人机协作工作环境，本方案构建的知识图谱的结构包括以下几个主要组件：</p>
<ul>
<li><p><strong>Nodes</strong></p>
</li>
<li><p>工件：每个工件都作为一个节点，节点包含工件的属性（如形状、尺寸、材质等，也可以包括多角度的图片），注：工件不一定是单独的零件，可以是装配体，也因此，整个装配任务可以被组织为一个树状的装配流程</p>
</li>
<li><p>工具：每种工具作为一个节点，节点包含工件的属性（如形状、尺寸、材质等，也可以包括多角度的图片）。</p>
</li>
<li><p>人员：描述工人或操作人员的节点，包含技能、工作任务等信息。</p>
</li>
<li><p><strong>Edges</strong></p>
</li>
<li><p>包含（Part-of）：表示某个工件是另一个工件的组成部分。</p>
</li>
<li><p>依赖（Depends-on）：描述任务或工具之间的依赖关系。例如，某个装配任务依赖于特定工具或工件。</p>
</li>
<li><p>执行（Performs）：表示人员与任务之间的执行关系，指示某个人员执行特定的任务。</p>
</li>
</ul>
<h4 id="1-动态语义空间重构（通用场景大模型适配专业化的工作领域，不需要微调fine-tuning-free）"><a href="#1-动态语义空间重构（通用场景大模型适配专业化的工作领域，不需要微调fine-tuning-free）" class="headerlink" title="1. 动态语义空间重构（通用场景大模型适配专业化的工作领域，不需要微调fine-tuning free）"></a>1. 动态语义空间重构（通用场景大模型适配专业化的工作领域，不需要微调fine-tuning free）</h4><p><strong>有选择地更新（亮点）</strong></p>
<p>场景语义化的核心目标是从原始场景数据中提取出有意义的实体（如工件、工具等）和它们之间的关系，并为这些实体和关系赋予语义标签，并输出给下游的推理模块生成任务。</p>
<p>主要分为以下几个步骤：</p>
<ol>
<li><p>场景数据采集</p>
</li>
<li><ol>
<li>深度图像与点云数据：使用多视角深度相机采集工作环境中的深度图像和点云数据</li>
</ol>
</li>
<li><ol start="2">
<li>使用<strong>ConceptFusion</strong>生成每个视角的像素级特征点云，以获取精确的场景语义点云信息。</li>
</ol>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=YjAxMmY1NWQyOWEzMDlkZTM1ZGYxNTdlZjUyYzg5ZDZfbHA5ZUVFZXhzaDZ1NFA5N3hnd1ZIQUlmTFpabklpbEJfVG9rZW46TWhKbWJNWERSbzZrdTV4YkI1ZGNVVk0zbk1kXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=YjAxMmY1NWQyOWEzMDlkZTM1ZGYxNTdlZjUyYzg5ZDZfbHA5ZUVFZXhzaDZ1NFA5N3hnd1ZIQUlmTFpabklpbEJfVG9rZW46TWhKbWJNWERSbzZrdTV4YkI1ZGNVVk0zbk1kXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   全局的像素级特帧点云 <code>M</code> 由一系列点构成，每个点都由顶点位置，法向向量，置信度数量，颜色和概念向量（concept vector）组成</p>
<p>   想要生成这样的像素级特征点云<code>M</code>，首先需要进行帧（单张输入图片）预处理：通过一系列输入的深度图片获取顶点法相maps和相机方位，再通过计算获得每张图片中每个像素的语义上下文嵌入。其中，语义上下文的嵌入是通过结合局部和全局的CLIP features获得的。</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NGEzNWQ2NDUyZmE3NTgyZmJhZjBjYTUyNDdhMTc3MDVfTzZyMFpFM3oxbFN0M3FyR2xuNHhGR2Qxc1lwdTcwN3RfVG9rZW46QXF0UmJVR2pkb3RvQkV4b0FoT2NZRTZublZ6XzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NGEzNWQ2NDUyZmE3NTgyZmJhZjBjYTUyNDdhMTc3MDVfTzZyMFpFM3oxbFN0M3FyR2xuNHhGR2Qxc1lwdTcwN3RfVG9rZW46QXF0UmJVR2pkb3RvQkV4b0FoT2NZRTZublZ6XzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   然后再进行特征融合：通过相机的方位将每个帧的顶点和法相图映射到全局坐标系。对于帧$X_{t}$中的每个像素$(u，v)_t$，都在全局的点云图中具有相应的点$P_k$</p>
<p>   以下是将不同帧$X_t$中的特征集合在<code>M</code>中特征点的公式：</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NjE1NWU4ZTRiMzlkMTE5ZDI4OTliYzE4MjEzMjhiODlfZHZjTzQzQjJiZzdGTVEwWXUybW5HdHdYQ3Q5TXRZbHJfVG9rZW46QUtVd2JnYlBhb21waHN4Mm1YUWNTN3J4bmZnXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NjE1NWU4ZTRiMzlkMTE5ZDI4OTliYzE4MjEzMjhiODlfZHZjTzQzQjJiZzdGTVEwWXUybW5HdHdYQ3Q5TXRZbHJfVG9rZW46QUtVd2JnYlBhb21waHN4Mm1YUWNTN3J4bmZnXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   通过ConceptFusion的预处理和语义上下文嵌入，就获得了精确的场景语义点云信息。</p>
</li>
<li><p>场景Token化：由于场景语义点云的信息过于密集，导致信息长度不可控，不利于输入大模型，所以使用Scene-LLM中的体素<strong>均匀下采样方法</strong>，将图像数据转化为统一的tokens格式，确保数据可以与prompt一起输入Scene-LLM模型进行推理，同时也便于将场景进行动态更新。</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NWQ0ZDVmZTJkMzhlZGVlMzY0M2YwYWFiNGUyNjg4N2JfY0JvREx5dVpjWU9Fc2VjQXhoRXh5cnZ2Mks3S1V0QmdfVG9rZW46SW9yZmJ2dndqb0hLWnR4bnJZOWNFa0c4bnFnXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=NWQ0ZDVmZTJkMzhlZGVlMzY0M2YwYWFiNGUyNjg4N2JfY0JvREx5dVpjWU9Fc2VjQXhoRXh5cnZ2Mks3S1V0QmdfVG9rZW46SW9yZmJ2dndqb0hLWnR4bnJZOWNFa0c4bnFnXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   具体来说，这里首先将空间分为具有尺寸x×y×z的固定分辨率体素网格，其中x，y，z代表沿着各个轴的素数。由于这种固定的分辨率，在不同场景中的体素数量有所不同。其次，对于每个体素，使用K近邻（KNN）方法将所有包含的点聚类。每个点的特征包括语义属性和空间坐标。由此可以获得特征的体素网格：</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=OTYxNjUzNDExMzE1NWVmNzJlZDczM2I1ZWU0OGJkMTBfWEExclJlTTEweTFLSW9ya2J5cDBMa1pValpqR29PbTBfVG9rZW46UUpTRWJCYzZ0b3lYVmp4R0lwRmNMZFpQbjJiXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=OTYxNjUzNDExMzE1NWVmNzJlZDczM2I1ZWU0OGJkMTBfWEExclJlTTEweTFLSW9ya2J5cDBMa1pValpqR29PbTBfVG9rZW46UUpTRWJCYzZ0b3lYVmp4R0lwRmNMZFpQbjJiXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   其中D是语义特征的维度，而3是空间坐标的维度。</p>
<p>   最后，计算可见性映射V∈{0，1} x×y×z，表明每个体素中的点存在（1）或不存在（0）。仅使用可见体素的特征用作视觉tokens。这种 hybrid-representation 通过均匀地采样点云信息设置来保留密集的空间信息，同时促进了语义特征空间的动态更新。</p>
<p>   语义体素网络的动态更新可以通过如下方式实现：为了更新场景以状态t的 $f^{vox}_t$ 到状态t + 1，我们首先从当前的摄像头视图渲染3D 帧。该帧的语义特征F被投影到3D点的特征映射Fˆ，并将其体素化为F^^{Vox}并且生成 visibility map Vˆ。然后使用以下方式更新语义体素网络</p>
 <div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=Zjg1ZGYyM2U3ZTgzZjM4MGI3OWFiNGU1YjZjZDM5MGJfaUJWYlJaOFZVY3BiQjZhVHFpNGZrS2pkTnN1ckdQUXhfVG9rZW46THFqNmJJdnJIb2QzTjB4OG56OWMzTlBvbnRlXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=Zjg1ZGYyM2U3ZTgzZjM4MGI3OWFiNGU1YjZjZDM5MGJfaUJWYlJaOFZVY3BiQjZhVHFpNGZrS2pkTnN1ckdQUXhfVG9rZW46THFqNmJJdnJIb2QzTjB4OG56OWMzTlBvbnRlXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>
 
<p>   如此便可以确保3D场景的语义表示与任何场景状态变化保持同步。</p>
</li>
<li><p>Scene-LLM生成语义空间信息</p>
</li>
<li><ol>
<li>通过将场景Tokens和prompt结合输入Scene-LLM，得到工件，工具或其他工人所需物品的信息(<strong>粗标签</strong>+坐标)</li>
</ol>
</li>
<li><ol start="2">
<li>依据物品在场景中的坐标，获得相机视角下该物体的（多视角）裁剪图片</li>
</ol>
</li>
<li><ol start="3">
<li>如果是工件&#x2F;工具，则通过CLIP，将裁剪图与知识图谱中该物品的文字描述进行<strong>比对</strong>，得到工件或工具的具体ID和<strong>专业名称</strong>。</li>
</ol>
</li>
</ol>
<div class="post-content"><a href="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=MTUzYzYwYWYyMDYyYWE0ZThhNWI0ZmMyZTU5ODhjNmRfaXRGajVuN0dZRGgySXBVRTZDRDUwT3dXR2dXQk5LR0NfVG9rZW46Q05haWJOZzg1bzhxNzR4cWtCa2NieENablNjXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" title="" title=" class="gallery-item"><img src="/2025/02/18/[OBS]NSFC - SceneLLM+KnowledgeGraph/https://sjtu.feishu.cn/space/api/box/stream/download/asynccode/?code=MTUzYzYwYWYyMDYyYWE0ZThhNWI0ZmMyZTU5ODhjNmRfaXRGajVuN0dZRGgySXBVRTZDRDUwT3dXR2dXQk5LR0NfVG9rZW46Q05haWJOZzg1bzhxNzR4cWtCa2NieENablNjXzE3NDAzMDgwMTU6MTc0MDMxMTYxNV9WNA" alt="" title=""></a></div>

<p>CLIP（Contrastive Language-Image Pre-training）是一种基于对比学习的模型，旨在同时处理图像和文本数据，并将它们映射到一个共享的特征嵌入空间中。其训练过程包括对图像和文本对的学习，其中每一对图像和文本（如图像的描述）都会被处理成特征向量，图像由视觉编码器（通常是卷积神经网络或视觉Transformer）处理，文本则通过一个Transformer模型编码。模型的核心思想是通过对比学习的方式优化图像和文本之间的关系，使得正确配对的图像和文本在共享的嵌入空间中距离较近，而不相关的图像和文本则距离较远。这一过程通过对比损失函数（如InfoNCE）进行优化，模型逐渐学习到图像和文本之间的语义对应关系。CLIP在大规模图像-文本数据集上进行训练，通常涉及数百万对图像-文本配对，从而使其能够进行跨模态推理。训练完成后的CLIP能够在零-shot的情况下执行任务，即在没有专门训练的情况下处理新的计算机视觉和自然语言处理任务，如通过文本描述检索相关图像，或者根据图像检索相关文本。</p>
<p>想要比对裁剪图和物品的文字描述，可以通过使用预先使用CLIP预训练好的ViT图编码器和Transformer 文字编码器，分别用于编码物体的裁剪图和知识图谱中对于每一个工件的描述（并不需要每次识别都进行编码，可以预编码之后保存用于后续每次对比）。再使用裁剪图和文字的特征向量进行似然性评估，找到最贴合裁剪图的文字特征向量并由此获得裁剪图对应的具体工件或者工具序号。</p>
<p><strong>语义空间最终输出</strong>：场景中所有关键的工具、零件的标签（ID和<strong>专业名称</strong>）+精确位置坐标（场景中有啥，在哪）</p>
<h4 id="2-基于知识图谱的推理与任务生成"><a href="#2-基于知识图谱的推理与任务生成" class="headerlink" title="2. 基于知识图谱的推理与任务生成"></a>2. 基于知识图谱的推理与任务生成</h4><p>基于知识图谱的推理和任务生成方法在智能系统中扮演着关键角色，特别是在需要理解复杂场景和动态调整任务的应用中。</p>
<p>在获取了语义空间的信息后，知识图谱的应用主要分为以下几个步骤：</p>
<ol>
<li><p>通过工人的手部位置+语义空间的信息-&gt;判断当前正在装配的工件（检索&#x2F;搜索过程）+工人在用的工具</p>
</li>
<li><p>正在装配的工件+工人在用的工具+<strong>知识图谱</strong><strong>-&gt;<strong>判断下一步需要装配的零件以及需要的工具，并据此生成机器人需要执行的</strong>具体任务</strong>（比如抓取某区域的关键物体并放置到特定位置，更具体一些？）</p>
</li>
</ol>
<p>具体任务可能包括以下几种：</p>
<ul>
<li><p>GRASP <Pos>：</p>
<ul>
<li><p>任务描述：机器人需要抓取某一特定区域(<Pos>)的关键物体。</p>
</li>
<li><p>生成任务：结合语义空间的信息，系统会确定物体的精确位置（例如，某个工件的位置），并且会根据工件的形状、尺寸、重量等属性选择适当的抓取策略和工具。系统会向机器人发送抓取任务，指示其准确抓取目标物体。</p>
</li>
</ul>
</li>
<li><p>PLACE <Pos>：</p>
<ul>
<li><p>任务描述：机器人将物体放置到指定位置(<Pos>)。</p>
</li>
<li><p>生成任务：根据知识图谱和工人正在装配物体的位置，推理出工件的目标位置，例如，物体需要放置在某个工作台上的特定位置。</p>
</li>
<li><p>示例：将抓取的零件放置到工人需要的位置上，确保其放置的位置正确。</p>
</li>
</ul>
</li>
<li><p>GOTO <Pos>：</p>
<ul>
<li><p>任务描述：机器人末端移动到指定位置(<Pos>)。</p>
</li>
<li><p>生成任务：一般用于机器人执行完PLACE <Pos>后，归位以免阻碍工人操作工件</p>
</li>
</ul>
</li>
</ul>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-17T13:56:40.000Z" title="2/17/2025, 9:56:40 PM">2025-02-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-11T09:02:45.266Z" title="4/11/2025, 5:02:45 PM">2025-04-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 14 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/02/17/%5BOBS%5Dlinux-Docker/">Docker</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>proxy网络: <a target="_blank" rel="noopener" href="https://docs.docker.com/engine/daemon/proxy/#httphttps-proxy">https://docs.docker.com/engine/daemon/proxy/#httphttps-proxy</a></p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-09T11:48:43.000Z" title="1/9/2025, 7:48:43 PM">2025-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-11T09:02:45.633Z" title="4/11/2025, 5:02:45 PM">2025-04-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">5 minutes read (About 722 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Moco-%20Momentum%20Contrast%20for%20Unsupervised%20Visual%20Representation%20Learning/">Momentum Contrast for Unsupervised Visual Representation Learning</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304154105.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304154105.png" alt="" title=""></a></div>
左侧是query encoder，右侧为key encoder
## 是什么
通过无监督对比学习的方法(loss:InfoNCE)来学习图像的特征。
<div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304154327.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304154327.png" alt="" title=""></a></div>
使用的pretext task是个体判别任务

<p>伪代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># f_q, f_k: encoder networks for query and key </span></span><br><span class="line"><span class="comment"># queue: dictionary as a queue of K keys (CxK) </span></span><br><span class="line"><span class="comment"># m: momentum </span></span><br><span class="line"><span class="comment"># t: temperature  </span></span><br><span class="line"></span><br><span class="line">f_k.params = f_q.params <span class="comment"># initialize </span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> loader: <span class="comment"># load a minibatch x with N samples </span></span><br><span class="line">	x_q = aug(x) <span class="comment"># a randomly augmented version </span></span><br><span class="line">	x_k = aug(x) <span class="comment"># another randomly augmented version  </span></span><br><span class="line">	q = f_q.forward(x_q) <span class="comment"># queries: NxC </span></span><br><span class="line">	k = f_k.forward(x_k) <span class="comment"># keys: NxC </span></span><br><span class="line">	k = k.detach() <span class="comment"># no gradient to keys  </span></span><br><span class="line">	</span><br><span class="line">	<span class="comment"># positive logits: Nx1 </span></span><br><span class="line">	l_pos = bmm(q.view(N,<span class="number">1</span>,C), k.view(N,C,<span class="number">1</span>))  <span class="comment"># 相当于把batch中每个正样本对之间求了cosine临近</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment"># negative logits: NxK </span></span><br><span class="line">	l_neg = mm(q.view(N,C), queue.view(C,K))  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># logits: Nx(1+K) </span></span><br><span class="line">	logits = cat([l_pos, l_neg], dim=<span class="number">1</span>)  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># contrastive loss, Eqn.(1) </span></span><br><span class="line">		labels = zeros(N) <span class="comment"># positives are the 0-th，将识别的类别视为0,可以直接使用CrossEntropyLoss</span></span><br><span class="line">	loss = CrossEntropyLoss(logits/t, labels)  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># SGD update: query network </span></span><br><span class="line">	loss.backward() </span><br><span class="line">	update(f_q.params)  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># momentum update: key network </span></span><br><span class="line">	f_k.params = m*f_k.params+(<span class="number">1</span>-m)*f_q.params  </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># update dictionary </span></span><br><span class="line">	enqueue(queue, k) <span class="comment"># enqueue the current minibatch </span></span><br><span class="line">	dequeue(queue) <span class="comment"># dequeue the earliest minibatch</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="亮点"><a href="#亮点" class="headerlink" title="亮点"></a>亮点</h2><h3 id="Dictionary-as-a-queue"><a href="#Dictionary-as-a-queue" class="headerlink" title="Dictionary as a queue"></a>Dictionary as a queue</h3><p>在使用key encoder(momentum encoder)创建负样本，并把encode过的负样本存在一个queue（FIFO）中方便后续对比时直接使用，每次训练都会使用一个新的mini batch，此时会将此mini batch中的样本encode之后加入queue并删除存在最久的那个mini batch的样本（因为考虑到最老的mini batch使用的encoder是最过时的，所以FIFO是非常合理的），这样可以有效控制负样本的数量，也就是公式中的K。</p>
<ul>
<li>节省字典的计算开销</li>
<li>而且mini batch大小可以直接和负样本脱钩</li>
</ul>
<h3 id="Momentum-update"><a href="#Momentum-update" class="headerlink" title="Momentum update"></a>Momentum update</h3><p>因为负样本数量（字典&#x2F;队列）很大，所以没办法给key encoder回传梯度，所以可以考虑把query encoder的参数直接复制给key encoder，<strong>但过快改变的key encoder会导致样本字典的特征不一致</strong>，所以使用动量更新的方式。</p>
<div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304160138.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304160138.png" alt="" title=""></a></div>
> queue这个字典越大，那么理论上这个m就需要越大，保证字典中key的一致性

<h2 id="过往工作对比"><a href="#过往工作对比" class="headerlink" title="过往工作对比"></a>过往工作对比</h2><div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304160703.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Moco- Momentum Contrast for Unsupervised Visual Representation Learning/Pasted_image_20250304160703.png" alt="" title=""></a></div>
a)
所有的样本都在一个 mini batch 里，两个encoder完全一致，也因此都可以回传梯度，keys也高度一致，但限制了字典的大小

<p>b)<br>只有一个编码器进行学习。Memory bank存下了所有样本的key。每当梯度回传后，会把memory bank被本次训练中被采样过的key使用新的encoder进行更新。</p>
<ul>
<li>缺乏特帧一致性</li>
<li>需要训练一阵个epoch才能更新一遍memory bank</li>
</ul>
<p>MoCo和memory bank 更接近，但是使用了queue dictionary和momentum update</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-09T08:29:47.000Z" title="1/9/2025, 4:29:47 PM">2025-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-11T09:02:45.660Z" title="4/11/2025, 5:02:45 PM">2025-04-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-Vision%20Transformers%20Need%20Registers/">Vision Transformers Need Registers</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-09T08:28:49.000Z" title="1/9/2025, 4:28:49 PM">2025-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-11T09:02:45.642Z" title="4/11/2025, 5:02:45 PM">2025-04-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-DINOv2-%20Learning%20Robust%20Visual%20Features%20without%20Supervision/">DINOv2- Learning Robust Visual Features without Supervision</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-09T08:18:40.000Z" title="1/9/2025, 4:18:40 PM">2025-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-11T09:02:45.644Z" title="4/11/2025, 5:02:45 PM">2025-04-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a few seconds read (About 71 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/09/%5BOBS%5DReconstruct%20Anything-Semantic-AN%20IMAGE%20IS%20WORTH%2016X16%20WORDS-%20TRANSFORMERS%20FOR%20IMAGE%20RECOGNITION%20AT%20SCALE/">AN IMAGE IS WORTH 16X16 WORDS- TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/01/09/[OBS]Reconstruct Anything-Semantic-AN IMAGE IS WORTH 16X16 WORDS- TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE/Pasted_image_20250109194820.png" title="" title=" class="gallery-item"><img src="/2025/01/09/[OBS]Reconstruct Anything-Semantic-AN IMAGE IS WORTH 16X16 WORDS- TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE/Pasted_image_20250109194820.png" alt="" title=""></a></div>

<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=j3VNqtJUoz0&t=16s">https://www.youtube.com/watch?v=j3VNqtJUoz0&amp;t=16s</a></p>
<p>核心思想：</p>
<ul>
<li>将图像分为patches, 线性映射, 再加上图片的position embeding来输入transformer encoder</li>
<li>额外使用一个cls token用于占位（ViT的输出就是这个cls input token对应的output token）</li>
</ul>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-08T12:26:27.000Z" title="1/8/2025, 8:26:27 PM">2025-01-08</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-11T09:02:45.657Z" title="4/11/2025, 5:02:45 PM">2025-04-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">4 minutes read (About 561 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/08/%5BOBS%5DReconstruct%20Anything-Semantic-DINO/">DINO</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/dino/tree/main">https://github.com/facebookresearch/dino/tree/main</a></p>
<div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250306112727.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250306112727.png" alt="" title=""></a></div>
# Emerging Properties in Self-Supervised Vision Transformers

<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/7224738994825789496">https://juejin.cn/post/7224738994825789496</a><br><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=h3ij3F3cPIk&t=1005s">https://www.youtube.com/watch?v=h3ij3F3cPIk&amp;t=1005s</a><br>DI+NO（蒸馏+No Label）<br>具体来说，DINO 是使用一种称为“无监督自蒸馏”的方法，该方法通过自监督学习来学习模型的知识表示。在这个方法中，模型使用自身的输出来生成“伪标签”，然后使用这些伪标签来重新训练模型，从而进一步提高模型的性能和泛化能力。</p>
<h2 id="知识蒸馏"><a href="#知识蒸馏" class="headerlink" title="知识蒸馏"></a>知识蒸馏</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/xbinworld/article/details/83063726">https://blog.csdn.net/xbinworld/article/details/83063726</a></p>
<blockquote>
<p>重点idea就是提出用soft target来辅助hard target一起训练，而soft target来自于大模型的预测输出。这里有人会问，明明true label（hard target）是完全正确的，为什么还要soft target呢？<br>hard target 包含的信息量（信息熵）很低，soft target包含的信息量大，拥有不同类之间关系的信息（比如同时分类驴和马的时候，尽管某张图片是马，但是soft target就不会像hard target 那样只有马的index处的值为1，其余为0，而是在驴的部分也会有概率。）[5]<br>这样的好处是，这个图像可能更像驴，而不会去像汽车或者狗之类的，而这样的soft信息存在于概率中，以及label之间的高低相似性都存在于soft target中。但是如果soft targe是像这样的信息[0.98 0.01 0.01]，就意义不大了，所以需要在softmax中增加温度参数T（这个设置在最终训练完之后的推理中是不需要的）</p>
</blockquote>
<div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250108203323.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250108203323.png" alt="" title=""></a></div>

<h2 id="ViT"><a href="#ViT" class="headerlink" title="ViT"></a>ViT</h2><div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250109141410.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250109141410.png" alt="" title=""></a></div>


<h2 id="DINO"><a href="#DINO" class="headerlink" title="DINO"></a>DINO</h2><div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250109152153.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250109152153.png" alt="" title=""></a></div>
<div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250304154624.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250304154624.png" alt="" title=""></a></div>
总的来说DINO最适合的任务就是将不同状态的同一物体进行归类。


<p>关于DINO中发生的涌现<br><a target="_blank" rel="noopener" href="https://juejin.cn/post/7280436457142501388">https://juejin.cn/post/7280436457142501388</a></p>
<p>DINO之前的工作</p>
<div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250110172355.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250110172355.png" alt="" title=""></a></div>

<p>We have also seen emerged two properties that can be leveraged in future applications: the quality of the features in k-NN classification has a potential for image retrieval. The presence of information about the scene layout in the features can also benefit weakly supervised image segmentation.</p>
<div class="post-content"><a href="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250219093931.png" title="" title=" class="gallery-item"><img src="/2025/01/08/[OBS]Reconstruct Anything-Semantic-DINO/Pasted_image_20250219093931.png" alt="" title=""></a></div></div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-06T12:12:44.000Z" title="1/6/2025, 8:12:44 PM">2025-01-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-11T09:02:45.660Z" title="4/11/2025, 5:02:45 PM">2025-04-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">a minute read (About 197 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/06/%5BOBS%5DReconstruct%20Anything-Semantic-CLIP%E5%A4%9A%E6%A8%A1%E6%80%81%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">CLIP</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/01/06/[OBS]Reconstruct Anything-Semantic-CLIP多模态预训练模型/Pasted_image_20250106201326.png" title="" title=" class="gallery-item"><img src="/2025/01/06/[OBS]Reconstruct Anything-Semantic-CLIP多模态预训练模型/Pasted_image_20250106201326.png" alt="" title=""></a></div>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/h661975/article/details/135116957">https://blog.csdn.net/h661975/article/details/135116957</a></p>
<p>loss: ITC (Image Text Contrastive)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># image_encoder - ResNet or Vision Transformer </span></span><br><span class="line"><span class="comment"># text_encoder - CBOW or Text Transformer </span></span><br><span class="line"><span class="comment"># I[n, h, w, c] - minibatch of aligned images </span></span><br><span class="line"><span class="comment"># T[n, l] - minibatch of aligned texts </span></span><br><span class="line"><span class="comment"># W_i[d_i, d_e] - learned proj of image to embed </span></span><br><span class="line"><span class="comment"># W_t[d_t, d_e] - learned proj of text to embed </span></span><br><span class="line"><span class="comment"># t - learned temperature parameter  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># extract feature representations of each modality </span></span><br><span class="line">I_f = image_encoder(I) <span class="comment">#[n, d_i] </span></span><br><span class="line">T_f = text_encoder(T) <span class="comment">#[n, d_t]  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># joint multimodal embedding [n, d_e] </span></span><br><span class="line">I_e = l2_normalize(np.dot(I_f, W_i), axis=<span class="number">1</span>) T</span><br><span class="line">_e = l2_normalize(np.dot(T_f, W_t), axis=<span class="number">1</span>)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># scaled pairwise cosine similarities [n, n] </span></span><br><span class="line">logits = np.dot(I_e, T_e.T) * np.exp(t)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># symmetric loss function </span></span><br><span class="line">labels = np.arange(n) </span><br><span class="line">loss_i = cross_entropy_loss(logits, labels, axis=<span class="number">0</span>) </span><br><span class="line">loss_t = cross_entropy_loss(logits, labels, axis=<span class="number">1</span>) </span><br><span class="line">loss = (loss_i + loss_t)/<span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>Cross_entropy_loss:</p>
<div class="post-content"><a href="/2025/01/06/[OBS]Reconstruct Anything-Semantic-CLIP多模态预训练模型/Pasted_image_20250304121717.png" title="" title=" class="gallery-item"><img src="/2025/01/06/[OBS]Reconstruct Anything-Semantic-CLIP多模态预训练模型/Pasted_image_20250304121717.png" alt="" title=""></a></div>

<p>CLIP 本质上是全局图像嵌入，不利于像素对齐特征提取。</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-06T08:42:43.000Z" title="1/6/2025, 4:42:43 PM">2025-01-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-11T09:02:45.632Z" title="4/11/2025, 5:02:45 PM">2025-04-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">5 minutes read (About 790 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/06/%5BOBS%5DReconstruct%20Anything-LERF-%20Language%20Embedded%20Radiance%20Fields/">LERF- Language Embedded Radiance Fields</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><div class="post-content"><a href="/2025/01/06/[OBS]Reconstruct Anything-LERF- Language Embedded Radiance Fields/Pasted_image_20250106164559.png" title="" title=" class="gallery-item"><img src="/2025/01/06/[OBS]Reconstruct Anything-LERF- Language Embedded Radiance Fields/Pasted_image_20250106164559.png" alt="" title=""></a></div>

<p><strong>NeRF+CLIP</strong></p>
<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul>
<li>神经辐射场 (NeRF) 已成为一种强大的技术，用于捕获复杂的现实世界 3D 场景的逼真数字表示。然而，NeRF 的直接输出只不过是一个彩色的密度场，缺乏意义或上下文，这阻碍了构建与生成的 3D 场景交互的界面。</li>
<li>自然语言是与 3D 场景交互的直观界面。考虑厨房的捕获。想象一下，能够通过询问“用具”在哪里来导航这个厨房，或者更具体地说，询问可用于“搅拌”的工具，甚至可以询问您最喜欢的带有特定功能的杯子。其上的徽标——贯穿日常对话的舒适和熟悉。这不仅需要处理自然语言输入查询的能力，还需要能够在多个尺度上合并语义并与长尾和抽象概念相关。</li>
</ul>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>一个Language Field<br>通过优化从现成的视觉语言模型（如 CLIP）到 3D 场景的嵌入，为 NeRF 中的语言奠定基础。<br>LERF 提供了一个额外的好处：由于我们从多个尺度的多个视图中提取 CLIP 嵌入，因此通过 3D CLIP 嵌入获得的文本查询的相关性图与通过 2D CLIP 嵌入获得的文本查询的相关性图相比更加本地化。根据定义，它们也是 3D 一致的，可以直接在 3D 字段中进行查询，而无需渲染到多个视图。</p>
<p>相较于Clip-Field[[CLIP-Fields- Weakly Supervised Semantic Fields for Robotic Memory]], LERF 更密集。</p>
<blockquote>
<p>CLIP-Fields [32] and NLMaps-SayCan [8] fuse CLIP embeddings of crops into pointclouds, using a contrastively supervised field and classical pointcloud fusion respectively. In CLIP-Fields, the crop locations are guided by Detic [40]. On the other hand, NLMaps-SayCan relies on region proposal networks. These maps are sparser than LERF as they primarily query CLIP on detected objects rather than densely throughout views of the scene. Concurrent work ConceptFusion [19] fuses CLIP features more densely in RGBD pointclouds, using Mask2Former [9] to predict regions of interest, meaning it can lose objects which are out of distribution to Mask2Former’s training set. In contrast, LERF does not use region or mask proposals.</p>
</blockquote>
<h2 id="LERF"><a href="#LERF" class="headerlink" title="LERF"></a>LERF</h2><h2 id="给定一组校准的输入图像，我们将-CLIP-嵌入到-NeRF-内的-3D-场中。然而，查询单个-3D-点的-CLIP-嵌入是不明确的，因为-CLIP-本质上是全局图像嵌入，不利于像素对齐特征提取。为了解释这一特性，我们提出了一种新颖的方法，该方法涉及学习以样本点为中心的卷上的语言嵌入领域。具体来说，该字段的输出是包含指定体积的图像作物的所有训练视图中的平均-CLIP-嵌入。通过将查询从点重新构造为体积，我们可以有效地从输入图像的粗裁剪中监督密集的字段，这些图像可以通过在给定的体积尺度上进行调节来以像素对齐的方式渲染。"><a href="#给定一组校准的输入图像，我们将-CLIP-嵌入到-NeRF-内的-3D-场中。然而，查询单个-3D-点的-CLIP-嵌入是不明确的，因为-CLIP-本质上是全局图像嵌入，不利于像素对齐特征提取。为了解释这一特性，我们提出了一种新颖的方法，该方法涉及学习以样本点为中心的卷上的语言嵌入领域。具体来说，该字段的输出是包含指定体积的图像作物的所有训练视图中的平均-CLIP-嵌入。通过将查询从点重新构造为体积，我们可以有效地从输入图像的粗裁剪中监督密集的字段，这些图像可以通过在给定的体积尺度上进行调节来以像素对齐的方式渲染。" class="headerlink" title="给定一组校准的输入图像，我们将 CLIP 嵌入到 NeRF 内的 3D 场中。然而，查询单个 3D 点的 CLIP 嵌入是不明确的，因为 CLIP 本质上是全局图像嵌入，不利于像素对齐特征提取。为了解释这一特性，我们提出了一种新颖的方法，该方法涉及学习以样本点为中心的卷上的语言嵌入领域。具体来说，该字段的输出是包含指定体积的图像作物的所有训练视图中的平均 CLIP 嵌入。通过将查询从点重新构造为体积，我们可以有效地从输入图像的粗裁剪中监督密集的字段，这些图像可以通过在给定的体积尺度上进行调节来以像素对齐的方式渲染。"></a>给定一组校准的输入图像，我们将 CLIP 嵌入到 NeRF 内的 3D 场中。然而，查询单个 3D 点的 CLIP 嵌入是不明确的，因为 CLIP 本质上是全局图像嵌入，不利于像素对齐特征提取。为了解释这一特性，我们提出了一种新颖的方法，该方法涉及学习以样本点为中心的卷上的语言嵌入领域。具体来说，该字段的输出是包含指定体积的图像作物的所有训练视图中的平均 CLIP 嵌入。通过将查询从点重新构造为体积，我们可以有效地从输入图像的粗裁剪中监督密集的字段，这些图像可以通过在给定的体积尺度上进行调节来以像素对齐的方式渲染。<br><div class="post-content"><a href="/2025/01/06/[OBS]Reconstruct Anything-LERF- Language Embedded Radiance Fields/Pasted_image_20250108172911.png" title="" title=" class="gallery-item"><img src="/2025/01/06/[OBS]Reconstruct Anything-LERF- Language Embedded Radiance Fields/Pasted_image_20250108172911.png" alt="" title=""></a></div></h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/amusi1994/article/details/129701012">https://blog.csdn.net/amusi1994/article/details/129701012</a></p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-06T07:08:28.000Z" title="1/6/2025, 3:08:28 PM">2025-01-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-04-11T09:02:45.696Z" title="4/11/2025, 5:02:45 PM">2025-04-11</time></span><span class="level-item"><a class="link-muted" href="/categories/Note/">Note</a></span><span class="level-item">3 minutes read (About 480 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/06/%5BOBS%5DReconstruct%20Anything-Some%20Thoughts%20Regarding%20-Reconstruct%20Anything-/">Some Thoughts Regarding -Reconstruct Anything-</a></p><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/css/lightgallery.min.css" /><div class=".article-gallery"><p>主要记录一些读场景语义化重建的论文的过程中的想法</p>
<h2 id="重要的问题"><a href="#重要的问题" class="headerlink" title="重要的问题"></a>重要的问题</h2><h3 id="多模态包含哪些任务"><a href="#多模态包含哪些任务" class="headerlink" title="多模态包含哪些任务"></a>多模态包含哪些任务</h3><ul>
<li>图文检索 Image-text Retrival</li>
<li>视觉问答 VQA</li>
<li>视觉推理 Visual Reasoning</li>
<li>视觉蕴含 Visual Entailment</li>
</ul>
<h3 id="多模态有哪些loss"><a href="#多模态有哪些loss" class="headerlink" title="多模态有哪些loss"></a>多模态有哪些loss</h3><ul>
<li>Image Text Contrastive(ITC) [[CLIP多模态预训练模型]]</li>
<li>Word Patch Aligment (WPA) used in object detection ViT</li>
<li>Image Text Matching (ITM) </li>
<li>Mask Languae Modeling (MLM) BERT 完形填空</li>
</ul>
<h3 id="给定一个具体的任务，机器人需要哪些场景信息才能顺利执行这个任务（通用机器人）"><a href="#给定一个具体的任务，机器人需要哪些场景信息才能顺利执行这个任务（通用机器人）" class="headerlink" title="给定一个具体的任务，机器人需要哪些场景信息才能顺利执行这个任务（通用机器人）"></a>给定一个具体的任务，机器人需要哪些场景信息才能顺利执行这个任务（通用机器人）</h3><p>限定：暂不考虑机器人的移动性，也就是不需要跨视野的导航(OK-Robot)，暂定为桌面机器人</p>
<p>具体来说，通用机器人的特点包括：</p>
<ol>
<li><strong>多任务能力</strong>：能够执行多种不同类型的任务，如装配、搬运、清洁、检测等。</li>
<li><strong>适应性强</strong>：具备适应多种环境和工作条件的能力，例如在不同地形或生产线中工作的能力。</li>
<li><strong>智能控制</strong>：通过先进的传感器、人工智能算法、机器学习技术等手段，能够实现自主决策和任务规划。</li>
</ol>
<ul>
<li>物体的具体形状（用于抓取, grab-anything）</li>
<li>物体语义信息（grounded caption, clip）</li>
</ul>
<h2 id="Recognize-The-Relationships-Between-Child-amp-Parent"><a href="#Recognize-The-Relationships-Between-Child-amp-Parent" class="headerlink" title="Recognize The Relationships Between Child &amp; Parent"></a>Recognize The Relationships Between Child &amp; Parent</h2><p>受DINO自蒸馏自监督的启发，可以通过物体活动的图像序列来推测物体各个部分的物理关系(attention map)[[DINO]]</p>
<p>训练集可以使用Unity生成不同的光影&#x2F;物体，连接语义</p>
<h2 id="Build-the-physics-world-in-robot-mind"><a href="#Build-the-physics-world-in-robot-mind" class="headerlink" title="Build the physics world in robot mind"></a>Build the physics world in robot mind</h2><p>voxel collider for detected objects, joints, physics agent interact with physics engine.<br>点云数据，grounded caption&#x3D;&gt;object property, hierarchy relation, joints(maybe new model should be proposed)</p>
<h2 id="语义还原物体模型"><a href="#语义还原物体模型" class="headerlink" title="语义还原物体模型"></a>语义还原物体模型</h2><p>受[[BLIP]]启发，understanding for language &amp; existing point cloud, generation for the rest of the point cloud (Wonder3D已实现)</p>
</div><script src="https://cdn.jsdelivr.net/npm/lightgallery.js@1.4.0/dist/js/lightgallery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-thumbnail.js@1.2.0/dist/lg-thumbnail.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-fullscreen.js@1.2.0/dist/lg-fullscreen.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-zoom.js@1.3.0/dist/lg-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-autoplay.js@1.2.0/dist/lg-autoplay.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-video.js@1.3.0/dist/lg-video.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-hash.js@1.0.0/dist/lg-hash.min.js"></script><script src="https://cdn.jsdelivr.net/npm/lg-pager.js@1.0.0/dist/lg-pager.min.js"></script><script>if (typeof lightGallery !== 'undefined') {
        var options = {
            selector: '.gallery-item'
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);
        }</script></div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/Note/">Previous</a></div><div class="pagination-next"><a href="/categories/Note/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/Note/">1</a></li><li><a class="pagination-link is-current" href="/categories/Note/page/2/">2</a></li><li><a class="pagination-link" href="/categories/Note/page/3/">3</a></li><li><a class="pagination-link" href="/categories/Note/page/4/">4</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/categories/Note/page/10/">10</a></li></ul></nav></div><style>.column.column-left,.column.column-right{display:none}</style><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Chen Yulin"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Chen Yulin</p><p class="is-size-6 is-block">SJTU student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Manchester by the Sea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">241</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">185</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Chen-Yulin" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/04/"><span class="level-start"><span class="level-item">April 2025</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">March 2025</span></span><span class="level-end"><span class="level-item tag">45</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">February 2025</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item">January 2025</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">December 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/11/"><span class="level-start"><span class="level-item">November 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/07/"><span class="level-start"><span class="level-item">July 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">June 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/05/"><span class="level-start"><span class="level-item">May 2024</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/04/"><span class="level-start"><span class="level-item">April 2024</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">December 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">May 2023</span></span><span class="level-end"><span class="level-item tag">46</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/2025/04/11/%5BOBS%5DPython-OmegaConf%20Python%20Package/"><img src="/thumb/Python.png" alt="OmegaConf Python Package"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-10T16:02:15.000Z">2025-04-11</time></p><p class="title"><a href="/2025/04/11/%5BOBS%5DPython-OmegaConf%20Python%20Package/">OmegaConf Python Package</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/07/%5BOBS%5Dlinux-SJTU-HPC-SJTU-HPC%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"><img src="/thumb/Linux.png" alt="SJTU-HPC基本操作"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-06T16:12:37.000Z">2025-04-07</time></p><p class="title"><a href="/2025/04/07/%5BOBS%5Dlinux-SJTU-HPC-SJTU-HPC%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/">SJTU-HPC基本操作</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/02/%5BOBS%5Dlinux-Tuxguitar%20on%20Archlinux/"><img src="/thumb/Linux.png" alt="Tuxguitar on Archlinux"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-02T10:28:21.000Z">2025-04-02</time></p><p class="title"><a href="/2025/04/02/%5BOBS%5Dlinux-Tuxguitar%20on%20Archlinux/">Tuxguitar on Archlinux</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/01/%5BOBS%5DAI-%E8%87%AA%E7%84%B6%E8%BE%A9%E8%AF%81%E6%B3%95%E5%88%86%E4%BA%AB%E4%B9%8BAI%E4%B8%AD%E7%9A%84%E6%B6%8C%E7%8E%B0/"><img src="/thumb/AI.png" alt="自然辩证法分享之AI中的涌现"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-04-01T15:44:28.000Z">2025-04-01</time></p><p class="title"><a href="/2025/04/01/%5BOBS%5DAI-%E8%87%AA%E7%84%B6%E8%BE%A9%E8%AF%81%E6%B3%95%E5%88%86%E4%BA%AB%E4%B9%8BAI%E4%B8%AD%E7%9A%84%E6%B6%8C%E7%8E%B0/">自然辩证法分享之AI中的涌现</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/03/31/%5BOBS%5D%E7%A7%91%E7%A0%94-DINOv2%20Repository%20Application/"><img src="/thumb/Linux.png" alt="DINOv2 Repository Application"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-03-31T11:25:46.000Z">2025-03-31</time></p><p class="title"><a href="/2025/03/31/%5BOBS%5D%E7%A7%91%E7%A0%94-DINOv2%20Repository%20Application/">DINOv2 Repository Application</a></p><p class="categories"><a href="/categories/Note/">Note</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/3D-Scene/"><span class="tag">3D-Scene</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/6-D/"><span class="tag">6-D</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AIGC/"><span class="tag">AIGC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AR/"><span class="tag">AR</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Academic/"><span class="tag">Academic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Aliyun/"><span class="tag">Aliyun</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/App/"><span class="tag">App</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Atlas/"><span class="tag">Atlas</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BS4/"><span class="tag">BS4</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Beautify/"><span class="tag">Beautify</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Behaviorism/"><span class="tag">Behaviorism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Business/"><span class="tag">Business</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CADC/"><span class="tag">CADC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CD/"><span class="tag">CD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CLIP/"><span class="tag">CLIP</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CV/"><span class="tag">CV</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Capstone/"><span class="tag">Capstone</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Communication/"><span class="tag">Communication</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Contrastive-Learning/"><span class="tag">Contrastive-Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Control/"><span class="tag">Control</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Csharp/"><span class="tag">Csharp</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Css/"><span class="tag">Css</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cuda/"><span class="tag">Cuda</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DD/"><span class="tag">DD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DINO/"><span class="tag">DINO</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DT/"><span class="tag">DT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dataframe/"><span class="tag">Dataframe</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debate/"><span class="tag">Debate</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debugger/"><span class="tag">Debugger</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Diffusion/"><span class="tag">Diffusion</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Discrete-Mathematics/"><span class="tag">Discrete-Mathematics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docs/"><span class="tag">Docs</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dynamic-programming/"><span class="tag">Dynamic-programming</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ESP32/"><span class="tag">ESP32</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Education/"><span class="tag">Education</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embeded-System/"><span class="tag">Embeded-System</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embodied-AI/"><span class="tag">Embodied-AI</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emoation/"><span class="tag">Emoation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emotion/"><span class="tag">Emotion</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ethic/"><span class="tag">Ethic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FL/"><span class="tag">FL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Family/"><span class="tag">Family</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Federated-Learning/"><span class="tag">Federated-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Foundation/"><span class="tag">Foundation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Functional-programming/"><span class="tag">Functional programming</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Game/"><span class="tag">Game</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gated-NN/"><span class="tag">Gated-NN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Github/"><span class="tag">Github</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Godot/"><span class="tag">Godot</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HPC/"><span class="tag">HPC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HRI/"><span class="tag">HRI</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Haskell/"><span class="tag">Haskell</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Health/"><span class="tag">Health</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hierarchical/"><span class="tag">Hierarchical</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Html/"><span class="tag">Html</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Humanism/"><span class="tag">Humanism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hyprland/"><span class="tag">Hyprland</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IK/"><span class="tag">IK</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Grounding/"><span class="tag">Image-Grounding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Text/"><span class="tag">Image-Text</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-generation/"><span class="tag">Image-generation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ImitationLearning/"><span class="tag">ImitationLearning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Jolt/"><span class="tag">Jolt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Json/"><span class="tag">Json</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LSP/"><span class="tag">LSP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latex/"><span class="tag">Latex</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life/"><span class="tag">Life</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LinearAlgebra/"><span class="tag">LinearAlgebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Live2d/"><span class="tag">Live2d</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Love/"><span class="tag">Love</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lua/"><span class="tag">Lua</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MBTI/"><span class="tag">MBTI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MR-AR/"><span class="tag">MR/AR</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mason/"><span class="tag">Mason</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Math/"><span class="tag">Math</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Meme/"><span class="tag">Meme</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Message-Passing/"><span class="tag">Message-Passing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mod/"><span class="tag">Mod</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Motivation/"><span class="tag">Motivation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Movie/"><span class="tag">Movie</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-modal/"><span class="tag">Multi-modal</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-view/"><span class="tag">Multi-view</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Music/"><span class="tag">Music</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NN/"><span class="tag">NN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Network/"><span class="tag">Network</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nodejs/"><span class="tag">Nodejs</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Numpy/"><span class="tag">Numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nvim/"><span class="tag">Nvim</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Object-Detection/"><span class="tag">Object-Detection</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Open-Vocabulary/"><span class="tag">Open-Vocabulary</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenCV/"><span class="tag">OpenCV</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Oral/"><span class="tag">Oral</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PHD/"><span class="tag">PHD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PSY/"><span class="tag">PSY</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pandas/"><span class="tag">Pandas</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Panoptic/"><span class="tag">Panoptic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Path/"><span class="tag">Path</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Philosophy/"><span class="tag">Philosophy</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PhysX/"><span class="tag">PhysX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Physical-Scene/"><span class="tag">Physical-Scene</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Physics-engine/"><span class="tag">Physics-engine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pio/"><span class="tag">Pio</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Planning/"><span class="tag">Planning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Plugin/"><span class="tag">Plugin</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PoseEstimation/"><span class="tag">PoseEstimation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Postgraduate/"><span class="tag">Postgraduate</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Prefab/"><span class="tag">Prefab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Probability/"><span class="tag">Probability</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">23</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/QML/"><span class="tag">QML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Quantum/"><span class="tag">Quantum</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROS/"><span class="tag">ROS</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reading/"><span class="tag">Reading</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Real2Sim/"><span class="tag">Real2Sim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reconstruct/"><span class="tag">Reconstruct</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regex/"><span class="tag">Regex</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reinforcement-learning/"><span class="tag">Reinforcement-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Repository/"><span class="tag">Repository</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation-Learning/"><span class="tag">Representation-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robot/"><span class="tag">Robot</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robotics/"><span class="tag">Robotics</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SJTU-Lecture/"><span class="tag">SJTU-Lecture</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SQL/"><span class="tag">SQL</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SSH/"><span class="tag">SSH</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scene-graph/"><span class="tag">Scene-graph</span><span class="tag">27</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scene-synthesis/"><span class="tag">Scene-synthesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Science-fiction/"><span class="tag">Science-fiction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scrap/"><span class="tag">Scrap</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Script/"><span class="tag">Script</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Segmentation/"><span class="tag">Segmentation</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Semantic/"><span class="tag">Semantic</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shader/"><span class="tag">Shader</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shell/"><span class="tag">Shell</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Signals-and-Systems/"><span class="tag">Signals and Systems</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sim2Real/"><span class="tag">Sim2Real</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sklearn/"><span class="tag">Sklearn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Snippets/"><span class="tag">Snippets</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Society/"><span class="tag">Society</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Star-rail/"><span class="tag">Star-rail</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Subgraph/"><span class="tag">Subgraph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Submodule/"><span class="tag">Submodule</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Supervised-learning/"><span class="tag">Supervised-learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Survey/"><span class="tag">Survey</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TC/"><span class="tag">TC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TOEFL/"><span class="tag">TOEFL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Task-Planning/"><span class="tag">Task-Planning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tasks/"><span class="tag">Tasks</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tech-Communication/"><span class="tag">Tech Communication</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Torch/"><span class="tag">Torch</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Translation-Embedding/"><span class="tag">Translation-Embedding</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Travel/"><span class="tag">Travel</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unity/"><span class="tag">Unity</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unsupervised-learning/"><span class="tag">Unsupervised-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLM/"><span class="tag">VLM</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLP/"><span class="tag">VLP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Version-management/"><span class="tag">Version-management</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ViT/"><span class="tag">ViT</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VideoEditing/"><span class="tag">VideoEditing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vim/"><span class="tag">Vim</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Visual-Relation/"><span class="tag">Visual-Relation</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WSL/"><span class="tag">WSL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Waybar/"><span class="tag">Waybar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wayland/"><span class="tag">Wayland</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Web/"><span class="tag">Web</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Website/"><span class="tag">Website</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Well-being/"><span class="tag">Well-being</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Window-manager/"><span class="tag">Window-manager</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/YKLL/"><span class="tag">YKLL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Zen/"><span class="tag">Zen</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%F0%9F%90%B1/"><span class="tag">🐱</span><span class="tag">1</span></a></div></div></div></div></div></div><style>.column.column-left,.column.column-right{display:block}</style></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img class="logo-img" src="/img/cyllogo.png" alt="Chen Yulin&#039;s Blog" height="28"><img class="logo-img-dark" src="/img/cyllogonight.png" alt="Chen Yulin&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 Chen Yulin</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/imaegoo/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Chen-Yulin"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><div class="searchbox-pinyin"><label class="checkbox"><input id="search-by-pinyin" type="checkbox" checked="checked"><span> 拼音检索</span></label></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/imaegoo/pinyin.js" defer></script><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script type="text/javascript" src="/js/imaegoo/imaegoo.js"></script><script type="text/javascript" src="/js/imaegoo/universe.js"></script><!-- hexo injector body_end start -->
<link rel="stylesheet" crossorigin href="https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.css" />
<script type="module" crossorigin src="https://g.alicdn.com/aliyun-documentation/web-chatbot-ui/0.0.11/index.js"></script>
<script>
  window.CHATBOT_CONFIG = {
    endpoint: "https://webchat-bot-iqu-knzhgrvznd.cn-hangzhou.fcapp.run/chat", // 可以替换为 https://{your-fc-http-trigger-domain}/chat
    displayByDefault: false, // 默认不展示 AI 助手聊天框
    aiChatOptions: { // aiChatOptions 中 options 会传递 aiChat 组件，自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat
      conversationOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#conversation-options
        conversationStarters: [
          {prompt: '你是谁？'},
          {prompt: '博主又是谁？'},
          {prompt: '怎么使用这个网站？'},
          {prompt: '想要博主联系方式！'},
        ]
      },
      displayOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#display-options
        height: 600,
        width: 350,
      },
      personaOptions: { // 自定义取值参考：https://docs.nlkit.com/nlux/reference/ui/ai-chat#chat-personas
        assistant: {          name: '博主的AI助手，十四行诗参上！',
          // AI 助手的图标
          avatar: 'https://chen-yulin.github.io/thumb/14.png',
          tagline: '要不要试试问下面的问题呢？',
        }
      }
    }
  };
</script>
<style>
  :root {
    /* webchat 工具栏的颜色 */
    --webchat-toolbar-background-color: #1464E4;
    /* webchat 工具栏文字和按钮的颜色 */
    --webchat-toolbar-text-color: #FFF;
  }
  /* webchat 对话框如果被遮挡，可以尝试通过 z-index、bottom、left 等设置来调整位置 */
  .webchat-container {
    z-index: 100;
    bottom: 10px;
    right: 10px;
  }
  /* webchat 的唤起按钮如果被遮挡，可以尝试通过 z-index、bottom、left 等设置来调整位置 */
  .webchat-bubble-tip {
    z-index: 99;
    bottom: 60px;
    right: 20px;
  }
  .webchat-bubble-tip {
    overflow: visible !important;
  }
  @keyframes float {
    0% {
      transform: translateY(0px) translateX(-50%);
    }
    50% {
      transform: translateY(-10px) translateX(-50%);
    }
    100% {
      transform: translateY(0px) translateX(-50%);
    }
  }

  .webchat-bubble-tip::before {
    content: '';
    position: absolute;
    top: -25px;
    left: 70%;
    width: 40px;
    height: 40px;
    background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='white'%3E%3Cpath d='M20 2H4c-1.1 0-2 .9-2 2v18l4-4h14c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm0 14H6l-2 2V4h16v12z'/%3E%3C/svg%3E");
    background-repeat: no-repeat;
    background-position: center;
    background-size: contain;
    filter: drop-shadow(0 4px 6px rgba(0, 0, 0, 0.5));
    animation: float 3s ease-in-out infinite;
  }
</style><script data-pjax src="https://registry.npmmirror.com/oh-my-live2d/latest/files"></script><script>const oml2d = OML2D.loadOml2d({libraryUrls:{"complete":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/complete.js","cubism2":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism2.js","cubism5":"https://registry.npmmirror.com/oh-my-live2d/latest/files/lib/cubism5.js"},dockedPosition:"left",mobileDisplay:true,models:[{"path":"https://model.hacxy.cn/mai/model.json","mobilePosition":[25,0],"mobileScale":0.1,"mobileStageStyle":{"width":125,"height":175},"motionPreloadStrategy":"ALL","position":[50,0],"scale":0.2,"stageStyle":{"width":250,"height":350}}],parentElement:document.body,primaryColor:"var(--btn-bg)",sayHello:false,tips:{style: {"width":230,"height":120,"left":"calc(50% - 20px)","top":"-100px"},mobileStyle: {"width":180,"height":80,"left":"calc(50% - 30px)","top":"-100px"},idleTips:{interval:15000,message:function(){
  return axios.get('https://v1.hitokoto.cn?c=i')
    .then(function (response) {
      return response.data.hitokoto ;
    })
    .catch(function (error) {
      console.error(error);
    });
}
}}});</script><!-- hexo injector body_end end --></body></html>